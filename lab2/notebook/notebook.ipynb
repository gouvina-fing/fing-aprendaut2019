{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega 2 - Clasificador (Árboles de Decisión)\n",
    "\n",
    "### Grupo 07:\n",
    "     - Renzo Gambone C.I. 5.155.486-4\n",
    "     - Germán Ouviña C.I. 4.823.566-1\n",
    "     - Leandro Rodríguez C.I 4.691.736-4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción\n",
    "***\n",
    "### 1.1. Objetivo\n",
    "***\n",
    "El objetivo de esta tarea fue implementar un modelo de **árboles de decisión**, basándose su entrenamiento en el algoritmo **ID3** con una serie de modificaciones. Una vez generados distintos clasificadores en base a ciertos parámetros, se evaluó la performance de los mismos utilizando distintos tipos de métrica y comparando dichas evaluaciones para determinar cual modelo se ajustó mejor a cada escenario.\n",
    "\n",
    "En términos formales, los parámetros del problema se reducen a lo siguiente:\n",
    "- **Tarea *T*:** Clasificar ejemplos siguiendo cierto formato.\n",
    "- **Experiencia *E*:** Conjunto de datos con ejemplos ya clasificados siguiendo cierto formato.\n",
    "- **Performance *P*:** Múltiples tipos de medidas (las cuales se profundizan en la sección 3).\n",
    "\n",
    "### 1.2. Entrega\n",
    "***\n",
    "La entrega de esta tarea consta de dos grandes componentes:\n",
    "- **Informe** en formato de Jupyter Notebook (este informe).\n",
    "- **Programa** que permite entrenar clasificadores, evaluar su desempeño y clasificar nuevos ejemplos.\n",
    "\n",
    "El objetivo del informe es centralizar la información relativa a la construcción del modelo así como los datos obtenidos mediante pruebas realizadas con distintas configuraciones paramétricas. Como agregado opcional, se adjuntan algunos scripts para ayudar a la lectura o probar en tiempo real ciertas funcionalidades.\n",
    "\n",
    "Por otra parte, el programa ofrece una interfaz en consola que permite entrenar y evaluar árboles acorde a múltiples configuraciones paramétricas, mostrar los arboles entrenados y calificar elementos del conjunto asociado al árbol. También se agregó un script para entrenar y evaluar modelos automáticamente. Si bien todas estas herramientas fueron pensadas para uso del grupo, en el archivo README.md se adjunta una sencilla guía de como utilizarlas.\n",
    "\n",
    "### 1.3. Formato\n",
    "***\n",
    "En las siguientes secciones se especifica el diseño del modelo, justificando la toma de decisiones a la hora de construirlo y se detallan las estrategias o algoritmos que fueron implementados para la configuración paramétrica, junto a las métricas utilizadas en la evaluación. Luego, se detalla la metodología de experimentación y con la misma los resultados obtenidos para cada modelo y cada conjunto de datos, habiendo entrenado con distintas configuraciones paramétricas. Finalmente se agregan conclusiones respecto a los resultados obtenidos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Diseño\n",
    "***\n",
    "En esta sección se detallan las características del diseño utilizado para construir el modelo, se profundizan las estrategias y algoritmos empleados en la configuración paramétrica y se tratan otros puntos como el procesamiento previo al entrenamiento y la evaluación posterior al mismo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Modelo\n",
    "***\n",
    "La consigna propone la utilización y comparación de dos tipos de modelos que basan su entrenamiento en **ID3**. Dichos modelos serán denominados **árboles de decisión** y **bosques de decisión** respectivamente. A continuación, se especifican las características de cada uno:\n",
    "\n",
    "**Notas:**\n",
    "* No se ahonda en dichas descripciones puesto que son conceptos trabajados en el teórico.\n",
    "* Se utiliza notación matemática para visualizar fácilmente la definición de cada modelo.\n",
    "\n",
    "#### 2.1.1. Árbol de decisión\n",
    "***\n",
    "Para este escenario uno de los modelos propuestos es el de un **árbol de decisión** multiclase, es decir, una estructura de árbol que para un ejemplo dado, lo clasifica en una de múltiples clases.\n",
    "\n",
    "Se definen más formalmente las siguientes nociones:\n",
    "* $D =$ Conjunto de entrenamiento\n",
    "* $C_D =$ Conjunto de posibles clasificaciones para $d \\in D$\n",
    "* $T_D =$ Árbol de decisión generado en base a $D$\n",
    "* Se representa una clasificación de un ejemplo $d \\in D$ realizada por el árbol $T_D$ como $T_D(d) = c : c \\in C_D$ y $d \\in D$\n",
    "\n",
    "#### 2.1.2. Bosque de decisión\n",
    "***\n",
    "\n",
    "El otro modelo propuesto es el de un **bosque de decisión** multiclase de árboles binarios. El modelo de bosque se basa fuertemente en el modelo de árbol, consistiendo básicamente en un conjunto de árboles de decisión que clasifican un ejemplo para cada clase. El bosque pondera las clasificaciones de cada árbol en base a cierto criterio y genera una clasificación.\n",
    "\n",
    "Se definen más formalmente las siguientes nociones:\n",
    "* $D =$ Conjunto de entrenamiento\n",
    "* $C_D =$ Conjunto de posibles clasificaciones para $d \\in D$\n",
    "* $B_D =$ Bosque de decisión generado en base a $D$\n",
    "* $B_D(d) = c : c \\in C_D ^ d \\in D$, Representando esto una clasificación de un ejemplo $d \\in D$ realizada por el bosque $B_D$\n",
    "* $T_{(B, c)} =$ Árbol de decisión binario perteneciente a $B_D$ y generado en base a la clasificación $c \\in C_D$\n",
    "* Sea $|C_D| = n$, hay $n$ árboles de decisión binarios en $B_D$\n",
    "* Se representa una clasificación de un ejemplo $d \\in D$ realizada por el árbol $T_{(B, c)}$ como $T_{(B, c)}(d) = c' : c' \\in \\{True, False\\}$ y $d \\in D$\n",
    "\n",
    "Los detalles sobre los algoritmos de entrenamiento y clasificación utilizados por cada modelo se expanden en la sección 2.3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Preprocesamiento\n",
    "***\n",
    "Con los objetivos tanto de hacer viable, como de mejorar la performance de entrenamiento, se realizaron ciertos cambios en el conjunto de datos a utilizar. A continuación, se listan los cambios realizados agrupandolos en base a motivación y área cambiada en el conjunto original.\n",
    "\n",
    "**Notas:**\n",
    "* Los cambios realizados en el conjunto de datos fueron hechos en memoria, sin modificar de forma alguna los archivos originales.\n",
    "\n",
    "#### 2.2.1. Optimización (Representación)\n",
    "***\n",
    "La elección de la representación interna fue compleja, ya que se tuvo en cuenta tanto la performance como la facilidad a la hora de programar e interpretar el código.\n",
    "\n",
    "Luego de numerosas pruebas utilizando distintas representaciones, se determinó la utilización del objeto **DataFrame** de la biblioteca *pandas*. Al principio trajo muchos problemas de performance (tanto en uso de memoria como en velocidad) pero al implementar técnicas ofrecidas por la biblioteca dichos problemas se palearon, generando eventualmente un uso de memoria reducido y un entrenamiento veloz.\n",
    "\n",
    "#### 2.2.2. Estructura (Atributos)\n",
    "***\n",
    "Originalmente se buscó mantener la estructura de atributos estática, con el fin de impactar lo menos posible en el entrenamiento y su posterior evaluación. No obstante, para el segundo conjunto de datos (detallado en la sección 2.4), fue necesario cambiar la estructura eliminando varios atributos y generando otros nuevos.\n",
    "\n",
    "Más concretamente, el cambio realizado fue el proceso inverso al conocido como **one hot encoding**, ya que habia múltiples atributos que representaban \"la idea\" de un sólo atributo discreto. En múltiples problemas, la implementación de dicho algoritmo resulta de gran utilidad para mejorar el rendimiento tanto a nivel de performance como de clasificación, generando $x$ atributos binarios para $x$ posibles valores del atributo original. \n",
    "\n",
    "En el contexto de árboles de decisión, sucede lo opuesto: el aumento lineal en cantidad de atributos genera un aumento exponencial en el tamaño del árbol y en el tiempo de entrenamiento. Tomando esto en cuenta, se deshizo el **one hot encoding**, tratando a los atributos generados como continuos (este punto junto a sus implicancias son expandidos en las siguientes secciones).\n",
    "\n",
    "#### 2.2.3. Clasificación (Resultados)\n",
    "***\n",
    "Para el modelo de **árbol de decisión** no fue necesario realizar ningún cambio en el conjunto de datos. No obstante, para entrenar a los árboles pertenecientes al **bosque de decisión**, al ser estos de carácter binario y funcionar para una sola clase, hubo que modificar los resultados del conjunto.\n",
    "\n",
    "Utilizando las nociones de la sección 2.1, se procesó el conjunto de datos generando $|C_D| = n$ conjuntos con las clasificaciones correspondientes, uno para cada posible valor. Cada árbol del bosque fue entrenado utilizando uno de esos conjuntos generados. \n",
    "\n",
    "El conjunto original no fue modificado, por lo que el bosque en sí puede clasificar para las clases originales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Algoritmo\n",
    "***\n",
    "En la siguiente sección se centralizan todas las especificaciones relativas a los algoritmos empleados, tanto para entrenar como para clasificar. \n",
    "\n",
    "**Notas:**\n",
    "* Se hace referencia a puntos mencionados en secciones anteriores, sin entrar en detalle en lo que ya fue explicado.\n",
    "\n",
    "#### 2.3.1. Algoritmo de entrenamiento\n",
    "***\n",
    "El algoritmo de entrenamiento se basa en el conocido **algoritmo ID3** para construcción de **árboles de decisión**. Dicho algoritmo sigue las pautas generales vistas en el teórico. Se agregó la posibilidad de tratar atributos continuos y se varió el uso de medidas para detectar el mejor atributo. Dichos cambios se tratan en las sub secciones 2.3.3 y 2.3.4. \n",
    "\n",
    "Teniendo en cuenta lo mencionado en secciones anteriores, el algoritmo de entrenamiento implementado puede entrenar dos tipos de modelos, generando dos tipos de clasificadores:\n",
    "\n",
    "- **Árbol de decisión:** Se implementa el entrenamiento greedy estándar de ID3 con los cambios anteriormente mencionados y se obtiene como resultado un árbol de decisión multiclase.\n",
    "- **Bosque de decisión:** Se itera sobre cada posible clasificación, procesando el conjunto de datos según corresponda y generando un árbol de decisión binario utilizando el algoritmo ID3 adaptado anteriormente mencionado.\n",
    "\n",
    "#### 2.3.2. Algoritmo de clasificación\n",
    "***\n",
    "A la hora de clasificar un elemento como miembro de una clase, el procedimiento difiere dependiendo del modelo utilizado. No obstante, al igual que con el entrenamiento, la clasificación de un bosque se basa fuertemente en la de un árbol. \n",
    "\n",
    "Es importante mencionar que los árboles generados tienen una **probabilidad** asignada a cada hoja. Dicha probabilidad es calculada al momento de generar la hoja durante el entrenamiento. Al no quedar más atributos, se calcula la frecuencia de cada clase en el subconjunto de datos que hay en la hoja y aquella clasificación con mayor frecuencia es la elegida por la hoja, adjuntandose dicha frecuencia junto a ella.\n",
    "\n",
    "Teniendo esto en cuenta, a grandes rasgos, los algoritmos funcionan como sigue:\n",
    "\n",
    "- **Árbol de decisión:** Se toma el ejemplo a clasificar y se recorre recursivamente los nodos del árbol hasta llegar a una hoja. Se devuelve la clasificación junto a su probabilidad. Por la naturaleza del algoritmo, dicha probabilidad suele ser mayor a 0.5. \n",
    "- **Bosque de decisión:** Se toma el ejemplo a clasificar y se itera sobre cada árbol, obteniendo la clasificación del mismo. Una vez obtenidas todas las clasificaciones, se procede a realizar una **votación**. El resultado de dicha votación es la clasificación del ejemplo en cuestión.\n",
    "\n",
    "La clasificación del **árbol de decisión** no cuenta con grandes especificidades, ya que es la misma utilizada por los árboles de decisión genéricos. No obstante, para determinar el algoritmo de votación del **bosque de decisión** fue necesario determinar un criterio, por lo que a continuación se explaya sobre este asunto.\n",
    "\n",
    "En el escenario donde todos los árboles indican *False*, aludiendo a que el elemento no es de su clasificación y uno de los árboles indica *True*, la clasificación es trivial. En este caso el resultado final es la clasificación del elemento. Sin embargo este no es siempre el caso, dado que los árboles de decisión si bien son resistentes al ruido, no son inmunes al mismo.\n",
    "\n",
    "Un problema a resolver a la hora de trabajar con bosques son los *empates*, en donde uno o más árboles devuelven *True* para determinado ejemplo. El desempate se alcanza comparando la **probabilidad** con la que cada árbol clasificó al ejemplo y tomando aquella clasificación con mayor frecuencia. \n",
    "\n",
    "En caso de que haya empate entre varias clasificaciones y sus probabilidades, el bosque elige una de ellas aleatoriamente. En la sección 4 se expanden las implicancias de este hecho.\n",
    "\n",
    "#### 2.3.3. Selección de mejor atributo\n",
    "***\n",
    "Un paso crucial del algoritmo es decidir que atributo \"bifurca mejor\" el árbol. ID3 propone elegir el atributo que maximice la **ganancia de información**. Sin embargo, esta métrica favorece los atributos que toman múltiples valores sobre otros. A raiz de esto es que también se experimentó con otras estrategias en la configuración paramétrica, como el **ratio de ganancia** y la **reducción de \"impureza\"**\n",
    "\n",
    "Todas las siguientes estrategias trabajan con una métrica que determina *\"cuánto un atributo separa a los ejemplos según la clasificación objetivo\"*, esta métrica es la **entropía** y se define como:\n",
    "- Sea $D = $ Conjunto de datos\n",
    "- Sea $C_D = $ Conjunto de posibles clasificaciones para $d \\in D$\n",
    "- Sea $|C_D| = n =$ Cantidad de posibles clasificaciones en $C_D$\n",
    "- Sea $f_D : D \\rightarrow C_D =$ Función que clasifica elementos en $D$\n",
    "- Sea $p_i$ la proporción de ejemplos $d \\in D : f_D(d) = c_i$ con $c_i \\in C_D$ la i-ésima clasificación\n",
    "\n",
    "$$Entropía(D) = -\\sum p_i log_2(p_i)$$\n",
    "\n",
    "La entropía mide la heterogeneidad de los datos: cuanto más homogéneos, menor será la misma.\n",
    "\n",
    "A continuación, se adjunta una breve noción de las tres medidas utilizadas para determinar *\"el mejor atributo\"*:\n",
    "\n",
    "##### 2.3.3.1. Ganancia\n",
    "***\n",
    "Se define la **ganancia de información** de un atributo $a$ sobre una muestra $D$ como:\n",
    "\n",
    "$$Ganancia(D,a) = Entropía(D) - \\sum_{v \\in Val(a)}\\frac{|D_v|}{|D|}\\cdotp\n",
    " Entropía(D_v)\\$$\n",
    "\n",
    "La fundamentación de tomar la ganancia es que se desea que el atributo sobre el cual se particione divida el conjunto de datos de la forma más homogénea en cuanto a su clasificación posible.\n",
    "\n",
    "Como se mencionó anteriormente, una desventaja de la ganancia es que favorece a los atributos que asumen un espectro muy alto de valores distintos con respecto a otros atributos. Un conjunto amplio y uniformemente distribuido de valores para el atributo no necesariamente es una característica que debería formar parte a la hora de determinar el mejor atributo para bifurcar.\n",
    "\n",
    "##### 2.3.3.2. Ratio de ganancia\n",
    "***\n",
    "Se define el **ratio de ganancia** de un atributo $a$ sobre una muestra $D$, en función de la **separación de información** de un atributo $a$ sobre una muestra $D$. Dichas definiciones son las siguientes:\n",
    "\n",
    "$$SeparacionDeInformacion(D,a) = - \\sum_{v \\in Val(a)}\\frac{|D_v|}{|D|} \\cdotp log_2(\\frac{|D_v|}{|D|})$$\n",
    "\n",
    "$$RatioGanancia(D,Aa) = \\frac{Ganancia(D,a)}{SeparacionDeInformacion(D,a)}$$\n",
    "\n",
    "La **separación de información** es sensible a que tan amplia y uniformemente el atributo distribuye sus datos, logrando así penalizar a los atributos que tomen un espectro muy amplio de valores. Una colección de ejemplos $D : |D| = n$ que estén completamente separados por un atributo $a_1$ (como una fecha) tendrá $SeparacionDeInformacion(D,a_1) = log_2(n)$. En cambio un atributo $a_2$ (booleano, por ejemplo) que divida los mismos $n$ ejemplos a la mitad tendrá $SeparacionDeInformacion(D,a_2) = 1$. Si ambos atributos producen la misma ganancia de información, entonces $a_2$ tendrá un **ratio de ganancia** más alto.\n",
    "\n",
    "Se observa que la **separación de información** es la entropía de $D$ respecto a los valores del atributo $a$ (a diferencia de tomarla con respecto a la clasificación).\n",
    "\n",
    "Una desventaja de usar el **ratio de ganancia** en lugar de sólo **ganancia** es que la **separación de información** puede ser 0, lo que hace el **ratio de ganancia** sea indefinido o muy grande para atributos que pueden tener el mismo valor para casi todos los miembros de $D$.\n",
    "\n",
    "##### 2.3.3.3. Reducción de \"impureza\"\n",
    "***\n",
    "Se define la **reducción de impureza** de un atributo $a$ sobre una muestra $D$, utilizando la **impureza Gini** (nombrada en honor a Conrado Gini) de una muestra $D$. Dichas definiciones son las siguientes:\n",
    "\n",
    "$$Gini(D) = 1 - \\sum p_{i}^2$$\n",
    "\n",
    "$$ReductionImpureza(D,a) = Gini(D) - \\sum_{v \\in Val(a)}\\frac{|D_v|}{|D|} \\cdotp Gini(D_v)$$\n",
    "\n",
    "La **impureza Gini**, nombrada por el matemático Corrado Gini, mide la homogeneidad de un conjunto de elementos, tomando un valor mínimo de 0.0 y un valor máximo acotado por 1.0.\n",
    "\n",
    "Dicha métrica toma valor 0 cuando todos los elementos del conjunto califican al mismo valor. En este contexto se dice que la **impureza** es mínima. A su vez si todos los valores del conjunto califican la misma cantidad de resultados distintos, se dice que la **impureza** es máxima (tomando un valor menor o igual a 1.0).\n",
    "\n",
    "A los efectos practicos de la construcción de **árboles de decisión**, durante la misma se desea bifurcar con atributos que reduzcan la **impureza** lo mayor posible posible (optando por atributos que califiquen la mayor cantidad de instancias en la misma clase).\n",
    "\n",
    "Una muy importante observación es que si bien la **impureza Gini** minimiza errores de clasificación y la **entropía** se usa para análisis exploratorio, ambas cumplen un rol casi idéntico. Usualmente, la **impureza Gini** da mejores resultados para atributos continuos mientras que la **entropía** funciona mejor con atributos discretos, sin embargo algunos estudios encontraron que sólo un 2% de las veces los resultados son distintos.\n",
    "\n",
    "Debido a que su efectividad es dependiente del problema, se decidió incluir reducción de impureza como parte de la configuración paramétrica. \n",
    "\n",
    "#### 2.3.4. Interpretación de valores continuos\n",
    "***\n",
    "Una característica clave para el escenario propuesto y que **ID3** no contempla es **el tratamiento de atributos continuos**. Se emplearon tres estrategias distintas para interpretar los valores de tales atributos, teniendo como fin las mismas, discretizar el espectro continuo en una pequeña cantidad de clases.\n",
    "\n",
    "Como noción general independiente a la estrategia implementada, cada clase discreta generada a partir de la estrategia en cuestión representa un **intervalo**. Los intervalos se definen por su **tope superior (máximo)**, excepto el último, que se define por su **tope inferior (mínimo)**\n",
    "\n",
    "Sea por ejemplo, la lista de intervalos $[v_0, ..., v_n, v_{n+1}]$, para cada valor $v_i : i \\in [0..n+1]$ se cumple lo siguiente:\n",
    "- El intervalo de $v_0$ representa \"todos los valores $k : k \\leq v_0$\".\n",
    "- El intervalo de $v_i : i \\in [1..n]$ representa \"todos los valores $k : v_{i-1} \\lt k \\leq v_i$\".\n",
    "- El intervalo de $v_{n+1}$ representa \"todos los valores $k : k \\gt v_{n+1}$\".\n",
    "\n",
    "Es importante mencionar que los últimos dos **valores** cumplen ser iguales ($v_n = v_{n+1}$), lo que cambia es lo que el intervalo representa.\n",
    "\n",
    "Habiendo visto esto, se resumen las estrategias implementadas:\n",
    "\n",
    "##### 2.3.4.1. Partir en intervalos fijos\n",
    "***\n",
    "Como primera estrategia, se determina la siguiente:\n",
    "- Sea $A_D =$ Conjunto de atributos en conjunto de datos $D$\n",
    "- Sea $a \\in A_D : Val(a) \\subseteq N, Z, R$ un atributo continuo\n",
    "- Sea $a^{*} \\in A_D : |Val(a^{*})| \\lt \\infty$ la discretización de un atributo continuo\n",
    "- Sea $\\mu_{a}$ la mediana de $Val(a)$ para los ejemplos en $D$\n",
    "- Entonces $Val(a^{*}) = \\{\\leq \\mu_{a}, \\gt \\mu_{a}\\}$\n",
    "\n",
    "En lenguaje natural, se generan dos intervalos: los valores menores o iguales a la mediana de los valores actuales, y los valores mayores a dicha mediana. Todo nuevo valor entra siempre en alguno de los dos intervalos.\n",
    "\n",
    "La fundamentación de tomar dos intervalos partidos por la mediana es que es una manera intuitiva de distribuir el atributo de forma \"pareja\" en el árbol. Por otra parte, la desventaja de esta estrategia está en que, además de no ser necesariamente el punto ideal de corte para la clasificación, el partir en solamente dos intervalos para atributos con múltiples valores puede terminar agrupando ejemplos e introduciendo ruido al conjunto de datos.\n",
    "\n",
    "##### 2.3.4.2. Partir en intervalos variables\n",
    "***\n",
    "Con el fin de mejorar el defecto del enfoque anterior se implementa la siguiente estrategia:\n",
    "- Sea $D_a =$ Conjunto de datos ordenado ascendentemente en base a atributo $a$\n",
    "- Sea $A_{D_a} =$ Conjunto de atributos en conjunto de datos $D_a$\n",
    "- Sea $a \\in A_{D_a} : Val(a) \\subseteq N, Z, R$ un atributo continuo\n",
    "- Sea $a^{*} \\in A_{D_a} : |Val(a^{*})| \\lt \\infty$ la discretización de un atributo continuo\n",
    "- Sea $v_i : v_i \\in Val(a)$ el valor de $a$ en el k-ésimo ejemplo $d_k \\in D_a$ tal que cambia su clasificación respecto a $d_{k-1}$\n",
    "- Entonces $Val(a^{*}) = \\{\\leq v_0, ..., \\leq v_n, \\gt v_n\\}$\n",
    "\n",
    "En lenguaje natural, se genera un número variable de intervalos. El procedimiento para generarlos es:\n",
    "1. Ordenar $D$ en base a $a$ (generando $D_a$).\n",
    "2. Iterar sobre $D_a$\n",
    "3. Almacenar en $Val(a^{*})$, el valor $v_i$ de $a$ en $d_k$, en el momento en que la clasificación cambia del ejemplo $d_{k-1}$ al ejemplo $d_k$.\n",
    "\n",
    "De esta forma, se tiene una cantidad de intervalos que relaciona el cambio en la clasificación del ejemplo con el cambio en el atributo $a$. Esta técnica impacta menos negativamente que la anterior en relación al ruido que introduce al recortar valores.\n",
    "\n",
    "No obstante, en conjuntos de datos muy grandes con valores de $a$ muy dispersos o con clasificaciones muy cambiantes, puede suceder que se genere una cantidad de intervalos cercana a la cantidad de valores originales. Este hecho atenta en contra de la idea de interpretar valores continuos y de construir árboles simples con pocas ramas. No solamente eso, si no que también impacta en el tiempo de entrenamiento.\n",
    "\n",
    "Teniendo esto en cuenta, se limitó la cantidad de posibles intervalos a 10, eligiendo 10 valores que se separan uniformemente en el conjunto total de intervalos.\n",
    "\n",
    "##### 2.3.4.3. Partir por el valor que maximice la ganancia\n",
    "***\n",
    "Basado en el algortimo C4.5, el algortimo sucesor de ID3, se implementa la siguiente estrategia:\n",
    "- Sea $D_a =$ Conjunto de datos ordenado ascendentemente en base a atributo $a$\n",
    "- Sea $A_{D_a} =$ Conjunto de atributos en conjunto de datos $D_a$\n",
    "- Sea $a \\in A_{D_a} : Val(a) \\subseteq N, Z, R$ un atributo continuo\n",
    "- Sea $a^{*} \\in A_{D_a} : |Val(a^{*})| \\lt \\infty$ la discretización de un atributo continuo\n",
    "- Sea $v_i : v_i \\in Val(a)$ el valor de $a$ en el k-ésimo ejemplo $d_k \\in D_a$ tal que cambia su clasificación respecto a $d_{k-1}$\n",
    "- Sea $Val(a') = \\{\\leq v_0, ..., \\leq v_n, \\gt v_n\\}$ los posibles valores determinados en la sección anterior\n",
    "- Entonces $Val(a^{*}) = \\{\\leq v_j, \\gt v_j\\} : v_j \\in Val(a')$ y se maximiza la ganancia de partir el conjunto de datos en $v_j$\n",
    "\n",
    "En lenguaje natural, se generan dos intervalos como en la sección 2.3.4.1 pero se parte de los valores tomados en la sección 2.3.4.2 y se determina cual de estos otorga una mayor ganancia.\n",
    "\n",
    "Una desventaja de esto es que es de un mayor orden computacional, requiriendo una recorrida del dataset para calcular la ganancia de cada punto de corte a probar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Evaluación\n",
    "***\n",
    "En la siguiente sección se centralizan todas las especificaciones relativas a la evaluación de los clasificadores entrenados.\n",
    "\n",
    "\n",
    "#### 2.4.1. Conjuntos de evaluación\n",
    "***\n",
    "Los dos conjuntos de datos a partir de los cuales se entrenó y evaluó los modelos son:\n",
    "- [**Conjunto *Iris*:**](https://archive.ics.uci.edu/ml/datasets/iris) El cual clasifica plantas del genero Iris (de la tribu Irideae, perteneciente a la familia Iridaceae) según especie. Cuenta con 150 ejemplos, 4 atributos de carácter continuo y 3 posibles clasificaciones.\n",
    "- [**Conjunto *Covertype*:**](https://archive.ics.uci.edu/ml/datasets/Covertype) El cual clasifica terrenos de bosques según atributos cartográficos. Cuenta con 581012 ejemplos,54 atributos, siendo 10 de carácter continuo y 44 de carácter binario (son el one hot encoding de 2 atributos generando 4 y 40 atributos respectivamente) y 7 posibles clasificaciones.\n",
    "\n",
    "Cabe destacar que el conjunto *Iris* cuenta con una cantidad ínfima de ejemplos, mientras que el conjunto *CoverType* va hacia el otro extremo. Las implicancias de estos hechos se tratan en la sección 3.\n",
    "\n",
    "#### 2.4.2. Métodos de evaluación\n",
    "***\n",
    "Se experimentó utilizando dos estrategias de evaluación, siendo las mismas:\n",
    "- Validación 80/20 (denominada \"normal\" a partir de ahora)\n",
    "- Validación cruzada con 10 particiones (denominada \"cruzada\" a partir de ahora)\n",
    "\n",
    "Ambas estrategias subdividen el conjunto de datos $D$ en dos subconjuntos, $T, E \\subset D$. El subconjunto $T$ se utiliza para entrenar al clasificador en cuestión, mientras que el subconjunto $E$ se utiliza para evaluar la eficacia del mismo. Esto se logra haciendo que el modelo entrenado clasifique los ejemplos del conjunto de evaluación $E$, comparando luego la clasificación original con la realizada. Dicha comparación se basa en distintas métricas, las cuales se tratan en la sub sección siguiente.\n",
    "\n",
    "Es importante destacar que, independiente al método de evaluación, el conjunto de datos $D$ original se mezcla de forma aleatoria antes de subdividirlo en $T$ y $E$. Esto es vital para evitar el mismo resultado en distintas evaluaciones.\n",
    "\n",
    "Si, por ejemplo, $D$ estuviera ordenado de forma tal que los últimos ejemplos en él (los que corresponderían a $E$) no agregan información nueva a $T$, entonces el desempeño del clasificador sería excelente. Por otra parte, si sucede lo contrario, el desempeño sería mucho peor. La mezcla al azar de $D$ se utiliza con el objetivo de reducir este fenómeno.\n",
    "\n",
    "A continuación se adjunta una breve descripción de los parámetros utilizados en cada método de evaluación.\n",
    "\n",
    "##### 2.4.2.1. Validación normal\n",
    "***\n",
    "Se denomina como **validación normal** a la partición única del conjunto $D$ en $T$ y $E$ utilizando una proporción donde $|T| \\lt |E|$.\n",
    "\n",
    "En general, dependiendo de la cantidad de ejemplos en $D$ y del objetivo que se quiera alcanzar, dicha partición sigue una relación 80/20, 85/15, 90/10, etc. Para el escenario actual, se determinó utilizar una partición 80/20, es decir, $T$ cuenta con el 80% de ejemplos en $D$, mientras que $E$ cuenta con el 20% restante.\n",
    "\n",
    "Es importante recordar el fenómeno mencionado en la subsección anterior. La validación normal, si bien parte al conjunto luego de haber sido reordenado aleatoriamente, puede verse afectada, por casualidad, por el fenómeno en cuestión. Con el objetivo de reducir esta posibilidad, se agrega el siguiente método\n",
    "\n",
    "##### 2.4.2.2. Validación cruzada\n",
    "***\n",
    "\n",
    "Se denomina como **validación cruzada** a la partición del conjunto $D$ en $k$ particiones $T_i$ y $E_i : i \\in [1..k]$,  utilizando una proporción $\\frac{k-1}{k}$ y $\\frac{1}{k}$ para $T_i$ y $E_i$ respectivamente.\n",
    "\n",
    "En lenguaje natural, la validación cruzada utiliza un parámetro $k$, generando $k$ particiones de $D$ siguiendo el método normal mencionado en la anterior sub sección. Esto se hace con el objetivo de evitar el sobreajuste en subconjuntos $T \\subset D$ específicos. Una vez se hacen las $k$ evaluaciones, se promedian las métricas obtenidas para obtener una mejor noción del desempeño del modelo.\n",
    "\n",
    "Esta estrategia es más robusta que la **validación normal** anteriormente mencionada, sin embargo tiene el problema de tener un mayor orden computacional, dado que tiene que correr $k$ entrenamientos en lugar de uno.\n",
    "\n",
    "En la experimentación se decidió fijar $k=10$.\n",
    "\n",
    "#### 2.4.3. Métricas de evaluación\n",
    "***\n",
    "Se utilizaron múltiples métricas para determinar la \"calidad\" o \"eficacia\" de los clasificadores entrenados. A continuación, una breve descripción de las mismas:\n",
    "\n",
    "##### 2.4.3.1 Accuracy\n",
    "***\n",
    "La **accuracy** o **exactitud** hace referencia a la cantidad de aciertos que el clasificador tuvo en relación al total de clasificaciones que realizó durante la evaluación. Para definir **accuracy**, se utilizan las siguientes nociones:\n",
    "- Sea $D$ el conjunto de datos, $C_D$ el conjunto de posibles clasificaciones en $D$ y $|C_D| = n$\n",
    "- Sea $t_i : i \\in [1..n]$ la cantidad de clasificaciones para la clase $i$ que fueron correctas\n",
    "- Sea $f_i : i \\in [1..n]$ la cantidad de clasificaciones para la clase $i$ que fueron incorrectas\n",
    "\n",
    "$$ accuracy = \\frac{\\sum_{i=1}^{n} t_i}{\\sum_{i=1}^{n} t_i + f_i}$$\n",
    "\n",
    "Se observa que **accuracy** no es una muy buena medida de performance, ya que depende mucho del conjunto de datos que se evalúe, pudiendo dar buenos resultados a un clasificador malo. Teniendo esto en cuenta, se utilizó esta métrica solo para tener una noción general del desempeño de un clasificador, dandole más peso a las métricas definidas a continuación.\n",
    "\n",
    "##### 2.4.3.2 Matriz de Confusión\n",
    "***\n",
    "La **matriz de confusión** es una matriz que permite almacenar todas las clasificaciones realizadas en una evaluación, basándose en cada resultado y su respectivo valor original. La estructura de la matriz es la siguiente:\n",
    "\n",
    "- Sea $D =$ Conjunto de datos\n",
    "- Sea $C_D =$ Conjunto de clasificaciones para $d \\in D$ \n",
    "- Sea $|C_D| = n$ cantidad de posibles clasificaciones en $C_D$\n",
    "- Sea $M$ la matriz de confusión para una evaluación definida como:\n",
    "\n",
    "$$M = \\begin{bmatrix}\n",
    "    x_{11} & x_{12} & \\dots  & x_{1n} \\\\\n",
    "    x_{21} & x_{22} & \\dots  & x_{2n} \\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    x_{n1} & x_{n2} & \\dots  & x_{nn}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "- Entonces $x_{ij} \\in M : i,j \\in [1..n]$ representa la cantidad de clasificaciones que originalmente eran **clase $i$** y que fueron clasificadas en la evaluación como **clase $j$**.\n",
    "\n",
    "De esta forma, en una matriz cuadrada de dimensión $n$, se pueden centralizar todas las clasificaciones realizadas y su relación con respecto a cada clase.\n",
    "\n",
    "En sí misma, la matriz de confusión no representa una métrica sino una herramienta para calcular otras métricas, las cuales serán detalladas a continuación. De todas formas, una matriz de confusión de tamaño razonable puede aportar información general sobre el desempeño del clasificador, sólo con mirarla por arriba (en la siguiente sub sección se detalla como).\n",
    "\n",
    "##### 2.4.3.3 Precision, Recall, Fall-off, F-measure\n",
    "***\n",
    "Existen cuatro medidas que, si bien siguen una fórmula similar a la de **accuracy**, son mucho menos sensibles al ruido en el conjunto de datos $D$, ya que operan **por clase**. Antes de detallar cada una, se repasan ciertas nociones básicas utilizadas en la definición de cada métrica.\n",
    "\n",
    "Retomando el punto anterior, la matriz de confusión permite calcular para cada clase $c_i$, cuatro valores indispensables:\n",
    "- Los **verdaderos positivos** en la clase $c_i$ (denotados como $t_i$), son aquellos ejemplos que originalmente son clase $c_i$ y fueron clasificados correctamente en la evaluación como clase $c_i$. Para calcularlos utilizando la matriz de confusión, simplemente hay que tomar la celda $M(i,i)$ para la clase $c_i$.\n",
    "\n",
    "$$ t_i = M(i,i) $$\n",
    "\n",
    "- Los **falsos positivos** en la clase $c_i$ (denotados como $f_i$), son aquellos ejemplos que originalmente son clase $c_j : j \\neq i$ y fueron clasificados incorrectamente en la evaluación como clase $c_i$. Para calcularlos utilizando la matriz de confusión, simplemente hay que tomar la fila $M_{(i,)}$ para la clase $c_i$, y sumar todos sus valores (excepto la celda $M(i,i)$, que corresponde a los verdaderos positivos).\n",
    "\n",
    "$$ f_i = \\sum_{j=1, j \\neq i}^{n} M(i,j) $$\n",
    "\n",
    "- Los **verdaderos negativos** en la clase $c_i$ (denotados como $\\bar{t_i}$), son aquellos ejemplos que originalmente no son clase $c_i$ y fueron clasificados en la evaluación como clase $c_j : j \\neq i$. Cabe destacar que la clasificación como $c_j$ puede ser correcta o no, lo importante es que sea consistente en relación a $c_i$. Para calcularlos utilizando la matriz de confusión, simplemente hay que tomar la matriz adjunta a los verdaderos positivos de $c_i$ y sumar todas sus entradas. Dicha matriz se define como $M_{ii}$ y contiene todas las entradas de $M$ excepto la fila $i$ y la columna $i$.\n",
    "\n",
    "$$ \\bar{t_i} = \\sum_{j=1}^{n-1} \\sum_{k=1}^{n-1} M_{ii}(j,k) $$\n",
    "\n",
    "- Los **falsos negativos** en la clase $c_i$ (denotados como $\\bar{f_i}$), son aquellos ejemplos que originalmente son clase $c_i$ y fueron clasificados incorrectamente en la evaluación como clase $c_j : j \\neq i$. Para calcularlos utilizando la matriz de confusión, simplemente hay que tomar la columna $M_{(,i)}$ para la clase $c_i$, y sumar todos sus valores (excepto la celda $M(i,i)$, que corresponde a los verdaderos positivos).\n",
    "\n",
    "$$ \\bar{f_i} = \\sum_{j=1, j \\neq i}^{n} M(j,i) $$\n",
    "\n",
    "Teniendo en cuenta dichas definiciones, se pasa a definir las métricas utilizadas:\n",
    "- **Precision**\n",
    "> - La **precision** de una **clase $c_i$** hace referencia a la cantidad de clasificaciones correctas para dicha clase, en relación a la cantidad de clasificaciones totales (correctas e incorrectas) para dicha clase.\n",
    "> - La precision permite determinar \"que tan bien se clasifica una clase\". En otras palabras, que tan poco se equivoca el clasificador en marcar un ejemplo como cierta clase.\n",
    "> - Oscila entre 0 y 1, siendo mejor cuanto **mayor** es.\n",
    "> - Se calcula como:\n",
    "> $$ precision(c_i) = \\frac{t_i}{t_i + f_i}$$\n",
    "\n",
    "- **Recall**\n",
    "> - La **recall** de una **clase $c_i$** hace referencia a la cantidad de clasificaciones correctas para dicha clase, en relación a la cantidad de clasificaciones originales para dicha clase.\n",
    "> - La recall permite determinar \"que tan bien se clasifican elementos de otras clases respecto a una clase\". En otras palabras, que tan poco se equivoca el clasificador en marcar un ejemplo de otras clases como cierta clase.\n",
    "> - Oscila entre 0 y 1, siendo mejor cuanto **mayor** es.\n",
    "> - Se calcula como:\n",
    "> $$ recall(c_i) = \\frac{t_i}{t_i + \\bar{f_i}}$$\n",
    "\n",
    "- **Fall-off**\n",
    "> - La **fall-off** de una **clase $c_i$** hace referencia a la cantidad de clasificaciones incorrectas para dicha clase, en relación a la cantidad de clasificaciones complemento (correctas e incorrectas) de dicha clase.\n",
    "> - La fall-off permite determinar \"que tan mal se clasifica una clase\". En otras palabras, es la noción inversa de la recall: cuantos más ejemplos de otra clase sean clasificados como clase $c_i$, más aumenta fall-off.\n",
    "> - Oscila entre 0 y 1, siendo mejor cuanto **menor** es.\n",
    "> - Se calcula como:\n",
    "> $$ falloff(c_i) = \\frac{f_i}{f_i + \\bar{t_i}}$$\n",
    "\n",
    "- **F-measure**\n",
    "> - La **F-measure** de una **clase $c_i$** es una medida que relaciona **precision** y **recall**, oficiando de alguna forma como un representante de cierta clase.\n",
    "> - La F-measure permite determinar \"que tan bien se clasifica una clase y que tan poco se falla a la vez\". En otras palabras, es una relación proporcional entre la precision y la recall y por tanto es una buena métrica para determinar el desempeño del clasificador respecto a una clase.\n",
    "> - Oscila entre 0 y 1, siendo mejor cuanto **mayor** es.\n",
    "> - Se calcula como:\n",
    "> $$ Fmeasure(c_i) = \\frac{2 precision(c_i) recall(c_i)}{precision(c_i) + recall(c_i)}$$\n",
    "\n",
    "Si bien estas medidas ofrecen información más enriquecedora en comparación a las anteriormente mencionadas, cuentan con el \"defecto\" de aplicar por clase y no dar una medida general del clasificador. Para conjuntos $D$ con pocas clasificaciones en $C_D$ esto no es un gran problema, pero complica la comparación al aumentar la cantidad de clases. En la siguiente sub sección se tratan métricas que tienen como objetivo mejorar este hecho.\n",
    "\n",
    "##### 2.4.3.4 Medidas macro y micro\n",
    "***\n",
    "Existen dos formas genéricas de establecer medidas representativas para un modelo sin importar la clase. En este escenario se implementaron ambas formas, siendo las siguientes:\n",
    "\n",
    "- **Promedios genéricos** \n",
    "> - El promedio genérico de una métrica dada consiste en la suma de las métricas para cada clase dividida por la cantidad de clases.\n",
    "> - Otorga una noción del desempeño general del clasificador en relación a la métrica dada. \n",
    "> - Sea $D$ el conjunto de datos\n",
    "> - Sea $C_D$ el conjuntos de posibles clases\n",
    "> - Sea $|C_D| = n$\n",
    "> - El promedio genérico se calcula como:\n",
    "> $$ metrica_{general} = \\frac{\\sum_{i=1}^{n} metrica(c_i)}{n}$$\n",
    "\n",
    "- **Promedios ponderados:**\n",
    "> - El promedio ponderado de una métrica dada consiste en la suma de las métricas para cada clase ponderada por la proporción de ejemplos en el conjunto de datos para dicha clase.\n",
    "> - Otorga una noción del desempeño del clasificador en relación a la métrica dada, ignorando el ruido generado por mal desempeño en clases con menor cantidad de ejemplos (en otras palabras, es particularmente útil ante conjuntos de datos con una distribución nada uniforme en las clasificaciones de sus ejemplos).\n",
    "> - Sea $D$ el conjunto de datos\n",
    "> - Sea $C_D$ el conjuntos de posibles clases\n",
    "> - Sea $|C_D| = n$\n",
    "> - Sea $c_i \\in C_D$ la i-ésima clase en $C_D$\n",
    "> - Sea $D_i \\subseteq D$ el conjunto de ejemplos clasificados con clase $c_i$\n",
    "> - El promedio ponderado se calcula como:\n",
    "> $$ metrica_{ponderada} = \\sum_{i=1}^{n} metrica(c_i) * \\frac{|D_i|}{|D|}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experimentación\n",
    "***\n",
    "En esta sección se detalla el conjunto de pruebas realizadas, agregandose observaciones pertinentes y comparaciones entre modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Metodología\n",
    "***\n",
    "\n",
    "Con el objetivo de evaluar las estrategias planteadas anteriormente y su efectividad, se probaron combinaciones de las mismas frente a los dos modelos desarrollados. La exprimentación se encaró diviendola en las siguientes etapas:\n",
    "\n",
    "1. **Recopilación y ajuste:** Si bien las configuraciones paramétricas y otras opciones generales eran conocidas desde una etapa bastante temprana, hubo ciertos cambios realizados a ensayo y error antes de llegar a un algoritmo óptimo. En esta sub sección se repasa brevemente el proceso de construcción previo a la evaluación de modelos terminados.\n",
    "<br><br>\n",
    "2. **Configuraciones paramétricas:** Luego de llegar a un modelo relativamente libre de errores (al menos de errores identificados), se realizaron pruebas para múltiples configuraciones paramétricas, con el fin de comparar cuales de ellas resultaron en mejores clasificadores. En esta etapa se detallan los datos obtenidos. \n",
    "<br><br>\n",
    "3. **Elección y comparación de representantes:** A falta de suficientes corridas para generar agrupamientos de configuraciones, se compararon manualmente los resultados obtenidos en las pruebas de cada configuración paramétrica de la etapa anterior. En base a distintas métricas, se eligió a aquellos clasificadores con mejores y peores resultados, interpretando la razón de su eficacia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Recopilación y ajuste\n",
    "***\n",
    "\n",
    "Aca hablo yo de como llegamos al algoritmo base que funca\n",
    "\n",
    "- Primera version: Covertype no termina\n",
    "- Segunda version: Optimización de loops, poda. Iris parece sobreajustar menos pero Covertype no termina. \n",
    "- Tercera version: Optimización de pandas y loops, eliminación de poda. Iris funciona como antes y Covertype termina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Configuraciones paramétricas\n",
    "***\n",
    "A continuación se \n",
    "\n",
    "Es importante destacar que a causa de el tamaño del conjunto *Covertype*, no fue posible probar todas las configuraciones paramétricas para el mismo. De hecho, todas las configuraciones que tratan atributos continuos como **intervalos variables** fueron omitidas, ya que el árbol crecía exponencialmente, creciendo también de esta forma el tiempo de entrenamiento.\n",
    "\n",
    "#### 3.3.1. Evaluaciones\n",
    "***\n",
    "Acá hablo yo\n",
    "\n",
    "##### 3.3.1.1 Conjuntos de datos\n",
    "***\n",
    "Iris y Covertype (2 opciones) Acá hablo yo\n",
    "\n",
    "##### 3.3.1.2 Modelos\n",
    "***\n",
    "Árbol y Bosque (2 opciones)\n",
    "\n",
    "##### 3.3.1.3 Parámetros\n",
    "***\n",
    "Fijo, Variable, C45 (3 opciones)\n",
    "Ganancia, Ratio de Ganancia, Reducción de Impureza (3 opciones)\n",
    "Acá hablo yo\n",
    "\n",
    "#### 3.3.2. Resultados\n",
    "***\n",
    "Acá hablo yo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.3.1. Resultados por clasificador\n",
    "***\n",
    "Introducción\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style=\"text-align: center;\">Seleccione un caso para visualizar de la botonera</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descripción: Arbol del conjunto CoverType, Impurity Reduction como medida, atributos continuos partiendo en intervalos fijos. Validación 80/20\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><strong>Accuracy</strong>: 0.6332452690550158</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "         <div>           <style type=\"text/css\">           .tg  {border-collapse:collapse;border-spacing:0;}           .tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}           .tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}           .tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}           </style>           <table class=\"tg\">             <tr>               <th class=\"tg-0pky\"><strong>Precision mean</strong></th>               <th class=\"tg-0pky\"><strong>Recall mean</strong></th>               <th class=\"tg-0pky\"><strong>Fall-off mean</strong></th>               <th class=\"tg-0pky\"><strong>F-Measure mean</strong></th>             </tr>             <tr>               <td class=\"tg-0pky\">0.6194090931568439</td>               <td class=\"tg-0pky\">0.3897701475208352</td>               <td class=\"tg-0pky\">0.07539815665118833</td>               <td class=\"tg-0pky\">0.436657119747169</td>             </tr>           </table>         </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "         <div>           <style type=\"text/css\">           .tg  {border-collapse:collapse;border-spacing:0;}           .tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}           .tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}           .tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}           </style>           <table class=\"tg\">             <tr>               <th class=\"tg-0pky\"><strong>Precision weighted mean</strong></th>               <th class=\"tg-0pky\"><strong>Recall weighted mean</strong></th>               <th class=\"tg-0pky\"><strong>Fall-off weighted mean</strong></th>               <th class=\"tg-0pky\"><strong>F-Measure weighted mean</strong></th>             </tr>             <tr>               <td class=\"tg-0pky\">0.6333075002469789</td>               <td class=\"tg-0pky\">0.6332452690550158</td>               <td class=\"tg-0pky\">0.22536442428117898</td>               <td class=\"tg-0pky\">0.6178587956015554</td>             </tr>           </table>         </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>Matriz de confusión</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>X</td><td style=\"text-align: right;\">    1</td><td style=\"text-align: right;\">    2</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">  4</td><td style=\"text-align: right;\">  5</td><td style=\"text-align: right;\">  6</td><td style=\"text-align: right;\">  7</td></tr>\n",
       "<tr><td>1</td><td style=\"text-align: right;\">24470</td><td style=\"text-align: right;\">17605</td><td style=\"text-align: right;\">   4</td><td style=\"text-align: right;\">  0</td><td style=\"text-align: right;\">  6</td><td style=\"text-align: right;\">  9</td><td style=\"text-align: right;\">126</td></tr>\n",
       "<tr><td>2</td><td style=\"text-align: right;\">12413</td><td style=\"text-align: right;\">43047</td><td style=\"text-align: right;\"> 742</td><td style=\"text-align: right;\"> 10</td><td style=\"text-align: right;\">105</td><td style=\"text-align: right;\">183</td><td style=\"text-align: right;\">136</td></tr>\n",
       "<tr><td>3</td><td style=\"text-align: right;\">    1</td><td style=\"text-align: right;\"> 2449</td><td style=\"text-align: right;\">4311</td><td style=\"text-align: right;\"> 94</td><td style=\"text-align: right;\">  4</td><td style=\"text-align: right;\">366</td><td style=\"text-align: right;\">  0</td></tr>\n",
       "<tr><td>4</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">   13</td><td style=\"text-align: right;\"> 308</td><td style=\"text-align: right;\">179</td><td style=\"text-align: right;\">  0</td><td style=\"text-align: right;\"> 84</td><td style=\"text-align: right;\">  0</td></tr>\n",
       "<tr><td>5</td><td style=\"text-align: right;\">  173</td><td style=\"text-align: right;\"> 1467</td><td style=\"text-align: right;\">  45</td><td style=\"text-align: right;\">  0</td><td style=\"text-align: right;\">205</td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\">  1</td></tr>\n",
       "<tr><td>6</td><td style=\"text-align: right;\">    3</td><td style=\"text-align: right;\"> 1303</td><td style=\"text-align: right;\">1125</td><td style=\"text-align: right;\"> 42</td><td style=\"text-align: right;\">  5</td><td style=\"text-align: right;\">895</td><td style=\"text-align: right;\">  0</td></tr>\n",
       "<tr><td>7</td><td style=\"text-align: right;\"> 1272</td><td style=\"text-align: right;\"> 2523</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">  0</td><td style=\"text-align: right;\">  0</td><td style=\"text-align: right;\">  0</td><td style=\"text-align: right;\">478</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>Métricas</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>X</td><td>Precision         </td><td>Recall             </td><td>Fall-off             </td><td>F-Measure          </td></tr>\n",
       "<tr><td>1</td><td>0.6383700302619222</td><td>0.5795831359545239 </td><td>0.15111246770518788  </td><td>0.607557850829278  </td></tr>\n",
       "<tr><td>2</td><td>0.6292777054979753</td><td>0.7600642700755703 </td><td>0.34665646016731366  </td><td>0.6885151507881289 </td></tr>\n",
       "<tr><td>3</td><td>0.6596786534047437</td><td>0.5966782006920415 </td><td>0.019876309298251887 </td><td>0.6265988372093023 </td></tr>\n",
       "<tr><td>4</td><td>0.5507692307692308</td><td>0.3065068493150685 </td><td>0.0012583603392401573</td><td>0.3938393839383938 </td></tr>\n",
       "<tr><td>5</td><td>0.6307692307692307</td><td>0.1083509513742072 </td><td>0.001034500594837842 </td><td>0.1849345963013081 </td></tr>\n",
       "<tr><td>6</td><td>0.581924577373212 </td><td>0.2653424251408242 </td><td>0.005576369375932286 </td><td>0.3644878843412747 </td></tr>\n",
       "<tr><td>7</td><td>0.6450742240215924</td><td>0.11186520009361105</td><td>0.0022726290775545474</td><td>0.19066613482249703</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85fe10b7b6ec4941943d10ee9aa6b3a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Box(children=(Button(button_style='warning', description='1', layout=Layout(margin='0px 16px 0px…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "         <div>           <style type=\"text/css\">           .tg  {border-collapse:collapse;border-spacing:0;}           .tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}           .tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}           .tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}           </style>           <table class=\"tg\">             <tr>               <th class=\"tg-0pky\"><strong>Botón</strong></th>               <th class=\"tg-0pky\" style=\"text-align: center;\"><strong>Descripción</strong></th>             </tr>             <tr>               <td class=\"tg-0pky\">1</td>               <td class=\"tg-0pky\">Arbol del conjunto Iris, Ganancia como medida, atributos continuos partiendo en intervalos fijos. Validación cruzada .</td>             </tr>             <tr>               <td class=\"tg-0pky\">2</td>               <td class=\"tg-0pky\">Arbol del conjunto Iris, GainRatio como medida, trata atributos continuos partiendo en intervalos fijos. Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">3</td>               <td class=\"tg-0pky\">Arbol del conjunto Iris, Impurity Reduction como medida, atributos continuos partiendo en intervalos fijos. Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">4</td>               <td class=\"tg-0pky\">Arbol del conjunto Iris, Ganancia como medida, atributos continuos partiendo en intervalos variables. Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">5</td>               <td class=\"tg-0pky\">Arbol del conjunto Iris, GainRatio como medida, atributos continuos partiendo en intervalos variables. Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">6</td>               <td class=\"tg-0pky\">Arbol del conjunto Iris, Impurity Reduction como medida, atributos continuos partiendo en intervalos variables. Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">7</td>               <td class=\"tg-0pky\">Arbol del conjunto Iris, Ganancia como medida, atributos continuos maximizando ganancia local (C4.5). Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">8</td>               <td class=\"tg-0pky\">Arbol del conjunto Iris, GainRatio como medida, atributos continuos maximizando ganancia local (C4.5). Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">9</td>               <td class=\"tg-0pky\">Arbol del conjunto Iris, Impurity Reduction como medida, atributos continuos maximizando ganancia local (C4.5). Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">10</td>               <td class=\"tg-0pky\">Bosque del conjunto Iris, Ganancia como medida, atributos continuos partiendo en intervalos fijos. Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">11</td>               <td class=\"tg-0pky\">Bosque del conjunto Iris, GainRatio como medida, atributos continuos partiendo en intervalos fijos. Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">12</td>               <td class=\"tg-0pky\">Bosque del conjunto Iris, Impurity Reduction como medida, atributos continuos partiendo en intervalos fijos. Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">13</td>               <td class=\"tg-0pky\">Bosque del conjunto Iris, Ganancia como medida, atributos continuos partiendo en intervalos variables. Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">14</td>               <td class=\"tg-0pky\">Bosque del conjunto Iris, GainRatio como medida, atributos continuos partiendo en intervalos variables. Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">15</td>               <td class=\"tg-0pky\">Bosque del conjunto Iris, Impurity Reduction como medida, atributos continuos partiendo en intervalos variables. Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">16</td>               <td class=\"tg-0pky\">Bosque del conjunto Iris, Ganancia como medida, atributos continuos maximizando ganancia local (C4.5). Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">17</td>               <td class=\"tg-0pky\">Bosque del conjunto Iris, GainRatio como medida, atributos continuos maximizando ganancia local (C4.5). Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">18</td>               <td class=\"tg-0pky\">Bosque del conjunto Iris, Impurity Reduction como medida, atributos continuos maximizando ganancia local (C4.5). Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">a</td>               <td class=\"tg-0pky\">Arbol del conjunto CoverType, Ganancia como medida, atributos continuos partiendo en intervalos fijos. Validación 80/20.</td>             </tr>             <tr>               <td class=\"tg-0pky\">b</td>               <td class=\"tg-0pky\">Arbol del conjunto CoverType, GainRatio como medida, atributos continuos partiendo en intervalos fijos. Validación 80/20</td>             </tr>             <tr>               <td class=\"tg-0pky\">c</td>               <td class=\"tg-0pky\">Arbol del conjunto CoverType, Impurity Reduction como medida, atributos continuos partiendo en intervalos fijos. Validación 80/20</td>             </tr>             <tr>               <td class=\"tg-0pky\">d</td>               <td class=\"tg-0pky\">Arbol del conjunto CoverType, Ganancia como medida, atributos continuos maximizando ganancia local (C4.5). Validación 80/20</td>             </tr>             <tr>               <td class=\"tg-0pky\">e</td>               <td class=\"tg-0pky\">Arbol del conjunto CoverType, GainRatio como medida, atributos continuos maximizando ganancia local (C4.5). Validación 80/20</td>             </tr>             <tr>               <td class=\"tg-0pky\">f</td>               <td class=\"tg-0pky\">Arbol del conjunto CoverType, Impurity Reduction como medida, atributos continuos maximizando ganancia local (C4.5). Validación 80/20</td>             </tr>             <tr>               <td class=\"tg-0pky\">g</td>               <td class=\"tg-0pky\">Bosque del conjunto CoverType, Ganancia como medida, atributos continuos partiendo en intervalos fijos. Validación 80/20</td>             </tr>             <tr>               <td class=\"tg-0pky\">h</td>               <td class=\"tg-0pky\">Bosque del conjunto CoverType, GainRatio como medida, atributos continuos partiendo en intervalos fijos. Validación 80/20</td>             </tr>             <tr>               <td class=\"tg-0pky\">i</td>               <td class=\"tg-0pky\">Bosque del conjunto CoverType, Impurity Reduction como medida, atributos continuos partiendo en intervalos fijos. Validación 80/20</td>             </tr>             <tr>               <td class=\"tg-0pky\">j</td>               <td class=\"tg-0pky\">Bosque del conjunto CoverType, Ganancia como medida, atributos continuos maximizando ganancia local (C4.5). Validación 80/20</td>             </tr>             <tr>               <td class=\"tg-0pky\">k</td>               <td class=\"tg-0pky\">Bosque del conjunto CoverType, GainRatio como medida, atributos continuos maximizando ganancia local (C4.5). Validación 80/20</td>             </tr>             <tr>               <td class=\"tg-0pky\">l</td>               <td class=\"tg-0pky\">Bosque del conjunto CoverType, Impurity Reduction como medida, atributos continuos maximizando ganancia local (C4.5). Validación 80/20</td>             </tr>           </table>         </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import getConfusionMatrix.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.3.2. Resultados generales\n",
    "***\n",
    "\n",
    "Introducción\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Modelo</th>\n",
    "        <th>Continuos</th>\n",
    "        <th>Medida</th>\n",
    "        <th>|</th>\n",
    "        <th>Accuracy</th>\n",
    "        <th>Precision promediada</th>\n",
    "        <th>Precision ponderada</th>\n",
    "        <th>Recall promediada</th>\n",
    "        <th>Recall ponderada</th>\n",
    "        <th>Fall-off promediada</th>\n",
    "        <th>Fall-off ponderada</th>\n",
    "        <th>F-measure promediada</th>\n",
    "        <th>F-measure ponderada</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Árbol</td>\n",
    "        <td>Fijo</td>\n",
    "        <td>Ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.873</td>\n",
    "        <td>0.884</td>\n",
    "        <td>0.898</td>\n",
    "        <td>0.889</td>\n",
    "        <td>0.873</td>\n",
    "        <td>0.059</td>\n",
    "        <td>0.060</td>\n",
    "        <td>0.873</td>\n",
    "        <td>0.875</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Árbol</td>\n",
    "        <td>Fijo</td>\n",
    "        <td>Ratio de Ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.893</td>\n",
    "        <td>0.897</td>\n",
    "        <td>0.923</td>\n",
    "        <td>0.906</td>\n",
    "        <td>0.893</td>\n",
    "        <td>0.051</td>\n",
    "        <td>0.048</td>\n",
    "        <td>0,879</td>\n",
    "        <td>0,893</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Árbol</td>\n",
    "        <td>Fijo</td>\n",
    "        <td>Reducción de Impureza</td>\n",
    "        <td>|</td>\n",
    "        <td>0.886</td>\n",
    "        <td>0.880</td>\n",
    "        <td>0.920</td>\n",
    "        <td>0.905</td>\n",
    "        <td>0.886</td>\n",
    "        <td>0.050</td>\n",
    "        <td>0.039</td>\n",
    "        <td>0,872</td>\n",
    "        <td>0,888</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Árbol</td>\n",
    "        <td>Variable</td>\n",
    "        <td>Ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.906</td>\n",
    "        <td>0.918</td>\n",
    "        <td>0.926</td>\n",
    "        <td>0.912</td>\n",
    "        <td>0.906</td>\n",
    "        <td>0.046</td>\n",
    "        <td>0.047</td>\n",
    "        <td>0,903</td>\n",
    "        <td>0,906</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Árbol</td>\n",
    "        <td>Variable</td>\n",
    "        <td>Ratio de Ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.933</td>\n",
    "        <td>0.939</td>\n",
    "        <td>0.944</td>\n",
    "        <td>0.938</td>\n",
    "        <td>0.933</td>\n",
    "        <td>0.033</td>\n",
    "        <td>0.037</td>\n",
    "        <td>0,932</td>\n",
    "        <td>0,933</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Árbol</td>\n",
    "        <td>Variable</td>\n",
    "        <td>Reducción de Impureza</td>\n",
    "        <td>|</td>\n",
    "        <td>0.920</td>\n",
    "        <td>0.931</td>\n",
    "        <td>0.947</td>\n",
    "        <td>0.932</td>\n",
    "        <td>0.920</td>\n",
    "        <td>0.037</td>\n",
    "        <td>0.030</td>\n",
    "        <td>0,917</td>\n",
    "        <td>0,919</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #95dcd4;\">\n",
    "        <td>Árbol</td>\n",
    "        <td>Maximizando ganancia</td>\n",
    "        <td>Ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.953</td>\n",
    "        <td>0.958</td>\n",
    "        <td>0.964</td>\n",
    "        <td>0.950</td>\n",
    "        <td>0.953</td>\n",
    "        <td>0.022</td>\n",
    "        <td>0.019</td>\n",
    "        <td>0,948</td>\n",
    "        <td>0,953</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Árbol</td>\n",
    "        <td>Maximizando ganancia</td>\n",
    "        <td>Ratio de ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.946</td>\n",
    "        <td>0.953</td>\n",
    "        <td>0.955</td>\n",
    "        <td>0.950</td>\n",
    "        <td>0.946</td>\n",
    "        <td>0.026</td>\n",
    "        <td>0.025</td>\n",
    "        <td>0,946</td>\n",
    "        <td>0,946</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #95dcd4;\">\n",
    "        <td>Árbol</td>\n",
    "        <td>Maximizando ganancia</td>\n",
    "        <td>Reducción de Impureza</td>\n",
    "        <td>|</td>\n",
    "        <td>0.953</td>\n",
    "        <td>0.954</td>\n",
    "        <td>0.957</td>\n",
    "        <td>0.952</td>\n",
    "        <td>0.953</td>\n",
    "        <td>0.023</td>\n",
    "        <td>0.025</td>\n",
    "        <td>0,951</td>\n",
    "        <td>0,953</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bosque</td>\n",
    "        <td>Fijo</td>\n",
    "        <td>Ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.913</td>\n",
    "        <td>0.930</td>\n",
    "        <td>0.932</td>\n",
    "        <td>0.905</td>\n",
    "        <td>0.913</td>\n",
    "        <td>0.044</td>\n",
    "        <td>0.046</td>\n",
    "        <td>0,906</td>\n",
    "        <td>0,912</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bosque</td>\n",
    "        <td>Fijo</td>\n",
    "        <td>Ratio de Ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.906</td>\n",
    "        <td>0.909</td>\n",
    "        <td>0.925</td>\n",
    "        <td>0.903</td>\n",
    "        <td>0.906</td>\n",
    "        <td>0.045</td>\n",
    "        <td>0.044</td>\n",
    "        <td>0,892</td>\n",
    "        <td>0,905</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bosque</td>\n",
    "        <td>Fijo</td>\n",
    "        <td>Reducción de Impureza</td>\n",
    "        <td>|</td>\n",
    "        <td>0.906</td>\n",
    "        <td>0.913</td>\n",
    "        <td>0.934</td>\n",
    "        <td>0.918</td>\n",
    "        <td>0.906</td>\n",
    "        <td>0.042</td>\n",
    "        <td>0.034</td>\n",
    "        <td>0,900</td>\n",
    "        <td>0,908</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bosque</td>\n",
    "        <td>Variable</td>\n",
    "        <td>Ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.913</td>\n",
    "        <td>0.904</td>\n",
    "        <td>0.932</td>\n",
    "        <td>0.915</td>\n",
    "        <td>0.913</td>\n",
    "        <td>0.040</td>\n",
    "        <td>0.035</td>\n",
    "        <td>0,900</td>\n",
    "        <td>0,915</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bosque</td>\n",
    "        <td>Variable</td>\n",
    "        <td>Ratio de Ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.900</td>\n",
    "        <td>0.908</td>\n",
    "        <td>0.914</td>\n",
    "        <td>0.903</td>\n",
    "        <td>0.900</td>\n",
    "        <td>0.047</td>\n",
    "        <td>0.046</td>\n",
    "        <td>0,898</td>\n",
    "        <td>0,899</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bosque</td>\n",
    "        <td>Variable</td>\n",
    "        <td>Reducción de Impureza</td>\n",
    "        <td>|</td>\n",
    "        <td>0.880</td>\n",
    "        <td>0.869</td>\n",
    "        <td>0.897</td>\n",
    "        <td>0.882</td>\n",
    "        <td>0.880</td>\n",
    "        <td>0.056</td>\n",
    "        <td>0.056</td>\n",
    "        <td>0,866</td>\n",
    "        <td>0,881</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bosque</td>\n",
    "        <td>Maximizando ganancia</td>\n",
    "        <td>Ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.946</td>\n",
    "        <td>0.945</td>\n",
    "        <td>0.953</td>\n",
    "        <td>0.950</td>\n",
    "        <td>0.946</td>\n",
    "        <td>0.025</td>\n",
    "        <td>0.024</td>\n",
    "        <td>0,944</td>\n",
    "        <td>0,946</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bosque</td>\n",
    "        <td>Maximizando ganancia</td>\n",
    "        <td>Ratio de ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.927</td>\n",
    "        <td>0.919</td>\n",
    "        <td>0.941</td>\n",
    "        <td>0.915</td>\n",
    "        <td>0.926</td>\n",
    "        <td>0.038</td>\n",
    "        <td>0.042</td>\n",
    "        <td>0,906</td>\n",
    "        <td>0,926</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #afdb99;\">\n",
    "        <td>Bosque</td>\n",
    "        <td>Maximizando ganancia</td>\n",
    "        <td>Reducción de Impureza</td>\n",
    "        <td>|</td>\n",
    "        <td>0.960</td>\n",
    "        <td>0.965</td>\n",
    "        <td>0.964</td>\n",
    "        <td>0.953</td>\n",
    "        <td>0.960</td>\n",
    "        <td>0.021</td>\n",
    "        <td>0.024</td>\n",
    "        <td>0,955</td>\n",
    "        <td>0,959</td>\n",
    "    </tr>\n",
    "    <caption>Tabla 1 - Resultados de entrenamiento de conjunto <b>Iris</b> para cada configuración paramétrica</caption>\n",
    "</table>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Modelo</th>\n",
    "        <th>Continuos</th>\n",
    "        <th>Medida</th>\n",
    "        <th>|</th>\n",
    "        <th>Accuracy</th>\n",
    "        <th>Precision promediada</th>\n",
    "        <th>Precision ponderada</th>\n",
    "        <th>Recall promediada</th>\n",
    "        <th>Recall ponderada</th>\n",
    "        <th>Fall-off promediada</th>\n",
    "        <th>Fall-off ponderada</th>\n",
    "        <th>F-measure promediada</th>\n",
    "        <th>F-measure ponderada</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Árbol</td>\n",
    "        <td>Fijo</td>\n",
    "        <td>Ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.635</td>\n",
    "        <td>0.658</td>\n",
    "        <td>0.638</td>\n",
    "        <td>0.385</td>\n",
    "        <td>0.635</td>\n",
    "        <td>0.074</td>\n",
    "        <td>0.222</td>\n",
    "        <td>0,434</td>\n",
    "        <td>0,620</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Árbol</td>\n",
    "        <td>Fijo</td>\n",
    "        <td>Ratio de Ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.685</td>\n",
    "        <td>0.682</td>\n",
    "        <td>0.684</td>\n",
    "        <td>0.430</td>\n",
    "        <td>0.685</td>\n",
    "        <td>0.066</td>\n",
    "        <td>0.195</td>\n",
    "        <td>0,481</td>\n",
    "        <td>0,670</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Árbol</td>\n",
    "        <td>Fijo</td>\n",
    "        <td>Reducción de Impureza</td>\n",
    "        <td>|</td>\n",
    "        <td>0.633</td>\n",
    "        <td>0.619</td>\n",
    "        <td>0.633</td>\n",
    "        <td>0.390</td>\n",
    "        <td>0.633</td>\n",
    "        <td>0.075</td>\n",
    "        <td>0.225</td>\n",
    "        <td>0,436</td>\n",
    "        <td>0,618</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #95dcd4;\">\n",
    "        <td>Árbol</td>\n",
    "        <td>Maximizando ganancia</td>\n",
    "        <td>Ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.654</td>\n",
    "        <td>0.651</td>\n",
    "        <td>0.653</td>\n",
    "        <td>0.527</td>\n",
    "        <td>0.654</td>\n",
    "        <td>0.069</td>\n",
    "        <td>0.198</td>\n",
    "        <td>0,555</td>\n",
    "        <td>0,648</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #95dcd4;\">\n",
    "        <td>Árbol</td>\n",
    "        <td>Maximizando ganancia</td>\n",
    "        <td>Ratio de ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.693</td>\n",
    "        <td>0.654</td>\n",
    "        <td>0.692</td>\n",
    "        <td>0.491</td>\n",
    "        <td>0.693</td>\n",
    "        <td>0.062</td>\n",
    "        <td>0.171</td>\n",
    "        <td>0,518</td>\n",
    "        <td>0,683</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #afdb99;\">\n",
    "        <td>Árbol</td>\n",
    "        <td>Maximizando ganancia</td>\n",
    "        <td>Reducción de Impureza</td>\n",
    "        <td>|</td>\n",
    "        <td>0.655</td>\n",
    "        <td>0.652</td>\n",
    "        <td>0.653</td>\n",
    "        <td>0.531</td>\n",
    "        <td>0.655</td>\n",
    "        <td>0.069</td>\n",
    "        <td>0.197</td>\n",
    "        <td>0,556</td>\n",
    "        <td>0,648</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bosque</td>\n",
    "        <td>Fijo</td>\n",
    "        <td>Ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.609</td>\n",
    "        <td>0.339</td>\n",
    "        <td>0.651</td>\n",
    "        <td>0.390</td>\n",
    "        <td>0.609</td>\n",
    "        <td>0.071</td>\n",
    "        <td>0.154</td>\n",
    "        <td>0,344</td>\n",
    "        <td>0,621</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bosque</td>\n",
    "        <td>Fijo</td>\n",
    "        <td>Ratio de Ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.600</td>\n",
    "        <td>0.332</td>\n",
    "        <td>0.640</td>\n",
    "        <td>0.389</td>\n",
    "        <td>0.600</td>\n",
    "        <td>0.073</td>\n",
    "        <td>0.162</td>\n",
    "        <td>0,334</td>\n",
    "        <td>0,610</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bosque</td>\n",
    "        <td>Fijo</td>\n",
    "        <td>Reducción de Impureza</td>\n",
    "        <td>|</td>\n",
    "        <td>0.607</td>\n",
    "        <td>0.347</td>\n",
    "        <td>0.648</td>\n",
    "        <td>0.414</td>\n",
    "        <td>0.607</td>\n",
    "        <td>0.072</td>\n",
    "        <td>0.156</td>\n",
    "        <td>0,353</td>\n",
    "        <td>0,618</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bosque</td>\n",
    "        <td>Maximizando ganancia</td>\n",
    "        <td>Ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.681</td>\n",
    "        <td>0.416</td>\n",
    "        <td>0.705</td>\n",
    "        <td>0.459</td>\n",
    "        <td>0.681</td>\n",
    "        <td>0.060</td>\n",
    "        <td>0.136</td>\n",
    "        <td>0,429</td>\n",
    "        <td>0,689</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bosque</td>\n",
    "        <td>Maximizando ganancia</td>\n",
    "        <td>Ratio de ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.680</td>\n",
    "        <td>0.411</td>\n",
    "        <td>0.692</td>\n",
    "        <td>0.433</td>\n",
    "        <td>0.680</td>\n",
    "        <td>0.062</td>\n",
    "        <td>0.152</td>\n",
    "        <td>0,416</td>\n",
    "        <td>0,681</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bosque</td>\n",
    "        <td>Maximizando ganancia</td>\n",
    "        <td>Reducción de Impureza</td>\n",
    "        <td>|</td>\n",
    "        <td>0.689</td>\n",
    "        <td>0.438</td>\n",
    "        <td>0.711</td>\n",
    "        <td>0.483</td>\n",
    "        <td>0.689</td>\n",
    "        <td>0.059</td>\n",
    "        <td>0.137</td>\n",
    "        <td>0,454</td>\n",
    "        <td>0,696</td>\n",
    "    </tr>\n",
    "    <caption>Tabla 2 - Resultados de entrenamiento de conjunto <b>CoverType</b> para cada configuración paramétrica</caption>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Elección y comparación de representantes\n",
    "***\n",
    "\n",
    "#### 3.4.1. Elección\n",
    "***\n",
    "Para elegir los representantes con los cuales comparar se siguió el siguiente proceso:\n",
    "- 1) Se agruparon elementos en subgrupos dada su similutud en: Accuracy y promedios generales de Precisión, Recall, FallOff y F-measure\n",
    "- 2) Los subgrupos fueron refinados en más subgrupos acorde a comparaciones entre otros subgrupos y los promedios ponderados.\n",
    "- 3) Se observaron desviaciones entre los mismos, en base a estas particularidades se centra la comparación y de los representantes.\n",
    "\n",
    "**ESTO NO VA, VA A IR EN LAS GRAFICAS Y TABLA, LO PONGO PARA SEGUIR HABLANDO DE LOS SUBGRUPOS Y QUE NO SE PIERDA EN WSP**\n",
    "**Hay que darle una 2da pasada a las tablas por si faltó agarrar algo que yo me perdí**\n",
    "##### Iris:\n",
    "###### Buenos resultados: (Metricas en general arriba de 0.95)\n",
    "    1.  18  Bosque  C45 GainRatio   F: 0.955\n",
    "    2.  7,8,9   Arbol   C45 Any     F: 0.945~\n",
    "###### Peores resultados: (Metricas en general por abajo del 0.88)\n",
    "    1.  15  Bosque  Var Impurity    F: 0.865    Calificó mal aunque tiene algunas metricas bastante bien\n",
    "    2.  1,2,3   Arbol   Fijos   Any     F: 0.87 Dieron los falloffs más altos\n",
    "\n",
    "##### Covertype:\n",
    "###### Buenos resultados: (F-Measure mayor a 0.5)\n",
    "    1.  D, F    Arbol   C45 Gain, Imp   F: 0.55 Resultados re identicos. Fueron los que mejor calificaron de 4-7.\n",
    "    2.  E   Arbol   C45 GainRatio   F: 0.51 Tiene mejor promedio ponderado porque califica mejor 1-3, no califica 4-7 horriblemente pero en gral tiene peor performance que D y F\n",
    "    3.  L   Bosque  C45 GainRatio   F: 0.45 MEjor precisión en 1-2, deteriora bastante la precisión en 3-7. El problema principal aca fue el falloff.\n",
    "    4.  J,K Bosque  C45 Gain, Imp   F: 0.42 Resultados en general peores a L pero sin ninguna varianza significativa respecto al mismo\n",
    "###### Peores resultados: (F-Measure mean  0.35, weights distribuidos no atipicamente (0.61-0.68))\n",
    "    1.  G,H,I   Bosque  Fijos   Any (H GainRatio fue el peor). Califican demasiado mal clases 4-7. Se observa que los promedios ponderados no son atipicos porque estos casos son la minoria.\n",
    "\n",
    "Se adjunta script de graficas\n",
    "\n",
    "<div style=\"margin-top: 16px; margin-bottom: 16px;\">\n",
    "    <div style=\"display: inline-block; width: 49%; text-align: center;\">\n",
    "        <img src=\"img/instancia1.png\" />\n",
    "        <label style=\"margin-top: 16px; font-size: 16px; font-family: monospace;\"> Figura 3.17 - Partidas ganadas para cada modelo entrenado de la instancia 1</label>\n",
    "    </div>\n",
    "    <div style=\"display: inline-block; width: 49%; text-align: center;\">\n",
    "        <img src=\"img/instancia2.png\" />\n",
    "        <label style=\"margin-top: 16px; font-size: 16px; font-family: monospace;\"> Figura 3.18 - Partidas ganadas para cada modelo entrenado de la instancia 2</label>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "#### 3.4.2. Comparación\n",
    "***\n",
    "Aca hablamos de los mejores y los comparamos\n",
    "\n",
    "**Observaciones generales:**\n",
    "- C4.5 siempre dio mejores resultados que particiones en intervalos fijos. Esto no es de extrañarse dado que C45 es en si una mejora sobre ID3.\n",
    "- Para *Covertype* se obtuvieron consistentemente mejores resultados empleando árboles que bosques.\n",
    "- *Covertype* es un conjunto dificil de calificar, pese a contar con una muestra extremadamente grande de datos en el entrenamiento, los resultados obtenidos mediante la construcción de un árbol de decisión son fuertemente perjudicados a causa de la complejidad de los atributos, así como por la enorme proporción de elementos de clase 1, 2 y 3 frente a los pocos elementos de clase 4, 5, 6 y 7.\n",
    "- Algunos resultados tuvieron una gran diferencia entre sus promedios generales y promedios ponderados (siendo los últimos bastante más altos). Esto es debido a que estos conjuntos son de los que menos éxito tienen al calificar elementos de la clase 4, 5, 6 y 7; pero a causa de su baja proporción respecto a los elementos de la clase 1, 2 y 3 los promedios ponderados no se ven tan disminuidos.\n",
    "- En *Covertype* los bosques califican los elementos de clase 1, 2 y 3 mejor que los árboles. Sin embargo, tienen una muy baja Precisión y muy alto FallOff para los elementos de clase 4, 5, 6 y 7. Esto se debe a que para una cantidad no despreciable de clasificaciones (7) y la reducida cantidad de datos de elementos de clase 4, 5, 6 y 7; es muy dificil clasificar elementos booleanamente para cada clase, la mayoría de clasificaciones acaban en votaciones (a causa de que no ocurre la situación ideal de que 1 árbol de true y los otros false) y en cualquier árbol un false dice muy poca información (no tiene caracteristicas de elementos de esta clase, pero puede tener caracteristicas de cualquier otro). Esto para un conjunto de atributos y clasificaciones con alta complejidad acaba disminuyendo enormemente la calidad del árbol cuando no es facil detectar atributos con muy baja impureza que determinen fuertemente la pertenencia a una clase.\n",
    "\n",
    "**Interpretaciones:**\n",
    "- Si bien llegaron a formar parte de subconjuntos distintos, la medida no tuvo gran impacto en la performance de los modelos. Inclusive es imposible afirmar con el número de resultados obtenidos si estos subconjuntos son correctos para la métrica y no se dieron aleatoriamente por la separación en el conjuntos de validación y entrenamiento.\n",
    "- Muchos de los resultados en *covertype* no necesariamente reflejan la realidad, esto es debido a la aleatoriedad de la validación (80/20). Una validación cruzada en 10 intervalos (Como la realizada en Iris) podría dar un intervalo de certeza mucho mayor sobre las conjeturas basadas en las interpretaciones de los candidatos.\n",
    "- El haber desecho el one-hot encoding es un buen candidato a culpar por los malos resultados obtenidos a la hora de clasificar elementos del conjunto 4 al 7 en Covertype. La cantidad de elementos pertenecientes a estos conjuntos es muy baja y poder diferenciar con mejor granularidad y menor sesgo inducido sobre el tipo de suelo (soil_type) pudo haber ayudado a encontrar relaciones entre el mismo y la calificación del terreno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusiones\n",
    "***\n",
    "\n",
    "#### 4.1. Respecto a los Modelos\n",
    "***\n",
    "Acá hablar sobre la demora de los bosques y la dificultad de establecer una votación que estuviera buena. La randomness al empatar es bastante mierda y mete ruido.\n",
    "\n",
    "#### 4.2. Respecto a los Atributos\n",
    "***\n",
    "Acá hablar de que el one hot encoding no rinde pa arboles\n",
    "\n",
    "#### 4.3. Respecto a los Parámetros\n",
    "***\n",
    "Acá hablar de que los arboles no encaran tanto en continuos, fixed es caca, c45 y variables son mejores pero para un dataset tan grande nos cagó.\n",
    "\n",
    "#### 4.4. Respecto a los Resultados\n",
    "***\n",
    "Acá hablar de que covertype da peores resultados porque es un dataset muy grande. Más conclusiones viendo los resultados. Hablar de que los promedios ponderados nos dieron mejor info que los promedios generales porque hay mucha cantidad de b1 en covertype y poca de otros como b4.\n",
    "\n",
    "#### 4.5. Posibles mejoras\n",
    "***\n",
    "A\n",
    "- Usar todos los valores en variables y c4.5\n",
    "- Usar distintas measures en c4.5\n",
    "- Mantener el onehotencoding o al menos no tratar como continuos esos atributos\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
