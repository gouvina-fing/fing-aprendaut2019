{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega 2 - Clasificador (Árboles de Decisión)\n",
    "\n",
    "### Grupo 07:\n",
    "     - Renzo Gambone C.I. 5.155.486-4\n",
    "     - Germán Ouviña C.I. 4.823.566-1\n",
    "     - Leandro Rodríguez C.I 4.691.736-4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción\n",
    "***\n",
    "### 1.1. Objetivo\n",
    "***\n",
    "El objetivo de esta tarea fue implementar un modelo de **árboles de decisión**, basándose su entrenamiento en el algoritmo **ID3** con una serie de modificaciones. Una vez generados distintos clasificadores en base a ciertos parámetros, se evaluó la performance de los mismos utilizando distintos tipos de métrica y comparando dichas evaluaciones para determinar cual modelo se ajustó mejor a cada escenario.\n",
    "\n",
    "En términos formales, los parámetros del problema se reducen a lo siguiente:\n",
    "- **Tarea *T*:** Clasificar ejemplos siguiendo cierto formato.\n",
    "- **Experiencia *E*:** Conjunto de datos con ejemplos ya clasificados siguiendo cierto formato.\n",
    "- **Performance *P*:** Múltiples tipos de medidas (las cuales se profundizan en la sección 3).\n",
    "\n",
    "### 1.2. Entrega\n",
    "***\n",
    "La entrega de esta tarea consta de dos grandes componentes:\n",
    "- **Informe** en formato de Jupyter Notebook (este informe).\n",
    "- **Programa** que permite entrenar clasificadores, evaluar su desempeño y clasificar nuevos ejemplos.\n",
    "\n",
    "El objetivo del informe es centralizar la información relativa a la construcción del modelo así como los datos obtenidos mediante pruebas realizadas con distintas configuraciones paramétricas. Como agregado opcional, se adjuntan algunos scripts para ayudar a la lectura o probar en tiempo real ciertas funcionalidades.\n",
    "\n",
    "Por otra parte, el programa ofrece una interfaz en consola que permite entrenar y evaluar árboles acorde a múltiples configuraciones paramétricas, mostrar los arboles entrenados y calificar elementos del conjunto asociado al árbol. También se agregó un script para entrenar y evaluar modelos automáticamente. Si bien todas estas herramientas fueron pensadas para uso del grupo, en el archivo README.md se adjunta una sencilla guía de como utilizarlas.\n",
    "\n",
    "### 1.3. Formato\n",
    "***\n",
    "En las siguientes secciones se especifica el diseño del modelo, justificando la toma de decisiones a la hora de construirlo y se detallan las estrategias o algoritmos que fueron implementados para la configuración paramétrica, junto a las métricas utilizadas en la evaluación. Luego, se detalla la metodología de experimentación y con la misma los resultados obtenidos para cada modelo y cada conjunto de datos, habiendo entrenado con distintas configuraciones paramétricas. Finalmente se agregan conclusiones respecto a los resultados obtenidos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Diseño\n",
    "***\n",
    "En esta sección se detallan las características del diseño utilizado para construir el modelo, se profundizan las estrategias y algoritmos empleados en la configuración paramétrica y se tratan otros puntos como el procesamiento previo al entrenamiento y la evaluación posterior al mismo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Modelo\n",
    "***\n",
    "La consigna propone la utilización y comparación de dos tipos de modelos que basan su entrenamiento en **ID3**. Dichos modelos serán denominados **árboles de decisión** y **bosques de decisión** respectivamente. A continuación, se especifican las características de cada uno:\n",
    "\n",
    "**Notas:**\n",
    "* No se ahonda en dichas descripciones puesto que son conceptos trabajados en el teórico.\n",
    "* Se utiliza notación matemática para visualizar fácilmente la definición de cada modelo.\n",
    "\n",
    "#### 2.1.1. Árbol de decisión\n",
    "***\n",
    "Para este escenario uno de los modelos propuestos es el de un **árbol de decisión** multiclase, es decir, una estructura de árbol que para un ejemplo dado, lo clasifica en una de múltiples clases.\n",
    "\n",
    "Se definen más formalmente las siguientes nociones:\n",
    "* $D =$ Conjunto de entrenamiento\n",
    "* $C_D =$ Conjunto de posibles clasificaciones para $d \\in D$\n",
    "* $T_D =$ Árbol de decisión generado en base a $D$\n",
    "* Se representa una clasificación de un ejemplo $d \\in D$ realizada por el árbol $T_D$ como $T_D(d) = c : c \\in C_D$ y $d \\in D$\n",
    "\n",
    "#### 2.1.2. Bosque de decisión\n",
    "***\n",
    "\n",
    "El otro modelo propuesto es el de un **bosque de decisión** multiclase de árboles binarios. El modelo de bosque se basa fuertemente en el modelo de árbol, consistiendo básicamente en un conjunto de árboles de decisión que clasifican un ejemplo para cada clase. El bosque pondera las clasificaciones de cada árbol en base a cierto criterio y genera una clasificación.\n",
    "\n",
    "Se definen más formalmente las siguientes nociones:\n",
    "* $D =$ Conjunto de entrenamiento\n",
    "* $C_D =$ Conjunto de posibles clasificaciones para $d \\in D$\n",
    "* $B_D =$ Bosque de decisión generado en base a $D$\n",
    "* $B_D(d) = c : c \\in C_D ^ d \\in D$, Representando esto una clasificación de un ejemplo $d \\in D$ realizada por el bosque $B_D$\n",
    "* $T_{(B, c)} =$ Árbol de decisión binario perteneciente a $B_D$ y generado en base a la clasificación $c \\in C_D$\n",
    "* Sea $|C_D| = n$, hay $n$ árboles de decisión binarios en $B_D$\n",
    "* Se representa una clasificación de un ejemplo $d \\in D$ realizada por el árbol $T_{(B, c)}$ como $T_{(B, c)}(d) = c' : c' \\in \\{True, False\\}$ y $d \\in D$\n",
    "\n",
    "Los detalles sobre los algoritmos de entrenamiento y clasificación utilizados por cada modelo se expanden en la sección 2.3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Preprocesamiento\n",
    "***\n",
    "Con los objetivos tanto de hacer viable, como de mejorar la performance de entrenamiento, se realizaron ciertos cambios en el conjunto de datos a utilizar. A continuación, se listan los cambios realizados agrupandolos en base a motivación y área cambiada en el conjunto original.\n",
    "\n",
    "**Notas:**\n",
    "* Los cambios realizados en el conjunto de datos fueron hechos en memoria, sin modificar de forma alguna los archivos originales.\n",
    "\n",
    "#### 2.2.1. Optimización (Representación)\n",
    "***\n",
    "La elección de la representación interna fue compleja, ya que se tuvo en cuenta tanto la performance como la facilidad a la hora de programar e interpretar el código.\n",
    "\n",
    "Luego de numerosas pruebas utilizando distintas representaciones, se determinó la utilización del objeto **DataFrame** de la biblioteca *pandas*. Al principio trajo muchos problemas de performance (tanto en uso de memoria como en velocidad) pero al implementar técnicas ofrecidas por la biblioteca dichos problemas se palearon, generando eventualmente un uso de memoria reducido y un entrenamiento veloz.\n",
    "\n",
    "#### 2.2.2. Estructura (Atributos)\n",
    "***\n",
    "Originalmente se buscó mantener la estructura de atributos estática, con el fin de impactar lo menos posible en el entrenamiento y su posterior evaluación. No obstante, para el segundo conjunto de datos (detallado en la sección 2.4), fue necesario cambiar la estructura eliminando varios atributos y generando otros nuevos.\n",
    "\n",
    "Más concretamente, el cambio realizado fue el proceso inverso al conocido como **one hot encoding**, ya que habia múltiples atributos que representaban \"la idea\" de un sólo atributo discreto. En múltiples problemas, la implementación de dicho algoritmo resulta de gran utilidad para mejorar el rendimiento tanto a nivel de performance como de clasificación, generando $x$ atributos binarios para $x$ posibles valores del atributo original. \n",
    "\n",
    "En el contexto de árboles de decisión, sucede lo opuesto: el aumento lineal en cantidad de atributos genera un aumento exponencial en el tamaño del árbol y en el tiempo de entrenamiento. Tomando esto en cuenta, se deshizo el **one hot encoding**, tratando a los atributos generados como continuos (este punto junto a sus implicancias son expandidos en las siguientes secciones).\n",
    "\n",
    "#### 2.2.3. Clasificación (Resultados)\n",
    "***\n",
    "Para el modelo de **árbol de decisión** no fue necesario realizar ningún cambio en el conjunto de datos. No obstante, para entrenar a los árboles pertenecientes al **bosque de decisión**, al ser estos de carácter binario y funcionar para una sola clase, hubo que modificar los resultados del conjunto.\n",
    "\n",
    "Utilizando las nociones de la sección 2.1, se procesó el conjunto de datos generando $|C_D| = n$ conjuntos con las clasificaciones correspondientes, uno para cada posible valor. Cada árbol del bosque fue entrenado utilizando uno de esos conjuntos generados. \n",
    "\n",
    "El conjunto original no fue modificado, por lo que el bosque en sí puede clasificar para las clases originales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Algoritmo\n",
    "***\n",
    "En la siguiente sección se centralizan todas las especificaciones relativas a los algoritmos empleados, tanto para entrenar como para clasificar. \n",
    "\n",
    "**Notas:**\n",
    "* Se hace referencia a puntos mencionados en secciones anteriores, sin entrar en detalle en lo que ya fue explicado.\n",
    "\n",
    "#### 2.3.1. Algoritmo de entrenamiento\n",
    "***\n",
    "El algoritmo de entrenamiento se basa en el conocido **algoritmo ID3** para construcción de **árboles de decisión**. Dicho algoritmo sigue las pautas generales vistas en el teórico. Se agregó la posibilidad de tratar atributos continuos y se varió el uso de medidas para detectar el mejor atributo. Dichos cambios se tratan en las subsecciones 2.3.3 y 2.3.4. \n",
    "\n",
    "Teniendo en cuenta lo mencionado en secciones anteriores, el algoritmo de entrenamiento implementado puede entrenar dos tipos de modelos, generando dos tipos de clasificadores:\n",
    "\n",
    "- **Árbol de decisión:** Se implementa el entrenamiento greedy estándar de ID3 con los cambios anteriormente mencionados y se obtiene como resultado un árbol de decisión multiclase.\n",
    "- **Bosque de decisión:** Se itera sobre cada posible clasificación, procesando el conjunto de datos según corresponda y generando un árbol de decisión binario utilizando el algoritmo ID3 adaptado anteriormente mencionado.\n",
    "\n",
    "#### 2.3.2. Algoritmo de clasificación\n",
    "***\n",
    "A la hora de clasificar un elemento como miembro de una clase, el procedimiento difiere dependiendo del modelo utilizado. No obstante, al igual que con el entrenamiento, la clasificación de un bosque se basa fuertemente en la de un árbol. \n",
    "\n",
    "Es importante mencionar que los árboles generados tienen una **probabilidad** asignada a cada hoja. Dicha probabilidad es calculada al momento de generar la hoja durante el entrenamiento. Al no quedar más atributos, se calcula la frecuencia de cada clase en el subconjunto de datos que hay en la hoja y aquella clasificación con mayor frecuencia es la elegida por la hoja, adjuntandose dicha frecuencia junto a ella.\n",
    "\n",
    "Teniendo esto en cuenta, a grandes rasgos, los algoritmos funcionan como sigue:\n",
    "\n",
    "- **Árbol de decisión:** Se toma el ejemplo a clasificar y se recorre recursivamente los nodos del árbol hasta llegar a una hoja. Se devuelve la clasificación junto a su probabilidad. Por la naturaleza del algoritmo, dicha probabilidad suele ser mayor a 0.5. \n",
    "- **Bosque de decisión:** Se toma el ejemplo a clasificar y se itera sobre cada árbol, obteniendo la clasificación del mismo. Una vez obtenidas todas las clasificaciones, se procede a realizar una **votación**. El resultado de dicha votación es la clasificación del ejemplo en cuestión.\n",
    "\n",
    "La clasificación del **árbol de decisión** no cuenta con grandes especificidades, ya que es la misma utilizada por los árboles de decisión genéricos. No obstante, para determinar el algoritmo de votación del **bosque de decisión** fue necesario determinar un criterio, por lo que a continuación se explaya sobre este asunto.\n",
    "\n",
    "En el escenario donde todos los árboles indican *False*, aludiendo a que el elemento no es de su clasificación y uno de los árboles indica *True*, la clasificación es trivial. En este caso el resultado final es la clasificación del elemento. Sin embargo este no es siempre el caso, dado que los árboles de decisión si bien son resistentes al ruido, no son inmunes al mismo.\n",
    "\n",
    "Un problema a resolver a la hora de trabajar con bosques son los *empates*, en donde uno o más árboles devuelven *True* para determinado ejemplo. El desempate se alcanza comparando la **probabilidad** con la que cada árbol clasificó al ejemplo y tomando aquella clasificación con mayor frecuencia. \n",
    "\n",
    "En caso de que haya empate entre varias clasificaciones y sus probabilidades, el bosque elige una de ellas aleatoriamente. En la sección 4 se expanden las implicancias de este hecho.\n",
    "\n",
    "#### 2.3.3. Selección de mejor atributo\n",
    "***\n",
    "Un paso crucial del algoritmo es decidir que atributo \"bifurca mejor\" el árbol. ID3 propone elegir el atributo que maximice la **ganancia de información**. Sin embargo, esta métrica favorece los atributos que toman múltiples valores sobre otros. A raiz de esto es que también se experimentó con otras estrategias en la configuración paramétrica, como el **ratio de ganancia** y la **reducción de \"impureza\"**\n",
    "\n",
    "Todas las siguientes estrategias trabajan con una métrica que determina *\"cuánto un atributo separa a los ejemplos según la clasificación objetivo\"*, esta métrica es la **entropía** y se define como:\n",
    "- Sea $D = $ Conjunto de datos\n",
    "- Sea $C_D = $ Conjunto de posibles clasificaciones para $d \\in D$\n",
    "- Sea $|C_D| = n =$ Cantidad de posibles clasificaciones en $C_D$\n",
    "- Sea $f_D : D \\rightarrow C_D =$ Función que clasifica elementos en $D$\n",
    "- Sea $p_i$ la proporción de ejemplos $d \\in D : f_D(d) = c_i$ con $c_i \\in C_D$ la i-ésima clasificación\n",
    "\n",
    "$$Entropía(D) = -\\sum p_i log_2(p_i)$$\n",
    "\n",
    "La entropía mide la heterogeneidad de los datos: cuanto más homogéneos, menor será la misma.\n",
    "\n",
    "A continuación, se adjunta una breve noción de las tres medidas utilizadas para determinar *\"el mejor atributo\"*:\n",
    "\n",
    "##### 2.3.3.1. Ganancia\n",
    "***\n",
    "Se define la **ganancia de información** de un atributo $a$ sobre una muestra $D$ como:\n",
    "\n",
    "$$Ganancia(D,a) = Entropía(D) - \\sum_{v \\in Val(a)}\\frac{|D_v|}{|D|}\\cdotp\n",
    " Entropía(D_v)\\$$\n",
    "\n",
    "La fundamentación de tomar la ganancia es que se desea que el atributo sobre el cual se particione divida el conjunto de datos de la forma más homogénea en cuanto a su clasificación posible.\n",
    "\n",
    "Como se mencionó anteriormente, una desventaja de la ganancia es que favorece a los atributos que asumen un espectro muy alto de valores distintos con respecto a otros atributos. Un conjunto amplio y uniformemente distribuido de valores para el atributo no necesariamente es una característica que debería formar parte a la hora de determinar el mejor atributo para bifurcar.\n",
    "\n",
    "##### 2.3.3.2. Ratio de ganancia\n",
    "***\n",
    "Se define el **ratio de ganancia** de un atributo $a$ sobre una muestra $D$, en función de la **separación de información** de un atributo $a$ sobre una muestra $D$. Dichas definiciones son las siguientes:\n",
    "\n",
    "$$SeparacionDeInformacion(D,a) = - \\sum_{v \\in Val(a)}\\frac{|D_v|}{|D|} \\cdotp log_2(\\frac{|D_v|}{|D|})$$\n",
    "\n",
    "$$RatioGanancia(D,Aa) = \\frac{Ganancia(D,a)}{SeparacionDeInformacion(D,a)}$$\n",
    "\n",
    "La **separación de información** es sensible a que tan amplia y uniformemente el atributo distribuye sus datos, logrando así penalizar a los atributos que tomen un espectro muy amplio de valores. Una colección de ejemplos $D : |D| = n$ que estén completamente separados por un atributo $a_1$ (como una fecha) tendrá $SeparacionDeInformacion(D,a_1) = log_2(n)$. En cambio un atributo $a_2$ (booleano, por ejemplo) que divida los mismos $n$ ejemplos a la mitad tendrá $SeparacionDeInformacion(D,a_2) = 1$. Si ambos atributos producen la misma ganancia de información, entonces $a_2$ tendrá un **ratio de ganancia** más alto.\n",
    "\n",
    "Se observa que la **separación de información** es la entropía de $D$ respecto a los valores del atributo $a$ (a diferencia de tomarla con respecto a la clasificación).\n",
    "\n",
    "Una desventaja de usar el **ratio de ganancia** en lugar de sólo **ganancia** es que la **separación de información** puede ser 0, lo que hace el **ratio de ganancia** sea indefinido o muy grande para atributos que pueden tener el mismo valor para casi todos los miembros de $D$.\n",
    "\n",
    "##### 2.3.3.3. Reducción de \"impureza\"\n",
    "***\n",
    "Se define la **reducción de impureza** de un atributo $a$ sobre una muestra $D$, utilizando la **impureza Gini** (nombrada en honor a Conrado Gini) de una muestra $D$. Dichas definiciones son las siguientes:\n",
    "\n",
    "$$Gini(D) = 1 - \\sum p_{i}^2$$\n",
    "\n",
    "$$ReductionImpureza(D,a) = Gini(D) - \\sum_{v \\in Val(a)}\\frac{|D_v|}{|D|} \\cdotp Gini(D_v)$$\n",
    "\n",
    "La **impureza Gini**, nombrada por el matemático Corrado Gini, mide la homogeneidad de un conjunto de elementos, tomando un valor mínimo de 0.0 y un valor máximo acotado por 1.0.\n",
    "\n",
    "Dicha métrica toma valor 0 cuando todos los elementos del conjunto califican al mismo valor. En este contexto se dice que la **impureza** es mínima. A su vez si todos los valores del conjunto califican la misma cantidad de resultados distintos, se dice que la **impureza** es máxima (tomando un valor menor o igual a 1.0).\n",
    "\n",
    "A los efectos practicos de la construcción de **árboles de decisión**, durante la misma se desea bifurcar con atributos que reduzcan la **impureza** lo mayor posible posible (optando por atributos que califiquen la mayor cantidad de instancias en la misma clase).\n",
    "\n",
    "Una muy importante observación es que si bien la **impureza Gini** minimiza errores de clasificación y la **entropía** se usa para análisis exploratorio, ambas cumplen un rol casi idéntico. Usualmente, la **impureza Gini** da mejores resultados para atributos continuos mientras que la **entropía** funciona mejor con atributos discretos, sin embargo algunos estudios encontraron que sólo un 2% de las veces los resultados son distintos.\n",
    "\n",
    "Debido a que su efectividad es dependiente del problema, se decidió incluir reducción de impureza como parte de la configuración paramétrica. \n",
    "\n",
    "#### 2.3.4. Interpretación de valores continuos\n",
    "***\n",
    "Una característica clave para el escenario propuesto y que **ID3** no contempla es **el tratamiento de atributos continuos**. Se emplearon tres estrategias distintas para interpretar los valores de tales atributos, teniendo como fin las mismas, discretizar el espectro continuo en una pequeña cantidad de clases.\n",
    "\n",
    "Como noción general independiente a la estrategia implementada, cada clase discreta generada a partir de la estrategia en cuestión representa un **intervalo**. Los intervalos se definen por su **tope superior (máximo)**, excepto el último, que se define por su **tope inferior (mínimo)**\n",
    "\n",
    "Sea por ejemplo, la lista de intervalos $[v_0, ..., v_n, v_{n+1}]$, para cada valor $v_i : i \\in [0..n+1]$ se cumple lo siguiente:\n",
    "- El intervalo de $v_0$ representa \"todos los valores $k : k \\leq v_0$\".\n",
    "- El intervalo de $v_i : i \\in [1..n]$ representa \"todos los valores $k : v_{i-1} \\lt k \\leq v_i$\".\n",
    "- El intervalo de $v_{n+1}$ representa \"todos los valores $k : k \\gt v_{n+1}$\".\n",
    "\n",
    "Es importante mencionar que los últimos dos **valores** cumplen ser iguales ($v_n = v_{n+1}$), lo que cambia es lo que el intervalo representa.\n",
    "\n",
    "Habiendo visto esto, se resumen las estrategias implementadas:\n",
    "\n",
    "##### 2.3.4.1. Partir en intervalos fijos\n",
    "***\n",
    "Como primera estrategia, se determina la siguiente:\n",
    "- Sea $A_D =$ Conjunto de atributos en conjunto de datos $D$\n",
    "- Sea $a \\in A_D : Val(a) \\subseteq N, Z, R$ un atributo continuo\n",
    "- Sea $a^{*} \\in A_D : |Val(a^{*})| \\lt \\infty$ la discretización de un atributo continuo\n",
    "- Sea $\\mu_{a}$ la mediana de $Val(a)$ para los ejemplos en $D$\n",
    "- Entonces $Val(a^{*}) = \\{\\leq \\mu_{a}, \\gt \\mu_{a}\\}$\n",
    "\n",
    "En lenguaje natural, se generan dos intervalos: los valores menores o iguales a la mediana de los valores actuales, y los valores mayores a dicha mediana. Todo nuevo valor entra siempre en alguno de los dos intervalos.\n",
    "\n",
    "La fundamentación de tomar dos intervalos partidos por la mediana es que es una manera intuitiva de distribuir el atributo de forma \"pareja\" en el árbol. Por otra parte, la desventaja de esta estrategia está en que, además de no ser necesariamente el punto ideal de corte para la clasificación, el partir en solamente dos intervalos para atributos con múltiples valores puede terminar agrupando ejemplos e introduciendo ruido al conjunto de datos.\n",
    "\n",
    "##### 2.3.4.2. Partir en intervalos variables\n",
    "***\n",
    "Con el fin de mejorar el defecto del enfoque anterior se implementa la siguiente estrategia:\n",
    "- Sea $D_a =$ Conjunto de datos ordenado ascendentemente en base a atributo $a$\n",
    "- Sea $A_{D_a} =$ Conjunto de atributos en conjunto de datos $D_a$\n",
    "- Sea $a \\in A_{D_a} : Val(a) \\subseteq N, Z, R$ un atributo continuo\n",
    "- Sea $a^{*} \\in A_{D_a} : |Val(a^{*})| \\lt \\infty$ la discretización de un atributo continuo\n",
    "- Sea $v_i : v_i \\in Val(a)$ el valor de $a$ en el k-ésimo ejemplo $d_k \\in D_a$ tal que cambia su clasificación respecto a $d_{k-1}$\n",
    "- Entonces $Val(a^{*}) = \\{\\leq v_0, ..., \\leq v_n, \\gt v_n\\}$\n",
    "\n",
    "En lenguaje natural, se genera un número variable de intervalos. El procedimiento para generarlos es:\n",
    "1. Ordenar $D$ en base a $a$ (generando $D_a$).\n",
    "2. Iterar sobre $D_a$\n",
    "3. Almacenar en $Val(a^{*})$, el valor $v_i$ de $a$ en $d_k$, en el momento en que la clasificación cambia del ejemplo $d_{k-1}$ al ejemplo $d_k$.\n",
    "\n",
    "De esta forma, se tiene una cantidad de intervalos que relaciona el cambio en la clasificación del ejemplo con el cambio en el atributo $a$. Esta técnica impacta menos negativamente que la anterior en relación al ruido que introduce al recortar valores.\n",
    "\n",
    "No obstante, en conjuntos de datos muy grandes con valores de $a$ muy dispersos o con clasificaciones muy cambiantes, puede suceder que se genere una cantidad de intervalos cercana a la cantidad de valores originales. Este hecho atenta en contra de la idea de interpretar valores continuos y de construir árboles simples con pocas ramas. No solamente eso, si no que también impacta en el tiempo de entrenamiento.\n",
    "\n",
    "Teniendo esto en cuenta, se limitó la cantidad de posibles intervalos a 10, eligiendo 10 valores que se separan uniformemente en el conjunto total de intervalos.\n",
    "\n",
    "##### 2.3.4.3. Partir por el valor que maximice la ganancia\n",
    "***\n",
    "Basado en el algortimo C4.5, el algortimo sucesor de ID3, se implementa la siguiente estrategia:\n",
    "- Sea $D_a =$ Conjunto de datos ordenado ascendentemente en base a atributo $a$\n",
    "- Sea $A_{D_a} =$ Conjunto de atributos en conjunto de datos $D_a$\n",
    "- Sea $a \\in A_{D_a} : Val(a) \\subseteq N, Z, R$ un atributo continuo\n",
    "- Sea $a^{*} \\in A_{D_a} : |Val(a^{*})| \\lt \\infty$ la discretización de un atributo continuo\n",
    "- Sea $v_i : v_i \\in Val(a)$ el valor de $a$ en el k-ésimo ejemplo $d_k \\in D_a$ tal que cambia su clasificación respecto a $d_{k-1}$\n",
    "- Sea $Val(a') = \\{\\leq v_0, ..., \\leq v_n, \\gt v_n\\}$ los posibles valores determinados en la sección anterior\n",
    "- Entonces $Val(a^{*}) = \\{\\leq v_j, \\gt v_j\\} : v_j \\in Val(a')$ y se maximiza la ganancia de partir el conjunto de datos en $v_j$\n",
    "\n",
    "En lenguaje natural, se generan dos intervalos como en la sección 2.3.4.1 pero se parte de los valores tomados en la sección 2.3.4.2 y se determina cual de estos otorga una mayor ganancia.\n",
    "\n",
    "Una desventaja de esto es que es de un mayor orden computacional, requiriendo una recorrida del dataset para calcular la ganancia de cada punto de corte a probar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Evaluación\n",
    "***\n",
    "En la siguiente sección se centralizan todas las especificaciones relativas a la evaluación de los clasificadores entrenados.\n",
    "\n",
    "\n",
    "#### 2.4.1. Conjuntos de evaluación\n",
    "***\n",
    "Los dos conjuntos de datos a partir de los cuales se entrenó y evaluó los modelos son:\n",
    "- [**Conjunto *Iris*:**](https://archive.ics.uci.edu/ml/datasets/iris) El cual clasifica plantas del genero Iris (de la tribu Irideae, perteneciente a la familia Iridaceae) según especie. Cuenta con 150 ejemplos, 4 atributos de carácter continuo y 3 posibles clasificaciones.\n",
    "- [**Conjunto *Covertype*:**](https://archive.ics.uci.edu/ml/datasets/Covertype) El cual clasifica terrenos de bosques según atributos cartográficos. Cuenta con 581012 ejemplos,54 atributos, siendo 10 de carácter continuo y 44 de carácter binario (son el one hot encoding de 2 atributos generando 4 y 40 atributos respectivamente) y 7 posibles clasificaciones.\n",
    "\n",
    "Cabe destacar que el conjunto *Iris* cuenta con una cantidad ínfima de ejemplos, mientras que el conjunto *CoverType* va hacia el otro extremo. Las implicancias de estos hechos se tratan en la sección 3.\n",
    "\n",
    "#### 2.4.2. Métodos de evaluación\n",
    "***\n",
    "Se experimentó utilizando dos estrategias de evaluación, siendo las mismas:\n",
    "- Validación 80/20 (denominada \"normal\" a partir de ahora)\n",
    "- Validación cruzada con 10 particiones (denominada \"cruzada\" a partir de ahora)\n",
    "\n",
    "Ambas estrategias subdividen el conjunto de datos $D$ en dos subconjuntos, $T, E \\subset D$. El subconjunto $T$ se utiliza para entrenar al clasificador en cuestión, mientras que el subconjunto $E$ se utiliza para evaluar la eficacia del mismo. Esto se logra haciendo que el modelo entrenado clasifique los ejemplos del conjunto de evaluación $E$, comparando luego la clasificación original con la realizada. Dicha comparación se basa en distintas métricas, las cuales se tratan en la subsección siguiente.\n",
    "\n",
    "Es importante destacar que, independiente al método de evaluación, el conjunto de datos $D$ original se mezcla de forma aleatoria antes de subdividirlo en $T$ y $E$. Esto es vital para evitar el mismo resultado en distintas evaluaciones.\n",
    "\n",
    "Si, por ejemplo, $D$ estuviera ordenado de forma tal que los últimos ejemplos en él (los que corresponderían a $E$) no agregan información nueva a $T$, entonces el desempeño del clasificador sería excelente. Por otra parte, si sucede lo contrario, el desempeño sería mucho peor. La mezcla al azar de $D$ se utiliza con el objetivo de reducir este fenómeno.\n",
    "\n",
    "A continuación se adjunta una breve descripción de los parámetros utilizados en cada método de evaluación.\n",
    "\n",
    "##### 2.4.2.1. Validación normal\n",
    "***\n",
    "Se denomina como **validación normal** a la partición única del conjunto $D$ en $T$ y $E$ utilizando una proporción donde $|T| \\lt |E|$.\n",
    "\n",
    "En general, dependiendo de la cantidad de ejemplos en $D$ y del objetivo que se quiera alcanzar, dicha partición sigue una relación 80/20, 85/15, 90/10, etc. Para el escenario actual, se determinó utilizar una partición 80/20, es decir, $T$ cuenta con el 80% de ejemplos en $D$, mientras que $E$ cuenta con el 20% restante.\n",
    "\n",
    "Es importante recordar el fenómeno mencionado en la subsección anterior. La validación normal, si bien parte al conjunto luego de haber sido reordenado aleatoriamente, puede verse afectada, por casualidad, por el fenómeno en cuestión. Con el objetivo de reducir esta posibilidad, se agrega el siguiente método\n",
    "\n",
    "##### 2.4.2.2. Validación cruzada\n",
    "***\n",
    "\n",
    "Se denomina como **validación cruzada** a la partición del conjunto $D$ en $k$ particiones $T_i$ y $E_i : i \\in [1..k]$,  utilizando una proporción $\\frac{k-1}{k}$ y $\\frac{1}{k}$ para $T_i$ y $E_i$ respectivamente.\n",
    "\n",
    "En lenguaje natural, la validación cruzada utiliza un parámetro $k$, generando $k$ particiones de $D$ siguiendo el método normal mencionado en la anterior subsección. Esto se hace con el objetivo de evitar el sobreajuste en subconjuntos $T \\subset D$ específicos. Una vez se hacen las $k$ evaluaciones, se promedian las métricas obtenidas para obtener una mejor noción del desempeño del modelo.\n",
    "\n",
    "Esta estrategia es más robusta que la **validación normal** anteriormente mencionada, sin embargo tiene el problema de tener un mayor orden computacional, dado que tiene que correr $k$ entrenamientos en lugar de uno.\n",
    "\n",
    "En la experimentación se decidió fijar $k=10$.\n",
    "\n",
    "#### 2.4.3. Métricas de evaluación\n",
    "***\n",
    "Se utilizaron múltiples métricas para determinar la \"calidad\" o \"eficacia\" de los clasificadores entrenados. A continuación, una breve descripción de las mismas:\n",
    "\n",
    "##### 2.4.3.1 Accuracy\n",
    "***\n",
    "La **accuracy** o **exactitud** hace referencia a la cantidad de aciertos que el clasificador tuvo en relación al total de clasificaciones que realizó durante la evaluación. Para definir **accuracy**, se utilizan las siguientes nociones:\n",
    "- Sea $D$ el conjunto de datos, $C_D$ el conjunto de posibles clasificaciones en $D$ y $|C_D| = n$\n",
    "- Sea $t_i : i \\in [1..n]$ la cantidad de clasificaciones para la clase $i$ que fueron correctas\n",
    "- Sea $f_i : i \\in [1..n]$ la cantidad de clasificaciones para la clase $i$ que fueron incorrectas\n",
    "\n",
    "$$ accuracy = \\frac{\\sum_{i=1}^{n} t_i}{\\sum_{i=1}^{n} t_i + f_i}$$\n",
    "\n",
    "Se observa que **accuracy** no es una muy buena medida de performance, ya que depende mucho del conjunto de datos que se evalúe, pudiendo dar buenos resultados a un clasificador malo. Teniendo esto en cuenta, se utilizó esta métrica solo para tener una noción general del desempeño de un clasificador, dandole más peso a las métricas definidas a continuación.\n",
    "\n",
    "##### 2.4.3.2 Matriz de Confusión\n",
    "***\n",
    "La **matriz de confusión** es una matriz que permite almacenar todas las clasificaciones realizadas en una evaluación, basándose en cada resultado y su respectivo valor original. La estructura de la matriz es la siguiente:\n",
    "\n",
    "- Sea $D =$ Conjunto de datos\n",
    "- Sea $C_D =$ Conjunto de clasificaciones para $d \\in D$ \n",
    "- Sea $|C_D| = n$ cantidad de posibles clasificaciones en $C_D$\n",
    "- Sea $M$ la matriz de confusión para una evaluación definida como:\n",
    "\n",
    "$$M = \\begin{bmatrix}\n",
    "    x_{11} & x_{12} & \\dots  & x_{1n} \\\\\n",
    "    x_{21} & x_{22} & \\dots  & x_{2n} \\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    x_{n1} & x_{n2} & \\dots  & x_{nn}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "- Entonces $x_{ij} \\in M : i,j \\in [1..n]$ representa la cantidad de clasificaciones que originalmente eran **clase $i$** y que fueron clasificadas en la evaluación como **clase $j$**.\n",
    "\n",
    "De esta forma, en una matriz cuadrada de dimensión $n$, se pueden centralizar todas las clasificaciones realizadas y su relación con respecto a cada clase.\n",
    "\n",
    "En sí misma, la matriz de confusión no representa una métrica sino una herramienta para calcular otras métricas, las cuales serán detalladas a continuación. De todas formas, una matriz de confusión de tamaño razonable puede aportar información general sobre el desempeño del clasificador, sólo con mirarla por arriba (en la siguiente subsección se detalla como).\n",
    "\n",
    "##### 2.4.3.3 Precision, Recall, Fall-off, F-measure\n",
    "***\n",
    "Existen cuatro medidas que, si bien siguen una fórmula similar a la de **accuracy**, son mucho menos sensibles al ruido en el conjunto de datos $D$, ya que operan **por clase**. Antes de detallar cada una, se repasan ciertas nociones básicas utilizadas en la definición de cada métrica.\n",
    "\n",
    "Retomando el punto anterior, la matriz de confusión permite calcular para cada clase $c_i$, cuatro valores indispensables:\n",
    "- Los **verdaderos positivos** en la clase $c_i$ (denotados como $t_i$), son aquellos ejemplos que originalmente son clase $c_i$ y fueron clasificados correctamente en la evaluación como clase $c_i$. Para calcularlos utilizando la matriz de confusión, simplemente hay que tomar la celda $M(i,i)$ para la clase $c_i$.\n",
    "\n",
    "$$ t_i = M(i,i) $$\n",
    "\n",
    "- Los **falsos positivos** en la clase $c_i$ (denotados como $f_i$), son aquellos ejemplos que originalmente son clase $c_j : j \\neq i$ y fueron clasificados incorrectamente en la evaluación como clase $c_i$. Para calcularlos utilizando la matriz de confusión, simplemente hay que tomar la fila $M_{(i,)}$ para la clase $c_i$, y sumar todos sus valores (excepto la celda $M(i,i)$, que corresponde a los verdaderos positivos).\n",
    "\n",
    "$$ f_i = \\sum_{j=1, j \\neq i}^{n} M(i,j) $$\n",
    "\n",
    "- Los **verdaderos negativos** en la clase $c_i$ (denotados como $\\bar{t_i}$), son aquellos ejemplos que originalmente no son clase $c_i$ y fueron clasificados en la evaluación como clase $c_j : j \\neq i$. Cabe destacar que la clasificación como $c_j$ puede ser correcta o no, lo importante es que sea consistente en relación a $c_i$. Para calcularlos utilizando la matriz de confusión, simplemente hay que tomar la matriz adjunta a los verdaderos positivos de $c_i$ y sumar todas sus entradas. Dicha matriz se define como $M_{ii}$ y contiene todas las entradas de $M$ excepto la fila $i$ y la columna $i$.\n",
    "\n",
    "$$ \\bar{t_i} = \\sum_{j=1}^{n-1} \\sum_{k=1}^{n-1} M_{ii}(j,k) $$\n",
    "\n",
    "- Los **falsos negativos** en la clase $c_i$ (denotados como $\\bar{f_i}$), son aquellos ejemplos que originalmente son clase $c_i$ y fueron clasificados incorrectamente en la evaluación como clase $c_j : j \\neq i$. Para calcularlos utilizando la matriz de confusión, simplemente hay que tomar la columna $M_{(,i)}$ para la clase $c_i$, y sumar todos sus valores (excepto la celda $M(i,i)$, que corresponde a los verdaderos positivos).\n",
    "\n",
    "$$ \\bar{f_i} = \\sum_{j=1, j \\neq i}^{n} M(j,i) $$\n",
    "\n",
    "Teniendo en cuenta dichas definiciones, se pasa a definir las métricas utilizadas:\n",
    "- **Precision**\n",
    "> - La **precision** o precisión de una **clase $c_i$** hace referencia a la cantidad de clasificaciones correctas para dicha clase, en relación a la cantidad de clasificaciones totales (correctas e incorrectas) para dicha clase.\n",
    "> - La precision permite determinar \"que tan bien se clasifica una clase\". En otras palabras, que tan poco se equivoca el clasificador en marcar un ejemplo como cierta clase.\n",
    "> - Oscila entre 0 y 1, siendo mejor cuanto **mayor** es.\n",
    "> - Se calcula como:\n",
    "> $$ precision(c_i) = \\frac{t_i}{t_i + f_i}$$\n",
    "\n",
    "- **Recall**\n",
    "> - La **recall** o recuperación de una **clase $c_i$** hace referencia a la cantidad de clasificaciones correctas para dicha clase, en relación a la cantidad de clasificaciones originales para dicha clase.\n",
    "> - La recall permite determinar \"que tan bien se clasifican elementos de otras clases respecto a una clase\". En otras palabras, que tan poco se equivoca el clasificador en marcar un ejemplo de otras clases como cierta clase.\n",
    "> - Oscila entre 0 y 1, siendo mejor cuanto **mayor** es.\n",
    "> - Se calcula como:\n",
    "> $$ recall(c_i) = \\frac{t_i}{t_i + \\bar{f_i}}$$\n",
    "\n",
    "- **Fall-off**\n",
    "> - La **fall-off** de una **clase $c_i$** hace referencia a la cantidad de clasificaciones incorrectas para dicha clase, en relación a la cantidad de clasificaciones complemento (correctas e incorrectas) de dicha clase.\n",
    "> - La fall-off permite determinar \"que tan mal se clasifica una clase\". En otras palabras, es la noción inversa de la recall: cuantos más ejemplos de otra clase sean clasificados como clase $c_i$, más aumenta fall-off.\n",
    "> - Oscila entre 0 y 1, siendo mejor cuanto **menor** es.\n",
    "> - Se calcula como:\n",
    "> $$ falloff(c_i) = \\frac{f_i}{f_i + \\bar{t_i}}$$\n",
    "\n",
    "- **F-measure**\n",
    "> - La **F-measure** o medida-F de una **clase $c_i$** es una medida que relaciona **precision** y **recall**, oficiando de alguna forma como un representante de cierta clase.\n",
    "> - La F-measure permite determinar \"que tan bien se clasifica una clase y que tan poco se falla a la vez\". En otras palabras, es una relación proporcional entre la precision y la recall y por tanto es una buena métrica para determinar el desempeño del clasificador respecto a una clase.\n",
    "> - Oscila entre 0 y 1, siendo mejor cuanto **mayor** es.\n",
    "> - Se calcula como:\n",
    "> $$ Fmeasure(c_i) = \\frac{2 precision(c_i) recall(c_i)}{precision(c_i) + recall(c_i)}$$\n",
    "\n",
    "Si bien estas medidas ofrecen información más enriquecedora en comparación a las anteriormente mencionadas, cuentan con el \"defecto\" de aplicar por clase y no dar una medida general del clasificador. Para conjuntos $D$ con pocas clasificaciones en $C_D$ esto no es un gran problema, pero complica la comparación al aumentar la cantidad de clases. En la siguiente subsección se tratan métricas que tienen como objetivo mejorar este hecho.\n",
    "\n",
    "##### 2.4.3.4 Medidas macro y micro\n",
    "***\n",
    "Existen dos formas genéricas de establecer medidas representativas para un modelo sin importar la clase. En este escenario se implementaron ambas formas, siendo las siguientes:\n",
    "\n",
    "- **Promedios genéricos** \n",
    "> - El promedio genérico de una métrica dada consiste en la suma de las métricas para cada clase dividida por la cantidad de clases.\n",
    "> - Otorga una noción del desempeño general del clasificador en relación a la métrica dada. \n",
    "> - Sea $D$ el conjunto de datos\n",
    "> - Sea $C_D$ el conjuntos de posibles clases\n",
    "> - Sea $|C_D| = n$\n",
    "> - El promedio genérico se calcula como:\n",
    "> $$ metrica_{general} = \\frac{\\sum_{i=1}^{n} metrica(c_i)}{n}$$\n",
    "\n",
    "- **Promedios ponderados:**\n",
    "> - El promedio ponderado de una métrica dada consiste en la suma de las métricas para cada clase ponderada por la proporción de ejemplos en el conjunto de datos para dicha clase.\n",
    "> - Otorga una noción del desempeño del clasificador en relación a la métrica dada, ignorando el ruido generado por mal desempeño en clases con menor cantidad de ejemplos (en otras palabras, es particularmente útil ante conjuntos de datos con una distribución nada uniforme en las clasificaciones de sus ejemplos).\n",
    "> - Sea $D$ el conjunto de datos\n",
    "> - Sea $C_D$ el conjuntos de posibles clases\n",
    "> - Sea $|C_D| = n$\n",
    "> - Sea $c_i \\in C_D$ la i-ésima clase en $C_D$\n",
    "> - Sea $D_i \\subseteq D$ el conjunto de ejemplos clasificados con clase $c_i$\n",
    "> - El promedio ponderado se calcula como:\n",
    "> $$ metrica_{ponderada} = \\sum_{i=1}^{n} metrica(c_i) * \\frac{|D_i|}{|D|}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experimentación\n",
    "***\n",
    "En esta sección se detalla el conjunto de pruebas realizadas, agregandose observaciones pertinentes y comparaciones entre modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Metodología\n",
    "***\n",
    "\n",
    "Con el objetivo de evaluar las estrategias planteadas anteriormente y su efectividad, se probaron combinaciones de las mismas frente a los dos modelos desarrollados. La exprimentación se encaró diviendola en las siguientes etapas:\n",
    "\n",
    "1. **Configuraciones paramétricas:** Luego de llegar a un modelo relativamente libre de errores (al menos de errores identificados), se realizaron pruebas para múltiples configuraciones paramétricas, con el fin de comparar cuales de ellas resultaron en mejores clasificadores. En esta etapa se detallan los datos obtenidos. \n",
    "<br><br>\n",
    "2. **Elección y comparación de representantes:** A falta de suficientes corridas para generar agrupamientos de configuraciones, se compararon manualmente los resultados obtenidos en las pruebas de cada configuración paramétrica de la etapa anterior. En base a distintas métricas, se eligió a aquellos clasificadores con mejores y peores resultados, interpretando la razón de su eficacia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Configuraciones paramétricas\n",
    "***\n",
    "A continuación se adjuntan las distintas configuraciones paramétricas utilizadas al evaluar, sus motivaciones y sus resultados. Se realizan pequeñas observaciones sobre los mismos, quedando el análisis exhaustivo pendiente para la siguiente sección.\n",
    "\n",
    "Es importante destacar que a causa de el tamaño del conjunto *Covertype*, no fue posible probar todas las configuraciones paramétricas para el mismo. De hecho, todas las configuraciones que tratan atributos continuos como **intervalos variables** fueron omitidas, ya que el árbol crecía exponencialmente, creciendo también el tiempo de entrenamiento, imposibilitando la extracción de datos.\n",
    "\n",
    "#### 3.2.1. Evaluaciones\n",
    "***\n",
    "Se realizaron un total de **30 evaluaciones**. Las mismas se distribuyen según los siguientes parámetros:\n",
    "- Conjunto de datos utilizado (2 opciones: *Iris*, *CoverType*)\n",
    "- Tipo de modelo entrenado (2 opciones: **Árbol**, **Bosque**)\n",
    "- Estrategia de atributos continuos utilizada (3 opciones: **Intervalos fijos**, **Intervalos variables**, **Intervalos maximizando la ganancia**)\n",
    "- Medida de ganancia utilizada (3 opciones: **Ganancia**, **Ratio de ganancia**, **Reducción de impureza**)\n",
    "\n",
    "Si se multiplican todas las posibles opciones, deberían realizarse **36 evaluaciones**. No obstante, como se menciona anteriormente, se eliminaron todas aquellas evaluaciones en *CoverType* que trataran atributos continuos como **intervalos variables**.\n",
    "\n",
    "El método de evaluación empleado dependió del conjunto de datos. Dado que *Iris* cuenta con pocos ejemplos, se utilizó **validación cruzada** con $k=10$ particiones, con el objetivo de generar datos menos sensibles al ruido generado por una única partición. Por otra parte, por motivos de tamaño del conjunto y tiempo de entrenamiento, para *CoverType* se utilizó **validación normal**.\n",
    "\n",
    "**Notas:**\n",
    "- Cabe mencionar que los tiempos de entrenamiento fueron optimizados sobre el final del período de entrega, por lo que para una próxima edición podría ser viable utilizar **validación cruzada**.\n",
    "\n",
    "#### 3.2.2. Resultados\n",
    "***\n",
    "A continuación se adjuntan los resultados de dichos entrenamientos y sus respectivas evaluaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.2.1. Resultados por clasificador\n",
    "***\n",
    "Con el objetivo de facilitar la lectura, se desarrolló un *script* que permite seleccionar cualquiera de los **30 entrenamientos** realizados y obtener todas las métricas calculadas.\n",
    "\n",
    "**Notas:**\n",
    "- Para las validaciones cruzadas no se adjunta matriz de confusión, ya que se muestran las métricas promediadas en base a la cantidad de particiones y no las métricas de cada partición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style=\"text-align: center;\">Seleccione un caso para visualizar de la botonera</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d33ba59b47cb44a1a1642cfe63f58643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Box(children=(Button(button_style='warning', description='1', layout=Layout(margin='0px 16px 0px…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "         <div>           <style type=\"text/css\">           .tg  {border-collapse:collapse;border-spacing:0;}           .tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}           .tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}           .tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}           </style>           <table class=\"tg\">             <tr>               <th class=\"tg-0pky\"><strong>Botón</strong></th>               <th class=\"tg-0pky\" style=\"text-align: center;\"><strong>Descripción</strong></th>             </tr>             <tr>               <td class=\"tg-0pky\">1</td>               <td class=\"tg-0pky\">Árbol del conjunto Iris, Ganancia como medida, atributos continuos partiendo en intervalos fijos. Validación cruzada .</td>             </tr>             <tr>               <td class=\"tg-0pky\">2</td>               <td class=\"tg-0pky\">Árbol del conjunto Iris, GainRatio como medida, trata atributos continuos partiendo en intervalos fijos. Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">3</td>               <td class=\"tg-0pky\">Árbol del conjunto Iris, Impurity Reduction como medida, atributos continuos partiendo en intervalos fijos. Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">4</td>               <td class=\"tg-0pky\">Árbol del conjunto Iris, Ganancia como medida, atributos continuos partiendo en intervalos variables. Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">5</td>               <td class=\"tg-0pky\">Árbol del conjunto Iris, GainRatio como medida, atributos continuos partiendo en intervalos variables. Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">6</td>               <td class=\"tg-0pky\">Árbol del conjunto Iris, Impurity Reduction como medida, atributos continuos partiendo en intervalos variables. Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">7</td>               <td class=\"tg-0pky\">Árbol del conjunto Iris, Ganancia como medida, atributos continuos maximizando ganancia local (C4.5). Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">8</td>               <td class=\"tg-0pky\">Árbol del conjunto Iris, GainRatio como medida, atributos continuos maximizando ganancia local (C4.5). Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">9</td>               <td class=\"tg-0pky\">Árbol del conjunto Iris, Impurity Reduction como medida, atributos continuos maximizando ganancia local (C4.5). Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">10</td>               <td class=\"tg-0pky\">Bosque del conjunto Iris, Ganancia como medida, atributos continuos partiendo en intervalos fijos. Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">11</td>               <td class=\"tg-0pky\">Bosque del conjunto Iris, GainRatio como medida, atributos continuos partiendo en intervalos fijos. Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">12</td>               <td class=\"tg-0pky\">Bosque del conjunto Iris, Impurity Reduction como medida, atributos continuos partiendo en intervalos fijos. Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">13</td>               <td class=\"tg-0pky\">Bosque del conjunto Iris, Ganancia como medida, atributos continuos partiendo en intervalos variables. Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">14</td>               <td class=\"tg-0pky\">Bosque del conjunto Iris, GainRatio como medida, atributos continuos partiendo en intervalos variables. Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">15</td>               <td class=\"tg-0pky\">Bosque del conjunto Iris, Impurity Reduction como medida, atributos continuos partiendo en intervalos variables. Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">16</td>               <td class=\"tg-0pky\">Bosque del conjunto Iris, Ganancia como medida, atributos continuos maximizando ganancia local (C4.5). Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">17</td>               <td class=\"tg-0pky\">Bosque del conjunto Iris, GainRatio como medida, atributos continuos maximizando ganancia local (C4.5). Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">18</td>               <td class=\"tg-0pky\">Bosque del conjunto Iris, Impurity Reduction como medida, atributos continuos maximizando ganancia local (C4.5). Validación cruzada </td>             </tr>             <tr>               <td class=\"tg-0pky\">a</td>               <td class=\"tg-0pky\">Árbol del conjunto CoverType, Ganancia como medida, atributos continuos partiendo en intervalos fijos. Validación 80/20.</td>             </tr>             <tr>               <td class=\"tg-0pky\">b</td>               <td class=\"tg-0pky\">Árbol del conjunto CoverType, GainRatio como medida, atributos continuos partiendo en intervalos fijos. Validación 80/20</td>             </tr>             <tr>               <td class=\"tg-0pky\">c</td>               <td class=\"tg-0pky\">Árbol del conjunto CoverType, Impurity Reduction como medida, atributos continuos partiendo en intervalos fijos. Validación 80/20</td>             </tr>             <tr>               <td class=\"tg-0pky\">d</td>               <td class=\"tg-0pky\">Árbol del conjunto CoverType, Ganancia como medida, atributos continuos maximizando ganancia local (C4.5). Validación 80/20</td>             </tr>             <tr>               <td class=\"tg-0pky\">e</td>               <td class=\"tg-0pky\">Árbol del conjunto CoverType, GainRatio como medida, atributos continuos maximizando ganancia local (C4.5). Validación 80/20</td>             </tr>             <tr>               <td class=\"tg-0pky\">f</td>               <td class=\"tg-0pky\">Árbol del conjunto CoverType, Impurity Reduction como medida, atributos continuos maximizando ganancia local (C4.5). Validación 80/20</td>             </tr>             <tr>               <td class=\"tg-0pky\">g</td>               <td class=\"tg-0pky\">Bosque del conjunto CoverType, Ganancia como medida, atributos continuos partiendo en intervalos fijos. Validación 80/20</td>             </tr>             <tr>               <td class=\"tg-0pky\">h</td>               <td class=\"tg-0pky\">Bosque del conjunto CoverType, GainRatio como medida, atributos continuos partiendo en intervalos fijos. Validación 80/20</td>             </tr>             <tr>               <td class=\"tg-0pky\">i</td>               <td class=\"tg-0pky\">Bosque del conjunto CoverType, Impurity Reduction como medida, atributos continuos partiendo en intervalos fijos. Validación 80/20</td>             </tr>             <tr>               <td class=\"tg-0pky\">j</td>               <td class=\"tg-0pky\">Bosque del conjunto CoverType, Ganancia como medida, atributos continuos maximizando ganancia local (C4.5). Validación 80/20</td>             </tr>             <tr>               <td class=\"tg-0pky\">k</td>               <td class=\"tg-0pky\">Bosque del conjunto CoverType, GainRatio como medida, atributos continuos maximizando ganancia local (C4.5). Validación 80/20</td>             </tr>             <tr>               <td class=\"tg-0pky\">l</td>               <td class=\"tg-0pky\">Bosque del conjunto CoverType, Impurity Reduction como medida, atributos continuos maximizando ganancia local (C4.5). Validación 80/20</td>             </tr>           </table>         </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'getConfusionMatrix.py'; 'getConfusionMatrix' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-165a6b033525>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgetConfusionMatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'getConfusionMatrix.py'; 'getConfusionMatrix' is not a package"
     ]
    }
   ],
   "source": [
    "import getConfusionMatrix.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.2.2. Resultados generales\n",
    "***\n",
    "\n",
    "A continuación se adjunta una comparación general del total de resultados obtenidos, separando por conjunto de datos.\n",
    "\n",
    "**Notas:**\n",
    "- Se marca en **celeste** aquellos clasificadores con un mejor desempeño que la mayoría.\n",
    "- Se marca en **verde** aquellos clasificadores elegidos como los mejores dentro de su grupo.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Modelo</th>\n",
    "        <th>Continuos</th>\n",
    "        <th>Medida</th>\n",
    "        <th>|</th>\n",
    "        <th>Accuracy</th>\n",
    "        <th>Precision promediada</th>\n",
    "        <th>Precision ponderada</th>\n",
    "        <th>Recall promediada</th>\n",
    "        <th>Recall ponderada</th>\n",
    "        <th>Fall-off promediada</th>\n",
    "        <th>Fall-off ponderada</th>\n",
    "        <th>F-measure promediada</th>\n",
    "        <th>F-measure ponderada</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Árbol</td>\n",
    "        <td>Fijo</td>\n",
    "        <td>Ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.873</td>\n",
    "        <td>0.884</td>\n",
    "        <td>0.898</td>\n",
    "        <td>0.889</td>\n",
    "        <td>0.873</td>\n",
    "        <td>0.059</td>\n",
    "        <td>0.060</td>\n",
    "        <td>0.873</td>\n",
    "        <td>0.875</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Árbol</td>\n",
    "        <td>Fijo</td>\n",
    "        <td>Ratio de Ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.893</td>\n",
    "        <td>0.897</td>\n",
    "        <td>0.923</td>\n",
    "        <td>0.906</td>\n",
    "        <td>0.893</td>\n",
    "        <td>0.051</td>\n",
    "        <td>0.048</td>\n",
    "        <td>0,879</td>\n",
    "        <td>0,893</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Árbol</td>\n",
    "        <td>Fijo</td>\n",
    "        <td>Reducción de Impureza</td>\n",
    "        <td>|</td>\n",
    "        <td>0.886</td>\n",
    "        <td>0.880</td>\n",
    "        <td>0.920</td>\n",
    "        <td>0.905</td>\n",
    "        <td>0.886</td>\n",
    "        <td>0.050</td>\n",
    "        <td>0.039</td>\n",
    "        <td>0,872</td>\n",
    "        <td>0,888</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Árbol</td>\n",
    "        <td>Variable</td>\n",
    "        <td>Ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.906</td>\n",
    "        <td>0.918</td>\n",
    "        <td>0.926</td>\n",
    "        <td>0.912</td>\n",
    "        <td>0.906</td>\n",
    "        <td>0.046</td>\n",
    "        <td>0.047</td>\n",
    "        <td>0,903</td>\n",
    "        <td>0,906</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Árbol</td>\n",
    "        <td>Variable</td>\n",
    "        <td>Ratio de Ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.933</td>\n",
    "        <td>0.939</td>\n",
    "        <td>0.944</td>\n",
    "        <td>0.938</td>\n",
    "        <td>0.933</td>\n",
    "        <td>0.033</td>\n",
    "        <td>0.037</td>\n",
    "        <td>0,932</td>\n",
    "        <td>0,933</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Árbol</td>\n",
    "        <td>Variable</td>\n",
    "        <td>Reducción de Impureza</td>\n",
    "        <td>|</td>\n",
    "        <td>0.920</td>\n",
    "        <td>0.931</td>\n",
    "        <td>0.947</td>\n",
    "        <td>0.932</td>\n",
    "        <td>0.920</td>\n",
    "        <td>0.037</td>\n",
    "        <td>0.030</td>\n",
    "        <td>0,917</td>\n",
    "        <td>0,919</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #95dcd4;\">\n",
    "        <td>Árbol</td>\n",
    "        <td>Maximizando ganancia</td>\n",
    "        <td>Ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.953</td>\n",
    "        <td>0.958</td>\n",
    "        <td>0.964</td>\n",
    "        <td>0.950</td>\n",
    "        <td>0.953</td>\n",
    "        <td>0.022</td>\n",
    "        <td>0.019</td>\n",
    "        <td>0,948</td>\n",
    "        <td>0,953</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Árbol</td>\n",
    "        <td>Maximizando ganancia</td>\n",
    "        <td>Ratio de ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.946</td>\n",
    "        <td>0.953</td>\n",
    "        <td>0.955</td>\n",
    "        <td>0.950</td>\n",
    "        <td>0.946</td>\n",
    "        <td>0.026</td>\n",
    "        <td>0.025</td>\n",
    "        <td>0,946</td>\n",
    "        <td>0,946</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #95dcd4;\">\n",
    "        <td>Árbol</td>\n",
    "        <td>Maximizando ganancia</td>\n",
    "        <td>Reducción de Impureza</td>\n",
    "        <td>|</td>\n",
    "        <td>0.953</td>\n",
    "        <td>0.954</td>\n",
    "        <td>0.957</td>\n",
    "        <td>0.952</td>\n",
    "        <td>0.953</td>\n",
    "        <td>0.023</td>\n",
    "        <td>0.025</td>\n",
    "        <td>0,951</td>\n",
    "        <td>0,953</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bosque</td>\n",
    "        <td>Fijo</td>\n",
    "        <td>Ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.913</td>\n",
    "        <td>0.930</td>\n",
    "        <td>0.932</td>\n",
    "        <td>0.905</td>\n",
    "        <td>0.913</td>\n",
    "        <td>0.044</td>\n",
    "        <td>0.046</td>\n",
    "        <td>0,906</td>\n",
    "        <td>0,912</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bosque</td>\n",
    "        <td>Fijo</td>\n",
    "        <td>Ratio de Ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.906</td>\n",
    "        <td>0.909</td>\n",
    "        <td>0.925</td>\n",
    "        <td>0.903</td>\n",
    "        <td>0.906</td>\n",
    "        <td>0.045</td>\n",
    "        <td>0.044</td>\n",
    "        <td>0,892</td>\n",
    "        <td>0,905</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bosque</td>\n",
    "        <td>Fijo</td>\n",
    "        <td>Reducción de Impureza</td>\n",
    "        <td>|</td>\n",
    "        <td>0.906</td>\n",
    "        <td>0.913</td>\n",
    "        <td>0.934</td>\n",
    "        <td>0.918</td>\n",
    "        <td>0.906</td>\n",
    "        <td>0.042</td>\n",
    "        <td>0.034</td>\n",
    "        <td>0,900</td>\n",
    "        <td>0,908</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bosque</td>\n",
    "        <td>Variable</td>\n",
    "        <td>Ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.913</td>\n",
    "        <td>0.904</td>\n",
    "        <td>0.932</td>\n",
    "        <td>0.915</td>\n",
    "        <td>0.913</td>\n",
    "        <td>0.040</td>\n",
    "        <td>0.035</td>\n",
    "        <td>0,900</td>\n",
    "        <td>0,915</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bosque</td>\n",
    "        <td>Variable</td>\n",
    "        <td>Ratio de Ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.900</td>\n",
    "        <td>0.908</td>\n",
    "        <td>0.914</td>\n",
    "        <td>0.903</td>\n",
    "        <td>0.900</td>\n",
    "        <td>0.047</td>\n",
    "        <td>0.046</td>\n",
    "        <td>0,898</td>\n",
    "        <td>0,899</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bosque</td>\n",
    "        <td>Variable</td>\n",
    "        <td>Reducción de Impureza</td>\n",
    "        <td>|</td>\n",
    "        <td>0.880</td>\n",
    "        <td>0.869</td>\n",
    "        <td>0.897</td>\n",
    "        <td>0.882</td>\n",
    "        <td>0.880</td>\n",
    "        <td>0.056</td>\n",
    "        <td>0.056</td>\n",
    "        <td>0,866</td>\n",
    "        <td>0,881</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bosque</td>\n",
    "        <td>Maximizando ganancia</td>\n",
    "        <td>Ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.946</td>\n",
    "        <td>0.945</td>\n",
    "        <td>0.953</td>\n",
    "        <td>0.950</td>\n",
    "        <td>0.946</td>\n",
    "        <td>0.025</td>\n",
    "        <td>0.024</td>\n",
    "        <td>0,944</td>\n",
    "        <td>0,946</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bosque</td>\n",
    "        <td>Maximizando ganancia</td>\n",
    "        <td>Ratio de ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.927</td>\n",
    "        <td>0.919</td>\n",
    "        <td>0.941</td>\n",
    "        <td>0.915</td>\n",
    "        <td>0.926</td>\n",
    "        <td>0.038</td>\n",
    "        <td>0.042</td>\n",
    "        <td>0,906</td>\n",
    "        <td>0,926</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #afdb99;\">\n",
    "        <td>Bosque</td>\n",
    "        <td>Maximizando ganancia</td>\n",
    "        <td>Reducción de Impureza</td>\n",
    "        <td>|</td>\n",
    "        <td>0.960</td>\n",
    "        <td>0.965</td>\n",
    "        <td>0.964</td>\n",
    "        <td>0.953</td>\n",
    "        <td>0.960</td>\n",
    "        <td>0.021</td>\n",
    "        <td>0.024</td>\n",
    "        <td>0,955</td>\n",
    "        <td>0,959</td>\n",
    "    </tr>\n",
    "    <caption>Tabla 1 - Resultados de entrenamiento de conjunto <b>Iris</b> para cada configuración paramétrica</caption>\n",
    "</table>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Modelo</th>\n",
    "        <th>Continuos</th>\n",
    "        <th>Medida</th>\n",
    "        <th>|</th>\n",
    "        <th>Accuracy</th>\n",
    "        <th>Precision promediada</th>\n",
    "        <th>Precision ponderada</th>\n",
    "        <th>Recall promediada</th>\n",
    "        <th>Recall ponderada</th>\n",
    "        <th>Fall-off promediada</th>\n",
    "        <th>Fall-off ponderada</th>\n",
    "        <th>F-measure promediada</th>\n",
    "        <th>F-measure ponderada</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Árbol</td>\n",
    "        <td>Fijo</td>\n",
    "        <td>Ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.635</td>\n",
    "        <td>0.658</td>\n",
    "        <td>0.638</td>\n",
    "        <td>0.385</td>\n",
    "        <td>0.635</td>\n",
    "        <td>0.074</td>\n",
    "        <td>0.222</td>\n",
    "        <td>0,434</td>\n",
    "        <td>0,620</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Árbol</td>\n",
    "        <td>Fijo</td>\n",
    "        <td>Ratio de Ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.685</td>\n",
    "        <td>0.682</td>\n",
    "        <td>0.684</td>\n",
    "        <td>0.430</td>\n",
    "        <td>0.685</td>\n",
    "        <td>0.066</td>\n",
    "        <td>0.195</td>\n",
    "        <td>0,481</td>\n",
    "        <td>0,670</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Árbol</td>\n",
    "        <td>Fijo</td>\n",
    "        <td>Reducción de Impureza</td>\n",
    "        <td>|</td>\n",
    "        <td>0.633</td>\n",
    "        <td>0.619</td>\n",
    "        <td>0.633</td>\n",
    "        <td>0.390</td>\n",
    "        <td>0.633</td>\n",
    "        <td>0.075</td>\n",
    "        <td>0.225</td>\n",
    "        <td>0,436</td>\n",
    "        <td>0,618</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #95dcd4;\">\n",
    "        <td>Árbol</td>\n",
    "        <td>Maximizando ganancia</td>\n",
    "        <td>Ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.654</td>\n",
    "        <td>0.651</td>\n",
    "        <td>0.653</td>\n",
    "        <td>0.527</td>\n",
    "        <td>0.654</td>\n",
    "        <td>0.069</td>\n",
    "        <td>0.198</td>\n",
    "        <td>0,555</td>\n",
    "        <td>0,648</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #95dcd4;\">\n",
    "        <td>Árbol</td>\n",
    "        <td>Maximizando ganancia</td>\n",
    "        <td>Ratio de ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.693</td>\n",
    "        <td>0.654</td>\n",
    "        <td>0.692</td>\n",
    "        <td>0.491</td>\n",
    "        <td>0.693</td>\n",
    "        <td>0.062</td>\n",
    "        <td>0.171</td>\n",
    "        <td>0,518</td>\n",
    "        <td>0,683</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #afdb99;\">\n",
    "        <td>Árbol</td>\n",
    "        <td>Maximizando ganancia</td>\n",
    "        <td>Reducción de Impureza</td>\n",
    "        <td>|</td>\n",
    "        <td>0.655</td>\n",
    "        <td>0.652</td>\n",
    "        <td>0.653</td>\n",
    "        <td>0.531</td>\n",
    "        <td>0.655</td>\n",
    "        <td>0.069</td>\n",
    "        <td>0.197</td>\n",
    "        <td>0,556</td>\n",
    "        <td>0,648</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bosque</td>\n",
    "        <td>Fijo</td>\n",
    "        <td>Ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.609</td>\n",
    "        <td>0.339</td>\n",
    "        <td>0.651</td>\n",
    "        <td>0.390</td>\n",
    "        <td>0.609</td>\n",
    "        <td>0.071</td>\n",
    "        <td>0.154</td>\n",
    "        <td>0,344</td>\n",
    "        <td>0,621</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bosque</td>\n",
    "        <td>Fijo</td>\n",
    "        <td>Ratio de Ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.600</td>\n",
    "        <td>0.332</td>\n",
    "        <td>0.640</td>\n",
    "        <td>0.389</td>\n",
    "        <td>0.600</td>\n",
    "        <td>0.073</td>\n",
    "        <td>0.162</td>\n",
    "        <td>0,334</td>\n",
    "        <td>0,610</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bosque</td>\n",
    "        <td>Fijo</td>\n",
    "        <td>Reducción de Impureza</td>\n",
    "        <td>|</td>\n",
    "        <td>0.607</td>\n",
    "        <td>0.347</td>\n",
    "        <td>0.648</td>\n",
    "        <td>0.414</td>\n",
    "        <td>0.607</td>\n",
    "        <td>0.072</td>\n",
    "        <td>0.156</td>\n",
    "        <td>0,353</td>\n",
    "        <td>0,618</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bosque</td>\n",
    "        <td>Maximizando ganancia</td>\n",
    "        <td>Ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.681</td>\n",
    "        <td>0.416</td>\n",
    "        <td>0.705</td>\n",
    "        <td>0.459</td>\n",
    "        <td>0.681</td>\n",
    "        <td>0.060</td>\n",
    "        <td>0.136</td>\n",
    "        <td>0,429</td>\n",
    "        <td>0,689</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bosque</td>\n",
    "        <td>Maximizando ganancia</td>\n",
    "        <td>Ratio de ganancia</td>\n",
    "        <td>|</td>\n",
    "        <td>0.680</td>\n",
    "        <td>0.411</td>\n",
    "        <td>0.692</td>\n",
    "        <td>0.433</td>\n",
    "        <td>0.680</td>\n",
    "        <td>0.062</td>\n",
    "        <td>0.152</td>\n",
    "        <td>0,416</td>\n",
    "        <td>0,681</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bosque</td>\n",
    "        <td>Maximizando ganancia</td>\n",
    "        <td>Reducción de Impureza</td>\n",
    "        <td>|</td>\n",
    "        <td>0.689</td>\n",
    "        <td>0.438</td>\n",
    "        <td>0.711</td>\n",
    "        <td>0.483</td>\n",
    "        <td>0.689</td>\n",
    "        <td>0.059</td>\n",
    "        <td>0.137</td>\n",
    "        <td>0,454</td>\n",
    "        <td>0,696</td>\n",
    "    </tr>\n",
    "    <caption>Tabla 2 - Resultados de entrenamiento de conjunto <b>CoverType</b> para cada configuración paramétrica</caption>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Elección y comparación de representantes\n",
    "***\n",
    "A continuación se presenta un análisis de los resultados obtenidos, separandose en dos procesos: elección y comparación.\n",
    "\n",
    "#### 3.3.1. Elección\n",
    "***\n",
    "Para determinar cuales fuern los clasificadores con mejor desempeño (denominados \"representantes\") frente a los posibles candidatos se siguió el siguiente proceso:\n",
    "1. Se agruparon elementos dada su similitud en base a **accuracy** y *promedios generales* de **precision**, **recall**, **fall-off** y **F-measure**.\n",
    "2. Una vez obtenidos dichos grupos, se generaron subgrupos acorde a comparaciones entre otros subgrupos y los *promedios ponderados*.\n",
    "3. Por último, se buscaron desviaciones en los mismos (como malos promedios generales y buenos promedios ponderados, precision y recall bajos para alguna clase, fall-off alto para alguna otra clase, etc.) determinando que *aquellos clasificadores con menos desviaciones serían elegidos como representantes.*\n",
    "\n",
    "A continuación se adjuntan gráficas que muestran las métricas para cada generadas con el fin de facilitar la lectura, en las mismas se puede apreciar más visualmente una comparación de las métricas obtenidas en cada representante. Se decidió mostrar para cada conjunto al representante elegido y compararlo con los mejores resultados obtenidos para cada modelo (Árbol, Bosque) y para cada estrategia al tratar con atributos continuos (Fijo, Maximizando ganancia).\n",
    "\n",
    "<div style=\"margin-top: 16px; margin-bottom: 16px;\">\n",
    "    <div style=\"display: inline-block; width: 99%; text-align: center;\">\n",
    "        <img src=\"img/iris.png\" />\n",
    "        <label style=\"margin-top: 16px; font-size: 16px; font-family: monospace;\"> Figura 3.3.1.1. - Comparaciones con el dataset Iris</label>\n",
    "    </div>\n",
    "    <div style=\"display: inline-block; width: 99%; text-align: center;\">\n",
    "        <img src=\"img/covertype.png\" />\n",
    "        <label style=\"margin-top: 16px; font-size: 16px; font-family: monospace;\"> Figura 3.3.1.2. - Comparaciones con el dataset Covertype</label>\n",
    "    </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2. Comparación\n",
    "***\n",
    "\n",
    "**Observaciones generales:**\n",
    "\n",
    "- Sobre los parámetros:\n",
    "> 1. La *estrategia para interpretar valores continuos* con mejores resultados fue **maximizar la ganancia**, independiente al resto de configuraciones paramétricas.\n",
    "> 2. Las distintas *medidas de ganancia* no parecen haber incidido de forma notable en los resultados.\n",
    "\n",
    "- Sobre los resultados:\n",
    "> 1. Los resultados en *Iris* fueron similares en general.\n",
    "> 2. Los resultados en *Covertype* también fueron similares, no obstante los árboles ofrecieron un mejor rendimiento de forma consistente.\n",
    "> 3. Algunos resultados tuvieron una gran diferencia entre sus promedios generales y promedios ponderados (siendo los últimos bastante más altos).\n",
    "> 4. En *CoverType* los bosques clasifican los elementos de clase 1, 2 y 3 mejor que los árboles. Sin embargo, tienen una muy baja **precision** y muy alto **fall-off** para los elementos de clase 4, 5, 6 y 7. \n",
    "\n",
    "Tomando en cuenta la información anterior, se determinó que los mejores clasificadores, a nivel general, fueron **árboles** que partieron atributos continuos en **2 intervalos maximizando la ganancia** y utilizaron **ganancia** o **reducción de impureza** como medida.\n",
    "\n",
    "Es importante aclarar que dichas elecciones son arbitrarias, aunque se intentó minimizar esta posibilidad. Dadas las características de los conjuntos de entrenamiento y los clasificadores, parece ser coherente que muchos hayan tenido resultados similares aunque trabajaran de forma distinta.\n",
    "\n",
    "También es importante observar que las evaluaciones utilizadas, especialmente en *CoverType*, pueden estar sujetas a ruido y por tanto ofrecer información \"tramposa\". El implementar técnicas de análisis estadístico como **Tests de Friedman** entre múltiples evaluaciones para una misma configuración, podría ayudar a reducir esto. También el correr **validaciones cruzadas** en *CoverType* podría dar mejores nociones sobre cada clasificador.\n",
    "\n",
    "En cualquier caso, a continuación se adjunta una serie de interpretaciones, producto de las observaciones hechas a los resultados. Dichas interpretaciones se basan en fundamentos teóricos y sensaciones empíricas, por lo que no escalan a algo más que eso, interpretaciones.\n",
    "\n",
    "**Interpretaciones:**\n",
    "\n",
    "- Sobre los parámetros:\n",
    "> 1. No se puede decir mucho respecto a la estrategia de **intervalos variables**, ya que sólo fue implementada en *Iris*, el cual cuenta con pocos ejemplos. No obstante, es lógico que la **maximización de ganancia** sea mejor que **intervalos fijos**, ya que ambas estrategias generan solamente 2 intervalos pero la primera siempre genera intervalos con mayor ganancia que la segunda, por lo que el clasificador resultante es mejor.\n",
    "\n",
    "- Sobre los resultados:\n",
    "> 1. Muchos de los resultados en *CoverType* no necesariamente reflejan la realidad, esto es debido a la aleatoriedad de la validación (80/20). Una validación cruzada en 10 intervalos (Como la realizada en *Iris*) podría dar un intervalo de certeza  mayor sobre las conjeturas basadas en las interpretaciones de los candidatos.\n",
    "> 2. La diferencia entre promedios generales y ponderados se da debido a que las clases 4, 5, 6 y 7 cuentan con una mucho menor cantidad de elementos en comparación a las clases 1, 2 y 3. Al tener peor desempeño en las clases de menor proporción, los promedios ponderados dan mejor resultado por darle menos importancia a dichas clases.\n",
    "> 3. En general las métricas descienden para las clases 4, 5, 6 y 7. Esto podría interpretarse como una dificultad para clasificadores basados en árboles de decisión, ya que parecen tener tendencia por clasificar en clases 1, 2 y 3, las cuales presentan una proporción mucho mayor a las otras clases anteriormente mencionadas.\n",
    "> 4. Existen otras interpretaciones para justificar las fallas en las clasificaciones de *CoverType*. Por ejemplo, el haber revertido el one-hot encoding, especialmente en el atributo *soil_type*, y haber interpretado dichos atributos como continuos, puede haber impactado notablemente en los resultados, especificamente sobre los de clasificaciones en clases 4, 5, 6 y 7. La cantidad de elementos pertenecientes a las mismas es muy baja y la capacidad de diferenciar con mejor granularidad y menor sesgo inducido sobre el atributo *soil_type* podría haber ayudado a encontrar relaciones entre el mismo y la clasificación del terreno.\n",
    "> 5. Tomando en cuenta el hecho de que los bosques clasificaron peor los elementos de clase 4, 5, 6 y 7 pero mejor los de clase 1, 2 y 3, puede interpretarse que el clasificar elementos binariamente para cada clase en este tipo de escenarios, es algo contraproducente. Podría ser que la mayoría de clasificaciones acaben en votaciones (a causa de que no ocurre la situación ideal en la cual un árbol clasifique con *True* y los demás con *False*) y en cualquier árbol un resultado *False* da muy poca información (básicamente \"no tiene características de elementos de esta clase, pero puede tener características de cualquier otro\"). Esto para un conjunto de atributos y clasificaciones con alta complejidad podría acabar disminuyendo enormemente la calidad del clasificador cuando no es fácil detectar atributos con muy baja impureza que determinen fuertemente la pertenencia a una clase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusiones\n",
    "***\n",
    "\n",
    "#### 4.1. Respecto a los Modelos\n",
    "***\n",
    "A priori los **bosques de decisión** no parecen haber representado algún tipo de mejora frente a los **árboles de decisión** (en todo caso, cuando no ofrecieron un resultado similar, fue uno peor). Esto se fundamenta en la dificultad de elegir un buen algoritmo de votación, sumado a la necesidad de haber implementado una elección aleatoria entre clasificaciones de igual probabilidad.\n",
    "\n",
    "Se concluye que los **bosques de decisión** que utilizan árboles binarios para una clasificación multiclase no representan una buen modelo si no se cuenta con un algoritmo de votación robusto.\n",
    "\n",
    "#### 4.2. Respecto a los Atributos\n",
    "***\n",
    "Se pudo comprobar empíricamente que los **árboles de decisión** no trabajan bien con una gran cantidad de atributos. De hecho, en coherencia con el sesgo de las hipótesis elegidas, los árboles simples suelen preferirse.\n",
    "\n",
    "Teniendo esto en cuenta, se deshizo el **one hot encoding** de dos atributos, reduciendo la cantidad total de atributos y mejorando exponencialmente el tiempo de entrenamiento. No obstante, el hacer esto puede haber impactado en el desempeño de los clasificadores, ya que un atributo con 40 posibles valores pasó a tener 2.\n",
    "\n",
    "Se concluye que en escenarios donde el **one hot encoding** sea viable o necesario para algunos atributos, la utilización de **árboles de decisión** no tendrá el mejor rendimiento posible, ya que es de alguna forma \"incompatible\" con esta noción.\n",
    "\n",
    "#### 4.3. Respecto a los Parámetros\n",
    "***\n",
    "El tratamiento de atributos continuos representó un reto, especialmente al tener un conjunto de entrenamiento tan voluminoso como **CoverType**. Para atributos con gran densidad de valores, el partir en 2 intervalos implicó una gran pérdida de información. Por otra parte, la estrategia de partir en intervalos variables podría haber hecho frente a esta pérdida, pero al tener tantos posibles valores el tamaño del árbol escaló exponencialmente, descartándose la posibilidad de implementarlo.\n",
    "\n",
    "Se concluye que en escenarios donde se tenga gran cantidad de ejemplos y muchos cantidad de atributos continuos con gran densidad, la utilización de **árboles de decisión** puede no tener el mejor desempeño.\n",
    "\n",
    "#### 4.4. Respecto a los Resultados\n",
    "***\n",
    "Como observación primordial, se notó que los resultados en *CoverType* fueron peores con respecto a *Iris*. A priori es un hecho razonable, ya que los árboles de decisión intuitivamente se ajustan mejor a pocos atributos y pocos ejemplos. No obstante, esto es solo una posible interpretación. En la sección anterior se generaron otras interpretaciones y, con la información actual, no es posible determinar si alguna es correcta.\n",
    "\n",
    "Se concluye que para poder establecer más información, es necesario comparar el desempeño de otros modelos de aprendizaje sobre un conjunto de datos similar, con el fin de entender si la baja eficiencia de los árboles fue producto de la mala compatibilidad del conjunto de datos con clasificadores de árbol o si tuvo que ver con decisiones de diseño, entre otras posibilidades. \n",
    "\n",
    "#### 4.5. Posibles mejoras\n",
    "***\n",
    "Para cerrar, se adjunta una lista de mejoras consideradas a la implementación actual:\n",
    "- No restringir el uso a 10 valores para *intervalos variables* y *c4.5*. Contemplar todo el conjunto de valores conlleva un mayor orden computacional pero garantiza resultados de igual o mayor calidad.\n",
    "- Agregar otro parámetro que altere la estrategia \"Maximizando ganancia* (C4.5), a maximizar por las otras medidas (*Ratio de Ganancia* y *Reducción de Impureza*)\n",
    "- No deshacer el one-hot encoding para los datos en *Covertype*. Esto incrementaría enormemente el orden computacional y la complejidad de los árboles generados pero daría resultados de mayor calidad. Como mínimo sería deseable modificar el algoritmo para que trate esos atributos como discretos (y no continuos).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
