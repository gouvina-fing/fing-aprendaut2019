{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega 3 - Clasificadores (Naive Bayes, KNN)\n",
    "\n",
    "### Grupo 07:\n",
    "     - Renzo Gambone C.I. 5.155.486-4\n",
    "     - Germán Ouviña C.I. 4.823.566-1\n",
    "     - Leandro Rodríguez C.I 4.691.736-4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción\n",
    "***\n",
    "### 1.1. Objetivo\n",
    "***\n",
    "El objetivo de esta tarea fue implementar clasificadores basados en dos tipos de aprendizaje: **aprendizaje bayesiano** y **aprendizaje basado en casos**. Más especificamente, los modelos utilizados fueron **bayes sencillo** y **k vecinos más cercanos** respectivamente. Una vez generados distintos clasificadores en base a ciertos parámetros, se evaluó la performance de los mismos utilizando distintos tipos de métricas y se compararon dichas evaluaciones con el fin de determinar cual modelo se ajustó mejor a cada escenario. Como agregado, se compararon los resultados obtenidos con los resultados obtenidos en el laboratorio anterior.\n",
    "\n",
    "En términos formales, los parámetros del problema se reducen a lo siguiente:\n",
    "- **Tarea *T*:** Clasificar ejemplos de un conjunto restringido a cierto formato dado.\n",
    "- **Experiencia *E*:** Conjunto de datos del formato apropiado con ejemplos previamente clasificados.\n",
    "- **Performance *P*:** Múltiples tipos de medidas (las cuales se profundizan en la sección 3).\n",
    "\n",
    "### 1.2. Entrega\n",
    "***\n",
    "La entrega de esta tarea consta de dos grandes componentes:\n",
    "- **Informe** en formato de Jupyter Notebook (este informe).\n",
    "- **Programa** que permite entrenar clasificadores, evaluar su desempeño y clasificar nuevos ejemplos.\n",
    "\n",
    "El objetivo del informe es centralizar la información relativa a la construcción de los distintos modelos, así como los datos obtenidos mediante pruebas realizadas con varias configuraciones paramétricas. Como agregado opcional, se adjuntan algunos scripts para ayudar a la lectura o probar en tiempo real ciertas funcionalidades.\n",
    "\n",
    "Por otra parte, el programa ofrece una interfaz en consola que permite entrenar y evaluar clasificadores acorde a múltiples configuraciones paramétricas. También se incluyen todas las herramientas desarrolladas en la anterior entrega, pudiendo entrenar y evaluar modelos basados en árboles o bosques de decisión. Si bien todas estas herramientas fueron pensadas para uso del grupo, en el archivo *README.md* se adjunta una sencilla guía de como utilizarlas.\n",
    "\n",
    "### 1.3. Formato\n",
    "***\n",
    "En las siguientes secciones se especifica el diseño de cada modelo, justificando la toma de decisiones a la hora de construirlos y detallando las estrategias o algoritmos que fueron implementados para la configuración paramétrica, junto a las métricas utilizadas en la evaluación. Luego, se detalla la metodología de experimentación y con la misma los resultados obtenidos para cada modelo y cada conjunto de datos, habiendo entrenado con distintas configuraciones paramétricas. Finalmente se agregan conclusiones respecto a los resultados obtenidos.\n",
    "\n",
    "Como detalle importante, dado que la consigna de la actual entrega presenta varias similitudes con la de la entrega anterior, se reutilizaron varios conceptos. A continuación se realiza una breve descripción del contenido de cada sección, especificando aquellas subsecciones que reutilizan contenido (las cuales son denotadas por un asterisco en su título), con el objetivo de facilitar una lectura que tenga en cuenta el informe anterior.\n",
    "\n",
    "La sección 2 (**Diseño**) reutiliza los conceptos de **preprocesamiento** y **evaluación** de la entrega anterior. Con respecto al diseño de **modelos** y **algoritmos**, nada es reutilizado, dado que los modelos son distintos.\n",
    "\n",
    "La sección 3 (**Experimentación**) reutiliza la estructura de la tarea anterior, siguiendo una metodología similar. De todas formas, al tratarse de nuevos resultados, no se reutiliza más que la estructura de la tarea anterior. Además, se agregan nuevos scripts para facilitar la visualización de la información.\n",
    "\n",
    "La sección 4 (**Conclusiones**) cuenta con una nueva lista de conclusiones extraídas de la realización de esta tarea, por lo que no comparte nada salvo ciertas comparaciones comparaciones con la tarea anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Diseño\n",
    "***\n",
    "En esta sección se detallan las características del diseño utilizado para construir el modelo, se profundizan las estrategias y algoritmos empleados en la configuración paramétrica y se tratan otros puntos como el procesamiento previo al entrenamiento y la evaluación posterior al mismo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Modelo\n",
    "***\n",
    "La consigna propone la utilización y comparación de dos tipos de modelos basados en distintos métodos de aprendizaje supervisado. A continuación, se especifican las características de cada uno:\n",
    "\n",
    "**Notas:**\n",
    "* No se ahonda en dichas descripciones puesto que son conceptos trabajados en el teórico.\n",
    "* Se utiliza notación matemática para visualizar fácilmente la definición de cada modelo.\n",
    "\n",
    "#### 2.1.1. Bayes sencillo (Naive Bayes)\n",
    "***\n",
    "Para este escenario uno de los modelos propuestos es el de **bayes sencillo** (a partir de ahora denominado **naive bayes** o **NB**), un modelo bayesiano que, al asumir independencia entre cada atributo del conjunto de datos, \"simplifica\" la interpretación de las frecuencias o **probabilidades** de los valores de cada atributo y permite utilizar el *Teorema de Bayes* para clasificar nuevos ejemplos con probabilidad.\n",
    "\n",
    "Se definen más formalmente las siguientes nociones:\n",
    "* $D =$ Conjunto de entrenamiento\n",
    "* $C_D =$ Conjunto de posibles clasificaciones para $d \\in D$\n",
    "* $NB_D =$ Clasificador bayesiano generado en base a $D$\n",
    "* Se representa una clasificación de un ejemplo $d \\in D$ realizada por el clasificador bayesiano $NB_D$ como $NB_D(d) = (c, p) : c \\in C_D$ y $p \\in [0..1]$\n",
    "\n",
    "#### 2.1.2. K vecinos más cercanos (KNN)\n",
    "***\n",
    "El otro modelo propuestos es el de **k vecinos más cercanos** (a partir de ahora denominado **KNN**), un modelo basados en casos, el cual representa el conjunto de datos como un espacio de **$n$ dimensiones** (siendo $n$ la cantidad de atributos) y clasifica nuevos ejemplos basandose en la clasificación de los $k$ vecinos más cercanos al ejemplo en cuestión, utilizando algún tipo de medida de distancia.\n",
    "\n",
    "Se definen más formalmente las siguientes nociones:\n",
    "* $D =$ Conjunto de entrenamiento\n",
    "* $C_D =$ Conjunto de posibles clasificaciones para $d \\in D$\n",
    "* $KNN_{(D,k)} =$ Clasificador de KNN generado en base a $D$ y evaluando los $k$ vecinos más cercanos\n",
    "* Se representa una clasificación de un ejemplo $d \\in D$ realizada por el clasificador $KNN_{(D,k)}$ como $KNN_{(D,k)}(d) = (c, p) : c \\in C_D$ y $p \\in [0..1]$\n",
    "\n",
    "Los detalles sobre los algoritmos de entrenamiento y clasificación utilizados por cada modelo se expanden en la sección 2.3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Preprocesamiento\n",
    "***\n",
    "Con los objetivos tanto de hacer viable como de mejorar la performance de entrenamiento, se realizaron ciertos cambios en el conjunto de datos a utilizar. A continuación, se listan los cambios realizados agrupandolos en base a motivación y área cambiada en el conjunto original.\n",
    "\n",
    "**Notas:**\n",
    "* Los cambios realizados en el conjunto de datos fueron hechos en memoria, sin modificar de forma alguna los archivos originales.\n",
    "* Los cambios como *interpretación de atributos continuos*, *normalización de rangos*, etc. son inherentes a ciertos modelos y por lo tanto no se especifícan en esta sección, tratandose en la sección correspondiente a cada algoritmo.\n",
    "\n",
    "#### 2.2.1. Optimización (Representación) (*)\n",
    "***\n",
    "La elección de la representación interna fue compleja, ya que se tuvo en cuenta tanto la performance como la facilidad a la hora de programar e interpretar el código. Siguiendo el ejemplo de la entrega anterior, se determinó la utilización del objeto **DataFrame** de la biblioteca *pandas*. Al principio trajo muchos problemas de performance (tanto en uso de memoria como en velocidad) pero al implementar técnicas ofrecidas por la biblioteca dichos problemas se palearon, generando eventualmente un uso de memoria reducido y un entrenamiento veloz.\n",
    "\n",
    "#### 2.2.2. Estructura (Atributos)\n",
    "***\n",
    "Originalmente se buscó mantener la estructura de atributos estática, con el fin de impactar lo menos posible en el entrenamiento y su posterior evaluación. No obstante, para el segundo conjunto de datos (detallado en la sección 2.4), fue necesario cambiar la estructura eliminando varios atributos y generando otros nuevos.\n",
    "\n",
    "Más concretamente, el cambio realizado fue el proceso inverso al conocido como *one hot encoding*, ya que habia múltiples atributos que representaban \"la idea\" de un sólo atributo discreto. En múltiples problemas, la implementación de dicho algoritmo resulta de gran utilidad para mejorar el rendimiento tanto a nivel de performance como de clasificación, generando $x$ atributos binarios para $x$ posibles valores del atributo original. \n",
    "\n",
    "Tomando la experiencia de la tarea anterior y teniendo en cuenta que **Naive Bayes** y **KNN** pueden trabajar con *one hot encoding*, se agregó la posibilidad de deshacerlo o de mantenerlo, con el fin de comprobar si el cambio influye en la performance de alguno de los modelos. En la sección 3 se muestran los resultados de dicho experimento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Algoritmo\n",
    "***\n",
    "En la siguiente sección se centralizan todas las especificaciones relativas a los algoritmos empleados, tanto para entrenar como para clasificar.\n",
    "\n",
    "**Notas:**\n",
    "* Se separa la especificación para **NB** y **KNN**.\n",
    "* Se hace referencia a puntos mencionados en secciones anteriores, sin entrar en detalle en lo que ya fue explicado.\n",
    "\n",
    "#### 2.3.1. Especificación - Naive Bayes\n",
    "***\n",
    "Un clasificador **Naive Bayes** trabaja con **atributos discretos** y una **clasificación discreta**. En este aspecto, no difiere de los **árboles de decisión** utilizados en la anterior tarea. No obstante, tanto la forma de *entrenar* como de *clasificar* si difiere, ya que se fundamenta en otros principios.\n",
    "\n",
    "Como se mencionó anteriormente, **Naive Bayes** es un modelo bayesiano, por lo que determina probabilidades en base al conjunto de entrenamiento y clasifica nuevos ejemplos sirviendose de las mismas, así como del *Teorema de Bayes*. Debido a esto, cuenta con sus propias particularidades y distintos parámetros a configurar.\n",
    "\n",
    "A continuación se tratan dichas particularidades, así como el algoritmo de entrenamiento y el de clasificación.\n",
    "\n",
    "##### 2.3.1.1. Algoritmo de entrenamiento\n",
    "***\n",
    "El algoritmo de entrenamiento implementado para **Naive Bayes** sigue las pautas del visto en el teórico. Se utilizan las siguientes nociones:\n",
    "\n",
    "- $D$ representa el conjunto de ejemplos.\n",
    "- $C_D$ representa el conjunto de clases en $D$.\n",
    "- $A_D$ representa el conjunto de atributos en $D$.\n",
    "- $f : D \\rightarrow C_D : f(d) = c$ representa la función de clasificación para un ejemplo existente en $D$.\n",
    "- $g_a : D \\rightarrow Val(a) : g_a(d) = v$ representa la función que determina el valor del atributo $a$ para un ejemplo existente en $D$.\n",
    "- $D_c = {d \\in D : f(d) = c}$ representa el subconjunto de $D$ donde cada ejemplo es clasificado como clase $c$.\n",
    "- $D_{a, v, c} = {d \\in D : f(d) = c, g_a(d) = v}$ representa el subconjunto de $D$ donde cada ejemplo con valor $v$ en el atributo $a$ es clasificado como clase $c$.\n",
    "\n",
    "En resumen, el algoritmo consiste en recorrer $D$ y para cada clase y cada posible valor de cada atributo, obtener las siguientes probabilidades:\n",
    "\n",
    "- $\\forall c \\in C_D$, se calcula la siguiente probabilidad, la cual representa la frecuencia de clasificaciones con clase $c$ en $D$.\n",
    "\n",
    "$$P(c) = \\frac{|D_c|}{|D|}$$\n",
    "\n",
    "- $\\forall a \\in A_D$ y $\\forall v \\in Val(a)$, se calcula la siguiente probabilidad, la cual representa la frecuencia de clasificaciones con clase $c$ en $D$ y que en sus ejemplos el atributo $a$ cuenta con el valor $v$. \n",
    "\n",
    "$$P(v|c) = \\frac{|D_{a, v, c}|}{|D|}$$\n",
    "\n",
    "Dichas probabilidades se almacenan en una estructura para utilizarse al momento de clasificar.\n",
    "\n",
    "##### 2.3.1.2. Algoritmo de clasificación\n",
    "***\n",
    "El algoritmo de clasificación implementado para **Naive Bayes** sigue las pautas del visto en el teórico. Se utilizan las nociones definidas en el punto anterior.\n",
    "\n",
    "En resumen, el algoritmo consiste en aplicar el *Teorema de Bayes* y calcular para cada clase $c \\in C_D$ la probabilidad condicional de que, dado $D$, la clasificación del ejemplo en cuestión sea $c$. Como **Naive Bayes** se fundamenta en asumir que los valores de cada atributo son **independientes**, se utilizan las siguientes nociones:\n",
    "\n",
    "- Sea $e$ el ejemplo a clasificar.\n",
    "- Sea $v_i$ el valor del i-ésimo atributo en $e$\n",
    "- $\\forall c \\in C_D$, se calcula la probabilidad de que el ejemplo $e$ sea de clase $c$, utilizando la siguiente fórmula:\n",
    "\n",
    "$$P(e|c) = \\prod_{i \\in [1..|A_D|]} = P(v_i|c) * P(c)$$\n",
    "\n",
    "- El clasificador toma la mayor de las probabilidades anteriormente calculadas y devuelve la clase correspondiente:\n",
    "\n",
    "$$NB_D(e) = argmax_{c \\in C_D} P(e|c)$$\n",
    "\n",
    "##### 2.3.1.3. Interpretación de atributos continuos\n",
    "***\n",
    "Una característica clave para el escenario propuesto y que **Naive Bayes** no contempla es **el tratamiento de atributos continuos**. Se emplearon **dos estrategias** distintas para interpretar los valores de tales atributos, teniendo como fin las mismas el poder obtener una probabilidad para cualquier valor dado. Dichas estrategias son las siguientes:\n",
    "\n",
    "- **Distribución normal:** Sea $a$ el atributo en cuestión y $Val(a)$ el conjunto de posibles valores para el mismo, se interpreta $Val(a)$ como una variable aleatoria con **distribución normal**, calculandose su media y desviación estándar a partir de la muestra en $D$. Dicha media $\\mu$ y desviación $\\sigma$ se almacenan en el clasificador. Luego, para ejemplos a clasificar, se toma el valor $v_a$ del atributo $a$ y se utiliza la **función de densidad normal** para calcular su probabilidad:\n",
    "$$P(v_a) = \\frac{1}{\\sigma \\sqrt{2\\pi}} e^{-\\frac{(x - \\mu)^2}{2 \\sigma^2}}$$\n",
    "    De esta forma, incluso para valores continuos que no aparecieron en $D$, se puede obtener una probabilidad. Dado que **Naive Bayes** trabaja originalmente con atributos continuos, esta estrategia puede tener un impacto negativo en la eficiencia. Dichos problemas se tratan con más profundidad en la sección 3.\n",
    "\n",
    "\n",
    "- **Intervalos variables:** Sea $a$ el atributo en cuestión y $Val(a)$ el conjunto de posibles valores para el mismo, se genera un número variable de intervalos a partir de $Val(a)$, ordenando $D$ según $a$ y partiendo $Val(a)$ cada vez que se encuentra un cambio en la clasificación $c$. En resumen, se **discretiza** al atributo $a$ siguiendo la estrategia utilizada en la tarea de **árboles de decisión**.\n",
    "\n",
    "    Es importante aclarar que se tomó la decisión de discretizar según esta estrategia y no las otras utilizadas en la tarea anterior (partir en dos intervalos fijos o partir en dos intervalos maximizando la ganancia) porque se identificó que la menor pérdida de información está asociada a esta estrategia. De hecho, **Naive Bayes** no trabaja con los conceptos de **ganancia** utilizados por los árboles de decisión, y partir solamente en dos intervalos podría resultar negativo para conjuntos $Val(a)$ esparsos.\n",
    "\n",
    "##### 2.3.1.4. Implementación de m-estimador\n",
    "***\n",
    "Existe un \"caso borde\" al calcular la probabilidad $P(v|c) = \\frac{|D_{a, v, c}|}{|D|}$, el cual es el caso donde no hay ejemplos para alguna de las clases. En este escenario, la probabilidad asignada a dicha clase sería 0. Teniendo esto en cuenta, el producto de las probabilidades también sería igual a 0, independientemente del resto de los atributos. Esto puede causar pérdida de información necesaria, afectando el rendimiento del clasificador.\n",
    "\n",
    "Para prevenir este problema, se agregó lo que se denomina un **m-estimador**, que aplica la técnica denominada *additive smoothing*, la cual es utilizada para suavizar la distribución de atributos discretos. Su inventor fue Pierre-Simon Laplace, llamandosele *laplace smoothing* cuando el valor elegido es $m = 1$.\n",
    "\n",
    "De esta forma, se pasa a calcular la probabilidad anteriormente mencionada, utilizando la siguiente fórmula:\n",
    "\n",
    "$$P(v|c) = \\frac{|D_{a, v, c}| + mp}{|D| + m}$$\n",
    "\n",
    "Siendo $P$ la estimación a priori de la probabilidad buscada y $m$ el valor elegido como **m-estimador**, $m$ determina que tan fuerte ponderar $P$ respecto a los datos observados. Desde la perspectiva Bayesiana, este cambio causa el aumento de la muestra con $m$ ejemplos virtuales, distribuidos acorde a $p$.\n",
    "\n",
    "Debido a que la elección para el valor de $m$ no es trivial, el mismo fue uno de los parámetros cuyo valor fue alternado para la configuración paramétrica. Se expande este punto en la sección 3.\n",
    "\n",
    "#### 2.3.2. Especificación - KNN\n",
    "***\n",
    "Un clasificador **KNN** trabaja con **atributos continuos** y una **clasificación discreta**. En este aspecto, difiere bastante de los **árboles de decisión** utilizados en la anterior tarea. Además de esto, cuenta con otra particularidad: la etapa de *entrenamiento* \"no existe\" en términos formales y cada clasificación se realiza utilizando el conjunto de datos completo.\n",
    "\n",
    "Como se mencionó anteriormente, **KNN** es un modelo basado en casos, por lo que utiliza los ejemplos que se parezcan más al ejemplo a clasificar, según algún tipo de métrica, y clasifica tomando una decisión en relación a las clasificaciones de los valores cercanos.\n",
    "\n",
    "A continuación se tratan las particularidades anteriormente mencionadas, así como el algoritmo de entrenamiento y el de clasificación.\n",
    "\n",
    "##### 2.3.2.1. Algoritmo de entrenamiento\n",
    "***\n",
    "El algoritmo **KNN** no cuenta con una etapa de entrenamiento propiamente dicha. De hecho, lo que se denomina como entrenamiento en esta implementación, consiste en realizar un **preprocesamiento** de los datos para poder manipularlos con mayor facilidad a la hora de clasificar, así como eliminar ruido y otras cuestiones menores. Dichos cambios son independientes al preprocesamiento realizado al principio (explicitado en la sección 2.2).\n",
    "\n",
    "Dentro del procesamiento propio a **KNN**, se realizan dos tareas:\n",
    "1. **Normalización de valores:** Utilizando una de varias posibles estrategias, se normalizan todos los valores del conjunto de datos, con el objetivo de mantener ''las proporciones'' pero no priorizar atributos con valores grandes en el cálculo de distancias. Las posibles estrategias se tratan en la sección 2.3.2.3.\n",
    "2. **Almacenamiento en estructuras auxiliares:** Utilizando una de varias posibles estrategias, se toma el conjunto de datos y se lo almacena utilizando una estructura acorde, con el fin de facilitar el proceso de clasificación. Las posibles estructuras se tratan en la sección 2.3.2.4.\n",
    "\n",
    "En resumen, el algoritmo consiste en recorrer $D$, aplicando la normalización que corresponda, almacenando los valores auxiliares de dicha normalización que permitan normalizar nuevos ejemplos y generando las estructuras auxiliares que correspondan.\n",
    "\n",
    "##### 2.3.2.2. Algoritmo de clasificación\n",
    "***\n",
    "El algoritmo de clasificación implementado para **KNN** sigue las pautas del visto en el teórico. Se utilizan las siguientes nociones:\n",
    "\n",
    "- $D$ representa el conjunto de ejemplos.\n",
    "- $C_D$ representa el conjunto de clases en $D$.\n",
    "- $f : D \\rightarrow C_D : f(d) = c$ representa la función de clasificación para un ejemplo existente en $D$.\n",
    "- $d : D \\times D \\rightarrow \\mathbb{R}^{+} \\cup \\{0\\}$ representa la función de distancia entre un par de ejemplos de $D$.\n",
    "- $D_{d, e}$ representa el conjunto de ejemplos $D$ ordenado ascendentemente según la distancia $d(e,x) \\forall x \\in D$\n",
    "- $g : D \\times (x_1,...,x_k) \\rightarrow C_D$ representa la función de votación para un subconjunto de $k$ ejemplos $x_i \\in D : i \\in [1..k]$, la cual elige una clase $c \\in C_D$ en base a las clases $f(x_i)$.\n",
    "\n",
    "En resumen, el algoritmo consiste en calcular la **distancia** del ejemplo a clasificar para todo el conjunto $D$ y obtener los $k$ vecinos más cercanos según esa distancia. Luego, utilizando un **algoritmo de votación**, se elige la clasificación del ejemplo en cuestión. Se utilizan las siguientes nociones:\n",
    "\n",
    "- Sea $e$ el ejemplo a clasificar\n",
    "- Sea $k$ la cantidad de vecinos a evaluar\n",
    "- $\\forall x \\in D$, se calcula la distancia $d(e,x)$ de $e$ a todos los ejemplos en $D$\n",
    "- Sea $X = (x_1,...,x_k) : x_i \\in D_{d,e} \\wedge i \\in [1,k]$, es decir, los primeros $k$ elementos de $D_{d,e}$ (los vecinos más cercanos a $e$), se utiliza las clases $f(x_i)$ y la función $g$ de votación anteriormente mencionada para que el clasificador devuelva la clase correspondiente para $e$:\n",
    "\n",
    "$$KNN_D(e) = g(e, X)$$\n",
    "\n",
    "Tanto la **función de distancia** $d$ como la **función de votación** $g$ se pueden tomar de distintas estrategias posibles, por lo que se expanden en las secciones 2.3.2.5 y 2.3.2.6 respectivamente.\n",
    "\n",
    "##### 2.3.2.3. Estrategias de normalización\n",
    "***\n",
    "La implementación \"original\" de **KNN** no toma en cuenta la posibilidad de normalizar los datos. No obstante, cuando el rango de valores de un atributo es mucho mayor al resto, esto provoca que el atributo en cuestión influya mucho más en el cálculo de distancias, independientemente a la función de distancia utilizada (en la sección 2.3.2.5 se profundiza en la relación entre las distancias y los valores de los atributos).\n",
    "\n",
    "Con el objetivo de no priorizar ningún atributo sobre otro, y a la vez mantener las proporciones y perder la menor cantidad de información posible, se introduce la técnica de **normalización**. Se utilizaron **tres estrategias** distintas para normalizar:\n",
    "\n",
    "- **Norma euclídea:** Interpretando el conjunto $D$ como un espacio vectorial de $n$ dimensiones (siendo $n = |A_D|$ la cantidad de atributos), una forma de normalizar cada elemento de $D$ es interpretarlo como un *vector* y dividir cada una de sus *coordenadas* entre su *norma*.\n",
    "\n",
    "    Sea $x \\in D$ un ejemplo representado como un vector, cada una de sus coordenadas es su valor para cada atributo. La norma de $x$ se representa como $||x|| = d(x,0)$ siendo $d$ la función de **distancia** definida para ese espacio vectorial. Independiente a la función de distancia utilizada por **KNN**, se eligió la **distancia euclídea** (en la sección 2.3.2.5 se trata esta distancia) para calcular la norma de un vector $x$.\n",
    "    \n",
    "    Teniendo esto en cuenta, el normalizar un vector consiste en dividirlo por su norma, obteniendo un **versor**, el cual es un vector con norma 1 en el espacio vectorial. El manejar un conjunto de versores provoca que sus coordenadas entren en un intervalo menor, reduciendo el problema anteriormente mencionado y manteniendo proporciones.\n",
    "    \n",
    "    De esta forma, se normalizó cada vector $x \\in D$ utilizando la siguiente fórmula:\n",
    "\n",
    "    $$x' = \\frac{x}{||x||} = \\sum_{i = 1}^{n} \\frac{x_i}{||x||}$$\n",
    "\n",
    "- **Reescalamiento:** Como su nombre indica, se cambia la escala para cada atributo, manteniendo la proporción o separación entre sus valores. Dicha escala lleva el rango del atributo, independientemente a su tamaño, a un rango $[0,1]$. Para ello, realiza una inspección para todos los valores de dicho rango. \n",
    "\n",
    "    Sea $x \\in D : x = (x_1,...,x_n)$, siendo $x_i$ el valor en $x$ para el i-ésimo atributo, se determina para cada atributo $a_i \\in A_D$ los valores $min(a_i)$ y $max(a_i)$ como el mínimo y el máximo valor respectivamente para el i-ésimo atributo $a_i$ en todos los ejemplos de $D$. Teniendo esto en cuenta, el reescalar un ejemplo consiste en llevar cada valor del mismo a un rango $[0,1]$.\n",
    "    \n",
    "    De esta forma, se reescaló cada ejemplo $x \\in D$ utilizando la siguiente fórmula:\n",
    "\n",
    "    $$x' = (x_1',...,x_n') : x_i' = \\frac{x_i - min(a_i)}{max(a_i) - min(a_i)}$$\n",
    "\n",
    "- **Estandarización:** Esta estrategia consiste en interpretar el rango de un atributo $a_i$ como una variable aleatoria siguiendo una **distribución normal**. Se utiliza un proceso similar al del reescalamiento, estudiando el rango completo de $a_i$, obteniendo la **media** y la **desviación estándar** del mismo y finalmente ajustando el rango de cada atributo a una escala menor.\n",
    "\n",
    "    Sea $x \\in D : x = (x_1,...,x_n)$, siendo $x_i$ el valor en $x$ para el i-ésimo atributo, se determina para cada atributo $a_i \\in A_D$ los valores $\\mu_i$ y $\\sigma_i$ como la media y la desviación estándar para el i-ésimo atributo $a_i$ en todos los ejemplos de $D$. Teniendo esto en cuenta, el estandarizar un ejemplo consiste en llevar cada valor del mismo a un rango menor. Más concretamente, consiste en transformar la distribución actual $N(\\mu_i, \\sigma_i)$ en una distribución $N(0,1)$, es decir, modificar los datos para que la media $\\mu_i = 0$ y la desviación estándar $\\sigma_i = 1$.\n",
    "    \n",
    "    Es importante marcar que, a diferencia del reescalamiento, el cual asegura que el nuevo rango es $[0,1]$, el rango de $N(0,1)$ no está específicamente definido. Se sabe que los valores entran en el rango $[-1,1]$ con una gran probabilidad ($\\approx 90\\%$), pero los **outliers** o valores atípicos pueden alejarse mucho de la distribución normal, quedando fuera del rango.\n",
    "    \n",
    "    De esta forma, se estandarizó cada ejemplo $x \\in D$ utilizando la siguiente fórmula:\n",
    "\n",
    "    $$x' = (x_1',...,x_n') : x_i' = \\frac{x_i - \\mu_i}{\\sigma_i}$$\n",
    "\n",
    "\n",
    "Cabe mencionar que, además de las estrategias anteriormente mencionadas, también está vigente la opción de **no normalizar**. Como se mencionó anteriormente, puede tener un impacto negativo en la clasificación, pero esto no es necesariamente cierto. En la sección 3 se estudia esto con mayor profundidad.\n",
    "\n",
    "##### 2.3.2.4. Estructuras de almacenamiento\n",
    "***\n",
    "La implementación \"original\" de **KNN** utiliza el conjunto de datos $D$ completo para obtener los $k$ vecinos más cercanos a un ejemplo dado. No obstante, para conjuntos $D$ de gran tamaño, el tener que calcular una distancia para cada ejemplo y luego obtener los $k$ ejemplos más cercanos, en el mejor de los casos requiere una recorrida completa al conjunto $D$ para **cada ejemplo a clasificar**. Si se quiere realizar una evaluación de un conjunto de gran tamaño, el tiempo de ejecución puede escalar a magnitudes inconvenientes.\n",
    "\n",
    "Tomando esto en cuenta, con el objetivo de mejorar la performance y poder realizar más evaluaciones con **KNN**, se utilizaron **dos estrategias** distintas para almacenar los datos:\n",
    "\n",
    "- **Conjunto de datos:** La estrategia original, almacenar $D$ en una estructura **DataFrame** de *pandas* y realizar el calculo de distancias con operaciones vectoriales. Minimizando la cantidad de operaciones costosas y vectorizando todas aquellas operaciones que se hicieran iterativamente, se logró reducir notablemente el tiempo de ejecución, manteniendo resultados y manteniendo también la **estructura de almacenamiento**. No obstante, para conjuntos de gran tamaño, los tiempos de ejecución obtenidos eran demasiado largos.\n",
    "\n",
    "\n",
    "- **Árbol KDTree:** Además de almacenar $D$ en la estructura anteriormente mencionada, se agregó la opción de almacenar $D$ también en otra estructura que permitiera obtener los $k$ vecinos más cercanos a un ejemplo dado de forma más veloz. Para ello, se utilizó la clase *sklearn.neighbors.KDTree*, la cual permite generar una estructura denominada **KDTree** y realizar búsquedas utilizando los métodos *query* o *query_radius*.\n",
    "\n",
    "    Dado que el método *query* representa exactamente lo que la tarea pide implementar, se utilizó el método *query_radius*, obteniendo para un ejemplo $e$ todos los vecinos $x$ que cumplieran $d(e,x) \\leq 1$. Dichos vecinos se devuelven de forma ordenada ascendentemente según su distancia a $e$, por lo que basta con tomar los primeros $k$. Si los vecinos obtenidos no llegan a ser $k$, se incrementa la distancia a 8 y se repite el algoritmo incrementando la distancia en potencias de 2 hasta encontrar $k$ vecinos.\n",
    "    \n",
    "    La ventaja de implementar un **KDTree** radica en como almacena los ejemplos: utiliza un árbol binario donde cada nivel representa una de las $k$ dimensiones del espacio vectorial que representa $D$. Dichas dimensiones se intercalan, por lo que el primer si el primer nivel representa la primera dimensión, el k+1-ésimo nivel representara de nuevo a la primera dimensión. De esta forma, al generar el árbol se van guardando ejemplos de $D$ en nodos y se elige la siguiente rama en base a la comparación de la coordenada de la dimensión del nodo actual frente a la coordenada de la dimensión del ejemplo. Si el ejemplo es mayor, se baja por el árbol hacia la rama derecha, y si no, hacia la izquierda. Este mismo principio es utilizado para clasificar.\n",
    "    \n",
    "    Para bajar a tierra el concepto, se plantea un ejemplo de un KDTree en 2 dimensiones, el cual se construiría de la siguiente manera:\n",
    "\n",
    "    Sean el conjunto de datos compuesto por los puntos (3, 6), (17, 15), (13, 15), (6, 12), (9, 1), (2, 7), (10, 19). Primero se inserta (3, 6) en la raíz dado que el árbol aún es vacío. Cuando se va a insertar (17, 15), como la raíz está alineada por el eje $x$, se compara el valor de la coordenada en $x$ del nuevo punto con el de la raíz. Como el valor es mayor, el punto va a ser la raíz del subárbol izquierdo y ese nodo va alinearse con respecto al eje $y$. Luego se inserta el punto (13, 15). En la raíz, verificando el valor de $x$ se comprueba que se va a encontrar en el subárbol derecho. En el nodo siguiente tambien lo hará, habiendo comparado por el eje $y$. Este nuevo nodo va a alinearse con respecto al eje $x$. Siguiendo el mismo procedimiento de comparar la coordenada $x$ o $y$ según la alineación del nodo actual, el árbol queda definido como sigue:\n",
    "\n",
    "    <div style=\"display: inline-block; width: 99%; text-align: center; margin-top: 16px;\">\n",
    "        <img src=\"img/kdtree1.jpg\" />\n",
    "        <label style=\"margin-top: 16px; font-size: 16px; font-family: monospace;\"> Figura 2.1 - Ejemplo de KDTree de dimensión 2</label>\n",
    "    </div>\n",
    "\n",
    "    Dado que es un ejemplo de 2 dimensiones, se puede visualizar como queda particionado el espacio:\n",
    "\n",
    "    <div style=\"display: inline-block; width: 99%; text-align: center; margin-top: 16px;\">\n",
    "        <img src=\"img/kdtree2.jpg\" />\n",
    "        <label style=\"margin-top: 16px; font-size: 16px; font-family: monospace;\"> Figura 2.2 - Ejemplo de espacio para KDTree de dimensión 2</label>\n",
    "    </div>\n",
    "\n",
    "    Teniendo en cuenta lo anterior, la búsqueda de vecinos en un **KDTree** para cierta cantidad $k$ de vecinos en relación al tamaño del conjunto $D$, será mucho más veloz que el tener que recorrer todo el conjunto, ya que las búsquedas en promedio son de orden $O(log$ $n)$.\n",
    "    \n",
    "Es importante destacar que, si bien se generaron ambas soluciones, se priorizó utilizar el conjunto de datos original, relegando la utilización del KDTree para casos donde el tiempo de ejecución fuera crucial. En la sección 3 se trata este tema con mayor profundidad.\n",
    "\n",
    "##### 2.3.2.5. Medidas de distancia\n",
    "***\n",
    "La implementación \"original\" de **KNN** no determina una medida de distancia en específico. Teniendo esto en cuenta, se investigaron las métricas de distancia más comunes y sus distintas aplicaciones.\n",
    "\n",
    "Una métrica clave utilizada en espacios vectoriales normados es la **distancia de Minkowski**, la cual establece la fórmula general:\n",
    "\n",
    "$$d_p(x,y) = (\\sum_{i=1}^{n} |x_i - y_i|^p)^{1-p} : x = (x_1,...,x_n), y = (y_1,...,y_n)$$\n",
    "\n",
    "Cuando $p \\geq 1$, $d_p$ es efectivamente una distancia (es decir, cumple con las propiedades). De dicha métrica se pueden obtener varias distancias variando $p$, las cuales cuentan con propiedades específicas. En este contexto, se utilizaron **tres estrategias** distintas para calcular la distancia:\n",
    "\n",
    "- **Distancia manhattan:** Utilizando $p = 1$, se calcula la distancia como:\n",
    "    $$d_1(x,y) = \\sum_{i=1}^{n} |x_i - y_i|$$\n",
    "- **Distancia euclídea:** Utilizando $p = 2$, se calcula la distancia como:\n",
    "    $$d_2(x,y) = \\sqrt{\\sum_{i=1}^{n} |x_i - y_i|^2}$$\n",
    "- **Distancia chebychev:** Utilizando $p = \\infty$, se calcula la distancia como:\n",
    "    $$d_{\\infty}(x,y) = max_{i=1}^{n} |x_i - y_i|$$\n",
    "\n",
    "Las tres funciones de distancia anteriormente mencionadas se utilizan en problemas de aprendizaje automático, por lo que se ofreció la posibilidad de utilizar cualquiera de las tres. En la sección 3 se compara sus rendimientos. Por ahora, es interesante observar que las tres generan distintos **\"círculos\" unitarios** alrededor de un eje. Si se toma la distancia entre el centro y cualquier punto de la figura celeste, la distancia es 1.\n",
    "\n",
    "\n",
    "<div style=\"display: inline-block; width: 99%; text-align: center; margin-top: 16px;\">\n",
    "    <img src=\"img/dist.png\" />\n",
    "    <label style=\"margin-top: 16px; font-size: 16px; font-family: monospace;\"> Figura 2.3 - Comparaciones entre distancias de Minkowski</label>\n",
    "</div>\n",
    "\n",
    "\n",
    "El hecho de que las tres distancias varien la forma que le dan a la unidad puede influir en que tan bien se clasifique dependiendo del conjunto de datos.\n",
    "\n",
    "##### 2.3.2.6. Estrategias de votación\n",
    "***\n",
    "Luego de obtener los $k$ vecinos más cercanos, es necesario determinar una forma de asignar una clase al ejemplo en cuestión. Para el caso donde $k = 1$, basta con asignar la clasificación del único ejemplo utilizado. No es así para el caso donde $k \\geq 1$.\n",
    "\n",
    "Teniendo esto en cuenta, se implementaron **dos estrategias** para votar:\n",
    "- **Votación general:** Dados los $k$ ejemplos más cercanos con sus respectivas clasificaciones, se selecciona la clase que tiene más repeticiones dentro de esas $k$ instancias. De esta manera, se 'vota' por la clase más frecuente dentro del subconjunto. No se toma en cuenta la distancia (es decir, si $k=7$ y el vecino más cercano es de clase $c_1$ y los otros seis son de clase $c_2$, se elige la clase $c_2$ por encima de la $c_1$).\n",
    "\n",
    "- **Votación ponderada:** Esta estrategia consiste en darle peso a los puntos que se encuentren más cerca del ejemplo a clasificar (dentro de los $k$ vecinos cercanos), ponderar por clase y elegir la de mayor valor. De esta manera, si $k=3$ y hay un punto muy cercano a la instancia que tenga, por ejemplo, una clase $c_1$, y luego otros dos vecinos cercanos más lejanos a la instancia que tengan ambos una clase $c_2$, se le otorga un mayor peso a la clase $c_1$ por encontrarse el vecino que la representa más cerca del ejemplo en cuestión.\n",
    "\n",
    "    Siendo $e$ el ejemplo a clasificar y $x_i$ el i-ésimo vecino más cercano a $e$, el peso $\\theta_i : i \\in [1..k]$ se calcula utilizando la siguiente expresión:\n",
    "\n",
    "$$ \\theta_i = d(e,x_i)^{-2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Evaluación (*)\n",
    "***\n",
    "En la siguiente sección se centralizan todas las especificaciones relativas a la evaluación de los clasificadores entrenados.\n",
    "\n",
    "#### 2.4.1. Conjuntos de evaluación (*)\n",
    "***\n",
    "Los dos conjuntos de datos a partir de los cuales se entrenó y evaluó los modelos son:\n",
    "- [**Conjunto *Iris*:**](https://archive.ics.uci.edu/ml/datasets/iris) El cual clasifica plantas del genero Iris (de la tribu Irideae, perteneciente a la familia Iridaceae) según especie. Cuenta con **150 ejemplos**, **4 atributos** de carácter continuo y **3 clases posibles**.\n",
    "- [**Conjunto *Covertype*:**](https://archive.ics.uci.edu/ml/datasets/Covertype) El cual clasifica terrenos de bosques según atributos cartográficos. Cuenta con **581012 ejemplos**, **54 atributos**, siendo 10 de carácter continuo y 44 de carácter binario (son el _one hot encoding_ de 2 atributos generando 4 y 40 atributos respectivamente) y **7 clases posibles**.\n",
    "\n",
    "Cabe destacar que el conjunto *Iris* cuenta con una cantidad ínfima de ejemplos, mientras que el conjunto *CoverType* va hacia el otro extremo. Las implicancias de estos hechos se tratan en la sección 3.\n",
    "\n",
    "#### 2.4.2. Métodos de evaluación (*)\n",
    "***\n",
    "Se experimentó utilizando dos estrategias de evaluación, siendo las mismas:\n",
    "- **Validación 80/20** (denominada \"normal\" a partir de ahora)\n",
    "- **Validación cruzada** con 10 particiones (denominada \"cruzada\" a partir de ahora)\n",
    "\n",
    "Ambas estrategias subdividen el conjunto de datos $D$ en dos subconjuntos, $T, E \\subset D$. El subconjunto $T$ se utiliza para entrenar al clasificador en cuestión, mientras que el subconjunto $E$ se utiliza para evaluar la eficacia del mismo. Esto se logra haciendo que el modelo entrenado clasifique los ejemplos del conjunto de evaluación $E$, comparando luego la clasificación original con la realizada. Dicha comparación se basa en distintas métricas, las cuales se tratan en la subsección siguiente.\n",
    "\n",
    "Es importante destacar que, independiente al método de evaluación, el conjunto de datos $D$ original se mezcla de forma aleatoria antes de subdividirlo en $T$ y $E$. Esto es vital para evitar repetir siempre el mismo resultado en distintas evaluaciones.\n",
    "\n",
    "Si, por ejemplo, $D$ estuviera ordenado de forma tal que los últimos ejemplos en él (los que corresponderían a $E$ al momento de hacer la partición) no agregan información nueva a $T$, entonces el desempeño del clasificador sería excelente, ya que con la información en $T$ podría clasificar perfectamente a $E$. Por otra parte, si sucede lo contrario, el desempeño sería mucho peor. En ambos casos, el resultado de la evaluación estaría sesgado. La mezcla al azar de $D$ se utiliza con el objetivo de mitigar este fenómeno.\n",
    "\n",
    "A continuación se adjunta una breve descripción de los parámetros utilizados en cada método de evaluación.\n",
    "\n",
    "##### 2.4.2.1. Validación normal (*)\n",
    "***\n",
    "Se denomina como **validación normal** a la partición única del conjunto $D$ en $T$ y $E$ utilizando una proporción donde $|T| \\lt |E|$.\n",
    "\n",
    "En general, dependiendo de la cantidad de ejemplos en $D$ y del objetivo que se quiera alcanzar, dicha partición sigue una relación 80/20, 85/15, 90/10, etc. Para el escenario actual, se determinó utilizar una partición 80/20, es decir, $T$ cuenta con el 80% de ejemplos en $D$, mientras que $E$ cuenta con el 20% restante.\n",
    "\n",
    "Es importante recordar el fenómeno mencionado en la subsección anterior. La validación normal, si bien parte al conjunto luego de haber sido reordenado aleatoriamente, puede verse afectada, por casualidad, por el fenómeno en cuestión. Con el objetivo de reducir esta posibilidad, se agrega el siguiente método\n",
    "\n",
    "##### 2.4.2.2. Validación cruzada (*)\n",
    "***\n",
    "\n",
    "Se denomina como **validación cruzada** a la partición del conjunto $D$ en $k$ particiones $T_i$ y $E_i : i \\in [1..k]$,  utilizando una proporción de $\\frac{k-1}{k}$ y $\\frac{1}{k}$ ejemplos para $T_i$ y $E_i$ respectivamente.\n",
    "\n",
    "En lenguaje natural, la validación cruzada utiliza un parámetro $k$, generando $k$ particiones de $D$ siguiendo el método normal mencionado en la anterior subsección. Esto se hace con el objetivo de evitar el sobreajuste en subconjuntos $T \\subset D$ específicos. Una vez se hacen las $k$ evaluaciones, se promedian las métricas obtenidas para obtener una mejor noción del desempeño del modelo.\n",
    "\n",
    "Esta estrategia es más robusta que la **validación normal** anteriormente mencionada, sin embargo tiene el problema de tener un mayor orden computacional, dado que tiene que correr $k$ entrenamientos en lugar de uno.\n",
    "\n",
    "En la experimentación se decidió fijar $k=10$.\n",
    "\n",
    "#### 2.4.3. Métricas de evaluación (*)\n",
    "***\n",
    "Se utilizaron múltiples métricas para determinar la \"calidad\" o \"eficacia\" de los clasificadores entrenados. A continuación, una breve descripción de las mismas:\n",
    "\n",
    "##### 2.4.3.1 Accuracy (*)\n",
    "***\n",
    "La **accuracy** o **exactitud** hace referencia a la cantidad de aciertos que el clasificador tuvo en relación al total de clasificaciones que realizó durante la evaluación. Para definir **accuracy**, se utilizan las siguientes nociones:\n",
    "- Sea $D$ el conjunto de datos, $C_D$ el conjunto de posibles clasificaciones en $D$ y $|C_D| = n$\n",
    "- Sea $t_i : i \\in [1..n]$ la cantidad de clasificaciones para la clase $i$ que fueron correctas\n",
    "- Sea $f_i : i \\in [1..n]$ la cantidad de clasificaciones para la clase $i$ que fueron incorrectas\n",
    "\n",
    "$$ accuracy = \\frac{\\sum_{i=1}^{n} t_i}{\\sum_{i=1}^{n} t_i + f_i}$$\n",
    "\n",
    "Se observa que **accuracy** no es una muy buena medida de performance, ya que depende mucho del conjunto de datos que se evalúe, pudiendo dar buenos resultados a un clasificador malo. Teniendo esto en cuenta, se utilizó esta métrica solo para tener una noción general del desempeño de un clasificador, dandole más peso a las métricas definidas a continuación.\n",
    "\n",
    "##### 2.4.3.2 Matriz de Confusión (*)\n",
    "***\n",
    "La **matriz de confusión** es una matriz que permite almacenar todas las clasificaciones realizadas en una evaluación, basándose en cada resultado y su respectivo valor original. La estructura de la matriz es la siguiente:\n",
    "\n",
    "- Sea $D =$ Conjunto de datos\n",
    "- Sea $C_D =$ Conjunto de clasificaciones para $d \\in D$ \n",
    "- Sea $|C_D| = n$ cantidad de posibles clasificaciones en $C_D$\n",
    "- Sea $M$ la matriz de confusión para una evaluación definida como:\n",
    "\n",
    "$$M = \\begin{bmatrix}\n",
    "    x_{11} & x_{12} & \\dots  & x_{1n} \\\\\n",
    "    x_{21} & x_{22} & \\dots  & x_{2n} \\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    x_{n1} & x_{n2} & \\dots  & x_{nn}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "- Entonces $x_{ij} \\in M : i,j \\in [1..n]$ representa la cantidad de clasificaciones que originalmente eran **clase $i$** y que fueron clasificadas en la evaluación como **clase $j$**.\n",
    "\n",
    "De esta forma, en una matriz cuadrada de dimensión $n$, se pueden centralizar todas las clasificaciones realizadas y su relación con respecto a cada clase.\n",
    "\n",
    "En sí misma, la matriz de confusión no representa una métrica sino una herramienta para calcular otras métricas, las cuales serán detalladas a continuación. De todas formas, una mirada superficial a una matriz de confusión de tamaño razonable puede aportar información general sobre el desempeño del clasificador, (esto es detallado en la siguiente subsección).\n",
    "\n",
    "##### 2.4.3.3 Precision, Recall, Fall-off, F-measure (*)\n",
    "***\n",
    "Existen cuatro medidas que, si bien siguen una fórmula similar a la de **accuracy**, son mucho menos sensibles al ruido en el conjunto de datos $D$, ya que operan **por clase**. Antes de detallar cada una, se repasan ciertas nociones básicas utilizadas en la definición de cada métrica.\n",
    "\n",
    "Retomando el punto anterior, la matriz de confusión permite calcular para cada clase $c_i$, cuatro valores indispensables:\n",
    "- Los **verdaderos positivos** en la clase $c_i$ (denotados como $t_i$), son aquellos ejemplos que originalmente son clase $c_i$ y fueron clasificados correctamente en la evaluación como clase $c_i$. Para calcularlos utilizando la matriz de confusión, simplemente hay que tomar la celda $M(i,i)$ para la clase $c_i$.\n",
    "\n",
    "$$ t_i = M(i,i) $$\n",
    "\n",
    "- Los **falsos positivos** en la clase $c_i$ (denotados como $f_i$), son aquellos ejemplos que originalmente son clase $c_j : j \\neq i$ y fueron clasificados incorrectamente en la evaluación como clase $c_i$. Para calcularlos utilizando la matriz de confusión, simplemente hay que tomar la fila $M_{(i,)}$ para la clase $c_i$, y sumar todos sus valores (excepto la celda $M(i,i)$, que corresponde a los verdaderos positivos).\n",
    "\n",
    "$$ f_i = \\sum_{j=1, j \\neq i}^{n} M(i,j) $$\n",
    "\n",
    "- Los **verdaderos negativos** en la clase $c_i$ (denotados como $\\bar{t_i}$), son aquellos ejemplos que originalmente no son clase $c_i$ y fueron clasificados en la evaluación como clase $c_j : j \\neq i$. Cabe destacar que la clasificación como $c_j$ puede ser correcta o no, lo importante es que sea consistente en relación a $c_i$. Para calcularlos utilizando la matriz de confusión, simplemente hay que tomar la matriz adjunta a los verdaderos positivos de $c_i$ y sumar todas sus entradas. Dicha matriz se define como $M_{ii}$ y contiene todas las entradas de $M$ excepto la fila $i$ y la columna $i$.\n",
    "\n",
    "$$ \\bar{t_i} = \\sum_{j=1}^{n-1} \\sum_{k=1}^{n-1} M_{ii}(j,k) $$\n",
    "\n",
    "- Los **falsos negativos** en la clase $c_i$ (denotados como $\\bar{f_i}$), son aquellos ejemplos que originalmente son clase $c_i$ y fueron clasificados incorrectamente en la evaluación como clase $c_j : j \\neq i$. Para calcularlos utilizando la matriz de confusión, simplemente hay que tomar la columna $M_{(,i)}$ para la clase $c_i$, y sumar todos sus valores (excepto la celda $M(i,i)$, que corresponde a los verdaderos positivos).\n",
    "\n",
    "$$ \\bar{f_i} = \\sum_{j=1, j \\neq i}^{n} M(j,i) $$\n",
    "\n",
    "Teniendo en cuenta dichas definiciones, se pasa a definir las métricas utilizadas:\n",
    "- **Precision**\n",
    "> - La **precision** o precisión de una **clase $c_i$** hace referencia a la cantidad de clasificaciones correctas para dicha clase, en relación a la cantidad de clasificaciones totales (correctas e incorrectas) para dicha clase.\n",
    "> - La precision permite determinar \"que tan bien se clasifica una clase\". En otras palabras, que tan poco se equivoca el clasificador en marcar un ejemplo como cierta clase.\n",
    "> - Oscila entre 0 y 1, siendo mejor cuanto **mayor** es.\n",
    "> - Se calcula como:\n",
    "> $$ precision(c_i) = \\frac{t_i}{t_i + f_i}$$\n",
    "\n",
    "- **Recall**\n",
    "> - La **recall** o recuperación de una **clase $c_i$** hace referencia a la cantidad de clasificaciones correctas para dicha clase, en relación a la cantidad de clasificaciones originales para dicha clase.\n",
    "> - La recall permite determinar \"que tan bien se clasifican elementos de otras clases respecto a una clase\". En otras palabras, que tan poco se equivoca el clasificador en marcar un ejemplo de otras clases como cierta clase.\n",
    "> - Oscila entre 0 y 1, siendo mejor cuanto **mayor** es.\n",
    "> - Se calcula como:\n",
    "> $$ recall(c_i) = \\frac{t_i}{t_i + \\bar{f_i}}$$\n",
    "\n",
    "- **Fall-off**\n",
    "> - La **fall-off** de una **clase $c_i$** hace referencia a la cantidad de clasificaciones incorrectas para dicha clase, en relación a la cantidad de clasificaciones complemento (correctas e incorrectas) de dicha clase.\n",
    "> - La fall-off permite determinar \"que tan mal se clasifica una clase\". En otras palabras, es la noción inversa de la recall: cuantos más ejemplos de otra clase sean clasificados como clase $c_i$, más aumenta fall-off.\n",
    "> - Oscila entre 0 y 1, siendo mejor cuanto **menor** es.\n",
    "> - Se calcula como:\n",
    "> $$ falloff(c_i) = \\frac{f_i}{f_i + \\bar{t_i}}$$\n",
    "\n",
    "- **F-measure**\n",
    "> - La **F-measure** o medida-F de una **clase $c_i$** es una medida que relaciona **precision** y **recall**, oficiando de alguna forma como un representante de cierta clase.\n",
    "> - La F-measure permite determinar \"que tan bien se clasifica una clase y que tan poco se falla a la vez\". En otras palabras, es una relación proporcional entre la precision y la recall y por tanto es una buena métrica para determinar el desempeño del clasificador respecto a una clase.\n",
    "> - Oscila entre 0 y 1, siendo mejor cuanto **mayor** es.\n",
    "> - Se calcula como:\n",
    "> $$ Fmeasure(c_i) = \\frac{2 precision(c_i) recall(c_i)}{precision(c_i) + recall(c_i)}$$\n",
    "\n",
    "Si bien estas medidas ofrecen información más enriquecedora en comparación a las anteriormente mencionadas, cuentan con el \"defecto\" de aplicar por clase y no dar una medida general del clasificador. Para conjuntos $D$ con pocas clasificaciones en $C_D$ esto no es un gran problema, pero complica la comparación al aumentar la cantidad de clases. En la siguiente subsección se tratan métricas que tienen como objetivo mejorar este hecho.\n",
    "\n",
    "##### 2.4.3.4 Medidas macro y micro (*)\n",
    "***\n",
    "Existen dos formas genéricas de establecer medidas representativas para un modelo sin importar la clase. En este escenario se implementaron ambas formas, siendo las siguientes:\n",
    "\n",
    "- **Promedios genéricos** \n",
    "> - El promedio genérico de una métrica dada consiste en la suma de las métricas para cada clase dividida por la cantidad de clases.\n",
    "> - Otorga una noción del desempeño general del clasificador en relación a la métrica dada. \n",
    "> - Sea $D$ el conjunto de datos\n",
    "> - Sea $C_D$ el conjuntos de posibles clases\n",
    "> - Sea $|C_D| = n$\n",
    "> - El promedio genérico se calcula como:\n",
    "> $$ metrica_{general} = \\frac{\\sum_{i=1}^{n} metrica(c_i)}{n}$$\n",
    "\n",
    "- **Promedios ponderados:**\n",
    "> - El promedio ponderado de una métrica dada consiste en la suma de las métricas para cada clase ponderada por la proporción de ejemplos en el conjunto de datos para dicha clase.\n",
    "> - Otorga una noción del desempeño del clasificador en relación a la métrica dada, ignorando el ruido generado por mal desempeño en clases con menor cantidad de ejemplos (en otras palabras, es particularmente útil ante conjuntos de datos con una distribución nada uniforme en las clasificaciones de sus ejemplos).\n",
    "> - Sea $D$ el conjunto de datos\n",
    "> - Sea $C_D$ el conjuntos de posibles clases\n",
    "> - Sea $|C_D| = n$\n",
    "> - Sea $c_i \\in C_D$ la i-ésima clase en $C_D$\n",
    "> - Sea $D_i \\subseteq D$ el conjunto de ejemplos clasificados con clase $c_i$\n",
    "> - El promedio ponderado se calcula como:\n",
    "> $$ metrica_{ponderada} = \\sum_{i=1}^{n} metrica(c_i) * \\frac{|D_i|}{|D|}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experimentación\n",
    "***\n",
    "En esta sección se detalla el conjunto de pruebas realizadas, agregandose observaciones pertinentes y comparaciones entre modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Metodología\n",
    "***\n",
    "\n",
    "Con el objetivo de evaluar las estrategias planteadas anteriormente y su efectividad, se probaron combinaciones de las mismas frente a los dos modelos desarrollados. La exprimentación se encaró diviendola en las siguientes etapas:\n",
    "\n",
    "1. **Configuraciones paramétricas:** Luego de llegar a un modelo relativamente libre de errores (al menos de errores identificados), se realizaron pruebas para múltiples configuraciones paramétricas, con el fin de comparar cuales de ellas resultaron en mejores clasificadores. En esta etapa se detallan los datos obtenidos. \n",
    "<br><br>\n",
    "2. **Elección y comparación de representantes:** A falta de suficientes corridas para generar agrupamientos de configuraciones, se compararon manualmente los resultados obtenidos en las pruebas de cada configuración paramétrica de la etapa anterior. En base a distintas métricas, se eligió a aquellos clasificadores con mejores y peores resultados, interpretando la razón de su eficacia.\n",
    "<br><br>\n",
    "3. **Comparación final:** Una vez obtenidos los representantes para cada modelo, se comparó su rendimiento con los representantes obtenidos en la tarea anterior, realizando distintas observaciones en base a la comparación en cuestión.\n",
    "<br><br> \n",
    "4. **Pruebas extra:** Para cerrar, se generaron nuevas evaluaciones para los representantes cambiando ciertos parámetros, con el objetivo de determinar si dichos cambios incidieron de alguna forma (ya sea positiva o negativa) en el rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Configuraciones paramétricas\n",
    "***\n",
    "A continuación se adjuntan las distintas configuraciones paramétricas utilizadas al evaluar, sus motivaciones y sus resultados. Se realizan pequeñas observaciones sobre los mismos, quedando el análisis exhaustivo pendiente para la siguiente sección.\n",
    "\n",
    "#### 3.2.1. Evaluaciones\n",
    "***\n",
    "\n",
    "Debido a que los tiempos de entrenamiento y evaluación fueron notablemente mejores que en la anterior tarea, se lograron generar evaluaciones cruzadas para *CoverType*, aumentando la cantidad de evaluaciones totales realizadas.\n",
    "\n",
    "En una primera instancia, se realizaron un total de **234 evaluaciones**, de las cuales **72** corresponden a **Naive Bayes** y **164** a **KNN**. Las mismas se distribuyen según los siguientes parámetros:\n",
    "\n",
    "- Evaluaciones en **Naive Bayes**:\n",
    "> - Conjunto de datos utilizado (2 opciones: *Iris*, *CoverType*)\n",
    "> - Tipo de evaluación utilizada (2 opciones: **Normal**, **Cruzada**)\n",
    "> - Utilización de *one hot encoding* (2 opciones: **Si**, **No**)\n",
    "> - Estrategia de atributos continuos utilizada (2 opciones: **Distribución normal**, **Intervalos variables**)\n",
    "> - Valor de m-estimador utilizado (5 opciones: **0, 0.01, 0.5, 1, 100**)\n",
    "\n",
    "- Evaluaciones en **KNN**:\n",
    "> - Conjunto de datos utilizado (2 opciones: *Iris*, *CoverType*)\n",
    "> - Tipo de evaluación utilizada (2 opciones: **Normal**, **Cruzada**)\n",
    "> - Utilización de *one hot encoding* (2 opciones: **Si**, **No**)\n",
    "> - Cantidad de vecinos evaluada (3 opciones: **1, 3, 7**)\n",
    "> - Medida de distancia utilizada (3 opciones: **Manhattan**, **Euclídea**, **Chebychev**)\n",
    "> - Estrategia de normalización utilizada (3 opciones: **Euclídea**, **Reescalamiento**, **Estandarización**)\n",
    "\n",
    "Cabe destacar que en el conjunto de datos *Iris* no hay atributos utilizando *one hot encoding* por lo que no se implementó distintas estrategias en ese caso, reduciendo la cantidad de evaluaciones a la mitad (en comparación a la cantidad de evaluaciones para *CoverType*).\n",
    "\n",
    "También es importante mencionar que para los datos generados con **KNN** no se utilizaron ciertas configuraciones paramétricas. De hecho, en *CoverType*, siempre se utilizó una estructura de KDTree, debido al gran tamaño del conjunto de datos. En cambio en *Iris*, se utilizó la estructura tradicional. Por otra parte, siempre se utilizaron estrategias de normalización y como votación nunca se utilizó la ponderada. En la sección 3.5 se prueban dichos cambios utilizando un subconjunto de configuraciones paramétricas.\n",
    "\n",
    "De esta forma, se generaron **24** y **48** evaluaciones para **Naive Bayes** en *Iris* y *CoverType* respectivamente, y **54** y **108** evaluaciones para **KNN** en *Iris* y *CoverType* respectivamente.\n",
    "\n",
    "#### 3.2.2. Resultados\n",
    "***\n",
    "A continuación se adjuntan los resultados de dichos entrenamientos y sus respectivas evaluaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.2.1. Resultados por clasificador\n",
    "***\n",
    "Con el objetivo de facilitar la lectura, se desarrolló un *script* que permite seleccionar cualquiera de las **234 evaluaciones** realizadas y obtener todas las métricas calculadas. Sumado a esto, se agregan las evaluaciones correspondientes a la anterior entrega.\n",
    "\n",
    "**Notas:**\n",
    "- Para las validaciones cruzadas no se adjunta matriz de confusión, ya que se muestran las métricas promediadas en base a la cantidad de particiones y no las métricas de cada partición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import getConfusionMatrix.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.2.2. Resultados generales\n",
    "***\n",
    "Con el objetivo de facilitar la lectura, se desarrollaron un *script* que permite filtrar los resultados de las evaluaciones según 3 parámetros: **modelo**, **conjunto de datos**, **estrategia de evaluación**. Una vez filtrados, se muestra una tabla comparativa de las métricas obtenidas, así como una gráfica de barras que permite comparar rápidamente distintas configuraciones paramétricas según dos métricas: **F-measure ponderada** y **Fall-off ponderada**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style=\"text-align: center;\">Seleccione la evaluación que desee visualizar</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5e8263ca1904e4b8cf38956688ed980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Box(children=(Dropdown(index=1, options=('Conjunto: Iris', 'Conjunto: Covertype'), value='Conjun…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td><b>Indice</b></td><td><b>Onehot</b></td><td><b>Continuos</b></td><td><b>mEst</b></td><td><b>|</b></td><td><b>Accuracy</b></td><td><b>Precisión promediada</b></td><td><b>Precisión ponderada</b></td><td><b>Recall promediado</b></td><td><b>Recall ponderado</b></td><td><b>Fall-off promediado</b></td><td><b>Fall-off ponderado</b></td><td><b>F-Measure promediada</b></td><td><b>F-Measure ponderado</b></td></tr>\n",
       "<tr><td>1            </td><td>No           </td><td>Standarization  </td><td>0.0        </td><td>|       </td><td>0.6109         </td><td>0.4701                     </td><td>0.6399                    </td><td>0.4579                  </td><td>0.6109                 </td><td>0.0737                    </td><td>0.1747                   </td><td>0.4415                     </td><td>0.5985                    </td></tr>\n",
       "<tr><td>2            </td><td>No           </td><td>Standarization  </td><td>0.01       </td><td>|       </td><td>0.6101         </td><td>0.4633                     </td><td>0.6392                    </td><td>0.4564                  </td><td>0.6101                 </td><td>0.0736                    </td><td>0.1730                   </td><td>0.4370                     </td><td>0.5976                    </td></tr>\n",
       "<tr><td>3            </td><td>No           </td><td>Standarization  </td><td>0.5        </td><td>|       </td><td>0.6101         </td><td>0.4658                     </td><td>0.6392                    </td><td>0.4598                  </td><td>0.6101                 </td><td>0.0737                    </td><td>0.1739                   </td><td>0.4393                     </td><td>0.5976                    </td></tr>\n",
       "<tr><td>4            </td><td>No           </td><td>Standarization  </td><td>1.0        </td><td>|       </td><td>0.6126         </td><td>0.4553                     </td><td>0.6396                    </td><td>0.4523                  </td><td>0.6126                 </td><td>0.0732                    </td><td>0.1731                   </td><td>0.4300                     </td><td>0.6001                    </td></tr>\n",
       "<tr><td>5            </td><td>No           </td><td>Standarization  </td><td>100.0      </td><td>|       </td><td>0.6092         </td><td>0.4553                     </td><td>0.6376                    </td><td>0.4544                  </td><td>0.6092                 </td><td>0.0738                    </td><td>0.1740                   </td><td>0.4311                     </td><td>0.5969                    </td></tr>\n",
       "<tr><td>6            </td><td>No           </td><td>Variable        </td><td>0.0        </td><td>|       </td><td>0.6749         </td><td>0.5094                     </td><td>0.6822                    </td><td>0.5752                  </td><td>0.6749                 </td><td>0.0614                    </td><td>0.1509                   </td><td>0.5364                     </td><td>0.6775                    </td></tr>\n",
       "<tr><td>7            </td><td>No           </td><td>Variable        </td><td>0.01       </td><td>|       </td><td>0.6746         </td><td>0.5129                     </td><td>0.6826                    </td><td>0.5810                  </td><td>0.6746                 </td><td>0.0614                    </td><td>0.1504                   </td><td>0.5409                     </td><td>0.6774                    </td></tr>\n",
       "<tr><td>8            </td><td>No           </td><td>Variable        </td><td>0.5        </td><td>|       </td><td>0.6749         </td><td>0.5160                     </td><td>0.6817                    </td><td>0.5772                  </td><td>0.6749                 </td><td>0.0614                    </td><td>0.1507                   </td><td>0.5418                     </td><td>0.6772                    </td></tr>\n",
       "<tr><td>9            </td><td>No           </td><td>Variable        </td><td>1.0        </td><td>|       </td><td>0.6712         </td><td>0.5130                     </td><td>0.6787                    </td><td>0.5762                  </td><td>0.6712                 </td><td>0.0618                    </td><td>0.1510                   </td><td>0.5397                     </td><td>0.6738                    </td></tr>\n",
       "<tr><td>10           </td><td>No           </td><td>Variable        </td><td>100.0      </td><td>|       </td><td>0.6730         </td><td>0.5174                     </td><td>0.6797                    </td><td>0.5677                  </td><td>0.6730                 </td><td>0.0617                    </td><td>0.1519                   </td><td>0.5388                     </td><td>0.6754                    </td></tr>\n",
       "<tr><td>11           </td><td>Si           </td><td>Standarization  </td><td>0.0        </td><td>|       </td><td>0.6624         </td><td>0.4959                     </td><td>0.6744                    </td><td>0.5935                  </td><td>0.6624                 </td><td>0.0628                    </td><td>0.1508                   </td><td>0.5271                     </td><td>0.6666                    </td></tr>\n",
       "<tr><td>12           </td><td>Si           </td><td>Standarization  </td><td>0.01       </td><td>|       </td><td>0.6626         </td><td>0.4965                     </td><td>0.6743                    </td><td>0.5912                  </td><td>0.6626                 </td><td>0.0627                    </td><td>0.1506                   </td><td>0.5285                     </td><td>0.6667                    </td></tr>\n",
       "<tr><td>13           </td><td>Si           </td><td>Standarization  </td><td>0.5        </td><td>|       </td><td>0.6611         </td><td>0.4929                     </td><td>0.6735                    </td><td>0.5872                  </td><td>0.6611                 </td><td>0.0630                    </td><td>0.1515                   </td><td>0.5231                     </td><td>0.6655                    </td></tr>\n",
       "<tr><td>14           </td><td>Si           </td><td>Standarization  </td><td>1.0        </td><td>|       </td><td>0.6620         </td><td>0.4948                     </td><td>0.6743                    </td><td>0.5945                  </td><td>0.6620                 </td><td>0.0628                    </td><td>0.1512                   </td><td>0.5276                     </td><td>0.6663                    </td></tr>\n",
       "<tr><td>15           </td><td>Si           </td><td>Standarization  </td><td>100.0      </td><td>|       </td><td>0.6659         </td><td>0.5067                     </td><td>0.6744                    </td><td>0.5855                  </td><td>0.6659                 </td><td>0.0624                    </td><td>0.1520                   </td><td>0.5369                     </td><td>0.6689                    </td></tr>\n",
       "<tr><td>16           </td><td>Si           </td><td>Variable        </td><td>0.0        </td><td>|       </td><td>0.6678         </td><td>0.5096                     </td><td>0.6814                    </td><td>0.6131                  </td><td>0.6678                 </td><td>0.0618                    </td><td>0.1478                   </td><td>0.5474                     </td><td>0.6727                    </td></tr>\n",
       "<tr><td>17           </td><td>Si           </td><td>Variable        </td><td>0.01       </td><td>|       </td><td>0.6691         </td><td>0.5094                     </td><td>0.6825                    </td><td>0.6101                  </td><td>0.6691                 </td><td>0.0616                    </td><td>0.1473                   </td><td>0.5470                     </td><td>0.6740                    </td></tr>\n",
       "<tr><td>18           </td><td>Si           </td><td>Variable        </td><td>0.5        </td><td>|       </td><td>0.6701         </td><td>0.5080                     </td><td>0.6845                    </td><td>0.6118                  </td><td>0.6701                 </td><td>0.0614                    </td><td>0.1465                   </td><td>0.5458                     </td><td>0.6753                    </td></tr>\n",
       "<tr><td>19           </td><td>Si           </td><td>Variable        </td><td>1.0        </td><td>|       </td><td>0.6689         </td><td>0.5075                     </td><td>0.6830                    </td><td>0.6054                  </td><td>0.6689                 </td><td>0.0616                    </td><td>0.1470                   </td><td>0.5435                     </td><td>0.6740                    </td></tr>\n",
       "<tr><td>20           </td><td>Si           </td><td>Variable        </td><td>100.0      </td><td>|       </td><td>0.6738         </td><td>0.5213                     </td><td>0.6840                    </td><td>0.5961                  </td><td>0.6738                 </td><td>0.0612                    </td><td>0.1487                   </td><td>0.5519                     </td><td>0.6776                    </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.print_figure_kwargs={'bbox_inches':None}\n",
    "import getTables.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Elección y comparación de representantes\n",
    "***\n",
    "A continuación se presenta un análisis de los resultados obtenidos, separandose en dos procesos: elección y comparación.\n",
    "\n",
    "#### 3.3.1. Elección\n",
    "***\n",
    "Para determinar cuales fueron los clasificadores con mejor desempeño (denominados \"representantes\") frente a los posibles candidatos se siguió el siguiente proceso:\n",
    "1. Utilizando el script de comparación con tablas y gráficas, se eligió aquellas configuraciones paramétricas con mejores métricas (en resumen, tomar aquellas con mayor **F-measure** y menor **Fall-off**) .\n",
    "2. Para cada grupo con mejores métricas se evaluó manualmente cada configuración, comprobando todas sus métricas y buscando alguna anomalía (positiva o negativa) dentro del grupo en cuestión.\n",
    "3. Para aquellos grupos con métricas similares y sin anomalías se eligió un representante de forma pseudoaleatoria (es decir, al azar pero teniendo ciertas consideraciones). Por otra parte, para aquellos grupos con métricas similares donde se detectó que alguna configuración contaba con mejores métricas en cierto aspecto, se tomó dicha configuración como representante.\n",
    "\n",
    "De esta forma, se determinó que los representantes son los siguientes:\n",
    "\n",
    "- Para **Naive Bayes**, la configuración que determina revertir *one hot encoding*, intervalos variables, m-estimador $m = 0.5$.\n",
    "- Para **KNN**, la configuración que determina revertir *one hot encoding*, $k = 3$, distancia manhattan, norma euclídea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2. Comparación\n",
    "***\n",
    "\n",
    "A continuación se realizan observaciones e interpretaciones obtenidas al comparar los resultados obtenidos en los modelos **Naive Bayes** y **KNN**. Cabe destacar que estos modelos también serán comparados frente a **Árbol de decisión** y **Bosque de decisión**, sin embargo las observaciones de dicha comparación se detallan en la siguiente sección, utilizando solamente a los representantes obtenidos en la sección anterior.\n",
    "\n",
    "**Observaciones generales:**\n",
    "\n",
    "- Sobre los parámetros:\n",
    "> 1. Mantener el *one hot encoding* para los atributos incidió en resultados con un desempeño mejor o similar a revertir el *one hot encoding*.\n",
    "> 2. Para el modelo **Naive Bayes**, la estrategia de discretizar valores continuos en **intervalos variables** dio mejores resultados frente a asumir **distribución normal** los valores para los atributos continuos.\n",
    "> 3. Para el modelo **Naive Bayes**, el parámetro **m-estimador** tuvo un impacto casi nulo en los resultados obtenidos, en el sentido de que no se percibió una variación en los resultados asociada a la variación del m-estimador.\n",
    "> 4. Para el modelo **KNN**, la elección de **estrategia de normalización** varió mucho su desempeño según si el *one hot encoding* fue revertido o no.\n",
    "> 5. Para el modelo **KNN** cuando al revertir el *one hot encoding*, se observó que:\n",
    "    - La *norma Euclídea* dio los mejores resultados.\n",
    "    - La *norma Min-Max (Reescalamiento)* dio las peores *F-measures* y malas *Fall-off*\n",
    "    - La *norma Z-Score (Estandarización)* dio las peores *Fall-off* y malas *F-measure*.\n",
    "    \n",
    "- Sobre los resultados:\n",
    "> 1. Los resultados en *Iris* fueron similares en general.\n",
    "> 2. Para determinadas configuraciones paramétricas, el desempeño en *Covertype* del modelo **KNN** superó al de **Naive Bayes**, alcanzando valores considerablemente superiores para cada métrica.\n",
    "> 3. Algunos resultados tuvieron una gran diferencia entre sus promedios generales y promedios ponderados (siendo los últimos bastante más altos).\n",
    "\n",
    "Tomando en cuenta la información anterior, se determinó que para los modelos empleados, el mejor modelo para clasificar el conjunto *Covertype* es **KNN**. Sin embargo debe tenerse precaución, dado que para algunas configuraciones de los parámetros esto no es siempre el caso.\n",
    "\n",
    "Es importante observar que las evaluaciones utilizadas, especialmente en *Covertype*, pueden estar sujetas a ruido y por tanto ofrecer información \"tramposa\". El implementar técnicas de análisis estadístico como *Tests de Friedman* entre múltiples evaluaciones para una misma configuración, podría ayudar a reducir esto. También el correr distintas validaciones cruzadas en *Covertype* podría dar mejores nociones sobre el modelo **KNN**.\n",
    "\n",
    "En cualquier caso, a continuación se adjunta una serie de interpretaciones, producto de las observaciones hechas a los resultados. Dichas interpretaciones se basan en fundamentos teóricos y sensaciones empíricas, por lo que no escalan a algo más que eso, interpretaciones.\n",
    "\n",
    "**Interpretaciones:**\n",
    "\n",
    "- Sobre los parámetros:\n",
    "> 1. Para el modelo **Naive Bayes**, se presume que el parámetro **m-estimador** tiene un impacto nulo en los resultados obtenidos, debido a que la cantidad de ocurrencias del caso borde que el **m-estimador** resuelve fue despreciable (o inclusive nula). En el caso de que haya sido nula, se pueden asociar las leves desviaciones en los resultados de cada métrica a la distribución aleatoria de ejemplos para los conjuntos de entrenamiento y validación.\n",
    "\n",
    "- Sobre los resultados:\n",
    "> 1. La diferencia entre promedios generales y ponderados se da debido a que las clases 4, 5, 6 y 7 cuentan con una mucho menor cantidad de elementos en comparación a las clases 1, 2 y 3. Al tener peor desempeño en las clases de menor proporción, los promedios ponderados dan mejor resultado por darle menos importancia a dichas clases.\n",
    "> 2. Parece ser que **KNN** es un mejor modelo para clasificar conjuntos con una extensa cantidad de atributos continuos en lugar de categóricos, debido a su gran desempeño en el conjunto *Covertype*.\n",
    "> 3. Parece ser que **Naive Bayes** es un mejor modelo para clasificar conjuntos con atributos categóricos, debido a que dio mejores resultados cuando se discretizaron los atributos continuos en intervalos variables que cuando se estandarizaron los valores de los mismos.\n",
    "\n",
    "Tomando las anteriores interpretaciones, el hecho de que el **m-estimador** haya tenido impacto nulo sumado al hecho de que el desempeño de **KNN** fue mejor que el de **Naive Bayes**, parece indicar que la implementación de **Naive Bayes** con **m-estimador** sería clave en un conjunto de datos con valores discretos y posibles clasificaciones nuevas o faltantes. Dado que los conjuntos de prueba utilizados son continuos, no se pudo probar si esta hipótesis es correcta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Comparación final\n",
    "***\n",
    "Tomando los representantes de la tarea anterior y de la tarea actual, se realizó una comparación con el objetivo de ver que modelo obtuvo mejor desempeño para la evaluación de *CoverType*.\n",
    "\n",
    "A continuación se adjunta una tabla y una gráfica comparativa de los resultados obtenidos en cada evaluación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th>Modelo</th>\n",
    "        <th>Onehot</th>\n",
    "        <th>Configuración del modelo</th>\n",
    "        <th>|</th>\n",
    "        <th>Accuracy</th>\n",
    "        <th>Precision promediada</th>\n",
    "        <th>Precision ponderada</th>\n",
    "        <th>Recall promediada</th>\n",
    "        <th>Recall ponderada</th>\n",
    "        <th>Fall-off promediada</th>\n",
    "        <th>Fall-off ponderada</th>\n",
    "        <th>F-measure promediada</th>\n",
    "        <th>F-measure ponderada</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Árbol</td>\n",
    "        <td>No</td>\n",
    "        <td><b>Continuos:</b> Maximizando ganancia, <b>Medida:</b> Reducción de Impureza</td>\n",
    "        <td>|</td>\n",
    "        <td>0.655</td>\n",
    "        <td>0.652</td>\n",
    "        <td>0.653</td>\n",
    "        <td>0.531</td>\n",
    "        <td>0.655</td>\n",
    "        <td>0.069</td>\n",
    "        <td>0.197</td>\n",
    "        <td>0,556</td>\n",
    "        <td>0,648</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bosque</td>\n",
    "        <td>No</td>\n",
    "        <td><b>Continuos:</b> Maximizando ganancia, <b>Medida:</b> Reducción de Impureza</td>\n",
    "        <td>|</td>\n",
    "        <td>0.689</td>\n",
    "        <td>0.438</td>\n",
    "        <td>0.711</td>\n",
    "        <td>0.483</td>\n",
    "        <td>0.689</td>\n",
    "        <td>0.059</td>\n",
    "        <td>0.137</td>\n",
    "        <td>0,454</td>\n",
    "        <td>0,696</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bayes</td>\n",
    "        <td>No</td>\n",
    "        <td><b>Continuos:</b> Intervalos variables, <b>mEst:</b> 0.5</td>\n",
    "        <td>|</td>\n",
    "        <td>0.6749</td>\n",
    "        <td>0.5160</td>\n",
    "        <td>0.6817</td>\n",
    "        <td>0.5772</td>\n",
    "        <td>0.6749</td>\n",
    "        <td>0.0614</td>\n",
    "        <td>0.1507</td>\n",
    "        <td>0.5418</td>\n",
    "        <td>0.6772</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>KNN</td>\n",
    "        <td>No</td>\n",
    "        <td><b>K:</b> 3, <b>Distancia:</b> 'Manhattan', <b>Norma:</b> Euclidea</td>\n",
    "        <td>|</td>\n",
    "        <td>0.9565</td>\n",
    "        <td>0.9358</td>\n",
    "        <td>0.9564</td>\n",
    "        <td>0.9101</td>\n",
    "        <td>0.9565</td>\n",
    "        <td>0.0098</td>\n",
    "        <td>0.0266</td>\n",
    "        <td>0.9223</td>\n",
    "        <td>0.9564</td>\n",
    "    </tr>\n",
    "    <caption>Tabla 1 - Resultados de entrenamiento de conjunto <b>CoverType</b> para representantes de modelos</caption>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: inline-block; width: 99%; text-align: center; margin-top: 16px;\">\n",
    "    <img src=\"img/finalplot.png\" />\n",
    "    <label style=\"margin-top: 16px; font-size: 16px; font-family: monospace;\"> Figura 3.1 - Resultados de entrenamiento de conjunto CoverType para representantes de modelos</label>\n",
    "</div>\n",
    "\n",
    "Se puede ver que el desempeño de **Naive Bayes** fue similar al del **Árbol de Decisión**, siendo un poco mejor que el del **Bosque de Decisión**. No obstante, el modelo que sin duda tuvo un mucho mejor desempeño fue **KNN**.\n",
    "\n",
    "Teniendo en cuenta las observaciones de la anterior sección, parece lógico que los modelos bayesianos y basados en árboles tengan un peor desempeño, ya que trabajan mejor con atributos discretos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Pruebas extra\n",
    "***\n",
    "\n",
    "#### 3.5.1 Fundamentación\n",
    "***\n",
    "Habiendo entrenado varios modelos con distintas configuraciones paramétricas, se vio la necesidad de generar pruebas extra para ciertas consideraciones que no se tuvieron en cuenta para modelos **KNN**. Más concretamente, no se probó la opción de **no normalizar** ni la opción de utilizar una **votación ponderada**.\n",
    "\n",
    "Por limitaciones de tiempo, se utilizaron algunos representantes de **KNN** con un buen y un mal rendimiento respectivamente, con el objetivo de detectar si dichos cambios impactan positiva o negativamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.2 Resultados obtenidos\n",
    "***\n",
    "A continuación se adjuntan los resultados obtenidos para algunos experimentos\n",
    "\n",
    "**Nota:** Las filas celestes son resultados generados anteriormente y sobre los cuales se \"pivoteó\" los valores de la normalización y de la votación. Se agregaron a la tabla a modo de comparación.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Onehot</th>\n",
    "        <th>K</th>\n",
    "        <th>Distancia</th>\n",
    "        <th>Norma</th>\n",
    "        <th>Ponderado</th>\n",
    "        <th>|</th>\n",
    "        <th>Accuracy</th>\n",
    "        <th>Precision promediada</th>\n",
    "        <th>Precision ponderada</th>\n",
    "        <th>Recall promediada</th>\n",
    "        <th>Recall ponderada</th>\n",
    "        <th>Fall-off promediada</th>\n",
    "        <th>Fall-off ponderada</th>\n",
    "        <th>F-measure promediada</th>\n",
    "        <th>F-measure ponderada</th>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #95dcd4;\">\n",
    "        <th>Sí</th>\n",
    "        <th>3</th>\n",
    "        <th>'Manhattan'</th>\n",
    "        <th>Euclídea</th>\n",
    "        <th>No</th>\n",
    "        <td>|</td>\n",
    "        <td>0.9532</td>\n",
    "        <td>0.9353</td>\n",
    "        <td>0.9531</td>\n",
    "        <td>0.9027</td>\n",
    "        <td>0.9532</td>\n",
    "        <td>0.0106</td>\n",
    "        <td>0.0288</td>\n",
    "        <td>0.9181</td>\n",
    "        <td>0.9531</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Sí</th>\n",
    "        <th>3</th>\n",
    "        <th>'Manhattan'</th>\n",
    "        <th>Ninguna</th>\n",
    "        <th>No</th>\n",
    "        <td>|</td>\n",
    "        <td>0.9711</td>\n",
    "        <td>0.9529</td>\n",
    "        <td>0.9711</td>\n",
    "        <td>0.9404</td>\n",
    "        <td>0.9711</td>\n",
    "        <td>0.0065</td>\n",
    "        <td>0.0174</td>\n",
    "        <td>0.9464</td>\n",
    "        <td>0.9711</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Sí</th>\n",
    "        <th>3</th>\n",
    "        <th>'Manhattan'</th>\n",
    "        <th>Euclídea</th>\n",
    "        <th>Sí</th>\n",
    "        <td>|</td>\n",
    "        <td>0.9549</td>\n",
    "        <td>0.9340</td>\n",
    "        <td>0.9548</td>\n",
    "        <td>0.9099</td>\n",
    "        <td>0.9549</td>\n",
    "        <td>0.0102</td>\n",
    "        <td>0.0273</td>\n",
    "        <td>0.9212</td>\n",
    "        <td>0.9548</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #95dcd4;\">\n",
    "        <th>No</th>\n",
    "        <th>1</th>\n",
    "        <th>Chebychev</th>\n",
    "        <th>Min Max</th>\n",
    "        <th>No</th>\n",
    "        <td>|</td>\n",
    "        <td>0.3005</td>\n",
    "        <td>0.2393</td>\n",
    "        <td>0.5115</td>\n",
    "        <td>0.3565</td>\n",
    "        <td>0.3005</td>\n",
    "        <td>0.1082</td>\n",
    "        <td>0.1255</td>\n",
    "        <td>0.2104</td>\n",
    "        <td>0.2935</td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <th>No</th>\n",
    "        <th>1</th>\n",
    "        <th>Chebychev</th>\n",
    "        <th>Min Max</th>\n",
    "        <th>Sí</th>\n",
    "        <td>|</td>\n",
    "        <td>0.2684</td>\n",
    "        <td>0.2235</td>\n",
    "        <td>0.4846</td>\n",
    "        <td>0.3358</td>\n",
    "        <td>0.2684</td>\n",
    "        <td>0.1108</td>\n",
    "        <td>0.1158</td>\n",
    "        <td>0.1937</td>\n",
    "        <td>0.2780</td>\n",
    "    </tr>\n",
    "    <caption>Tabla 2 - Resultados de entrenamiento de conjunto <b>CoverType</b> para pruebas extra</caption>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.3 Comparación\n",
    "***\n",
    "Es interesante observar que para el primer ejemplo celeste, el cual tuvo muy buenos resultados, el cambiar la forma de votación y el no normalizar **ambos** tuvieron un impacto de mejora sobre las métricas, por sobretodo el no normalizar.\n",
    "\n",
    "Esto va en contra de nuestra suposición inicial, ya que existen en *CoverType* algunos atributos con valores drásticamente mayores en magnitud frente a otros. El hecho de que el no normalizar diera mejores resultados parece indicar que dichos atributos son cruciales a la hora de clasificar y tienen un mayor peso que el resto.\n",
    "\n",
    "Por otra parte, al tomar el segundo ejemplo celeste, el cual tuvo un mal desempeño en general, al cambiar la forma de votación a ponderada, empeoraron todas las métricas.\n",
    "\n",
    "Para poder determinar información más concluyente debería correrse más evaluaciones variando otros parámetros. A priori parece ser que la decisión de no normalizar no fue buena."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusiones\n",
    "***\n",
    "\n",
    "#### 4.1. Respecto a los Modelos\n",
    "***\n",
    "Si bien **Naive Bayes** tuvo un desempeño similar a al de los **Árboles de decisión** y **Bosques de decisión**, se encontró que **KNN** representó una gran mejora frente al resto dentro del conjunto *Covertype*.\n",
    "\n",
    "Se concluye que para el conjunto *Covertype* el modelo **KNN** da como resultado el mejor clasificador en comparación al resto de los modelos con los que se experimentó. También se presume que esta afirmación debería cumplirse para conjuntos similiares a *Covertype*, es decir, conjuntos multiclase, con múltiples atributos continuos distribuidos dentro de múltiples rangos de valores, así como con una distribución no uniforme de ejemplos para cada posible clase.\n",
    "\n",
    "Dicha declaración no puede comprobarse a ciencia cierta con los datos generados en esta experimentación, por lo que son nada más que leves conjeturas.\n",
    "\n",
    "#### 4.2. Respecto a los Atributos\n",
    "***\n",
    "Se comprobó empiricamente que tanto **Naive Bayes** como **KNN** son más adecuados para ser empleados a la hora de generar un calificador para conjuntos de gran magnitud en ejemplos y atributos como lo es *Covertype*, esta afirmación es debido a que por su baja carga en el entrenamiento, fue posible generar un clasificador en un tiempo adecuado mantuviendo el *one hot encoding*, a diferencia del caso para **Árboles de decisión** y **Bosques de decisión**.\n",
    "\n",
    "A su vez se presume que **KNN** da mejores resultados a la hora de clasificar conjuntos con una gran cantidad de atributos continuos en lugar de categoricos, sin embargo se carecen de pruebas suficientes para dar una afirmación solida respecto a este último punto.\n",
    "\n",
    "#### 4.3. Respecto a los Parámetros\n",
    "***\n",
    "Un parámetro clave a la hora de observar los resultados en *Covertype* fue la utilización del *one hot encoding*; dando resultados con mejores métricas para **Naive Bayes** (al ser utilizado el *one hot encoding*) y teniendo un efecto de gran proporción en el desempeño de la **estrategia de normalización** empleada para **KNN**. Si bien se esperaba de antemano que utilizar el *one hot encoding* diese resultados iguales o mejores frente a no utilizarlo, el haber experimentado con este parámetro enriqueció en gran magnitud las observaciones y conclusiones de este estudio.\n",
    "\n",
    "##### 4.3.1. Parámetros para Naive Bayes\n",
    "***\n",
    "A diferencia de lo esperado originalmente, un parámetro que tuvo muy bajo impacto en el rendimiento de los resultados al clasificar el conjunto *Covertype* fue el valor del **m-estimador**. Debido al rendimiento tan similar al variar este parámetro, como ya se mencionó anteriormente, se cree que el hecho de tratar con atributos continuos anuló la posibilidad de darle utilidad a este parámetro. De hecho, es posible (mas no se tienen pruebas) que en un conjunto de datos categórico con valores faltantes su desempeño fuera mucho mejor. \n",
    "\n",
    "También se destaca como independientemente al valor del resto de los parámetros, la estrategía de discretizar los atributos continuos partiendo en **intervalos variables** tuvo mejor desempeño que la interpretación como **distribución normal** de los atributos continuos (para el conjunto *Covertype*). Se presume que esto se dio debido a que **Naive Bayes** funciona mejor con atributos discretos que continuos, sin embargo, otra vez se carecen de pruebas suficientes para dar una afirmación solida respecto a este último punto.\n",
    "\n",
    "##### 4.3.2. Parámetros para KNN\n",
    "***\n",
    "Al contrario a lo que se esperaba, uno de los parámetros que menos impactó los resultados obtenidos fue el parámetro $k$,  dado que variarlo se obtuvieron resultados muy similares respecto a los resultados obtenidos con distinto valor de $k$ y el mismo valor para el resto de los parámetros. Es posible que el bajo impacto de $k$ se haya dado a causa de la distribución de datos que *Covertype* posee.\n",
    "\n",
    "Si bien todas las **funciones de distancia** probadas tuvieron un desempeño similar, se destaca como para los resultados obtenidos en el conjunto *Covertype* la **distancia manhattan** siempre dio resultados similares o levemente superiores al resto de las distancias.\n",
    "\n",
    "Por otra parte, la **normalización con norma euclídea** se desempeñó considerablemente mejor al resto cuando no se empleó *one hot encoding*, sin embargo al emplear *one hot encoding* tuvo un desempeño bastante similar al resto de las otras normas para la mayoría de resultados obtenidos. Si bien no se evaluó exhaustivamente en la configuración paramétrica, se resalta que el mejor resultado obtenido fue al **no emplear ninguna norma**.\n",
    "\n",
    "#### 4.4. Respecto a los Resultados\n",
    "***\n",
    "Nuevamente una observación primordial fue que los resultados obtenidos al validar los calificadores del conjunto *Covertype* fueron peores con respecto a los calificadores del conjunto *Iris* (pese a que KNN haya dado resultados similares para ambos conjuntos), esto tiene sentido, debido a que el conjunto *Covertype* posee una complejidad mayor respecto al conjunto *Iris*, tanto en la cantidad de clases distintas a clasificar como en en cantidad de atributos y el rango de sus valores.\n",
    "\n",
    "Para poder establecer más información al respecto de la eficacia de los modelos, es probable que fuera necesario probar su desempeño para otros conjuntos; en particular alguno cuyas caracteristicas difieran del conjunto *Covertype*, por ejemplo un conjunto de similar magnitud pero que todos sus atributos sean categóricos.\n",
    "\n",
    "#### 4.5. Posibles mejoras\n",
    "***\n",
    "Para cerrar, se adjunta una lista de mejoras consideradas a la experimentación actual:\n",
    "- Probar exhaustivamente el desempeño del valor *ninguna norma* en **KNN**.\n",
    "- Buscar optimizar los modelos **Árbol de decisión** y **Bosque de decisión** para que sea posible obtener resultados empleando el *one hot encoding*. Esto permitiria una mejor comparación de resultados obtenidos frente a **Naive Bayes** y **KNN**\n",
    "- Fijar múltiples conjuntos de entrenamiento y validación y obtener nuevos resultados para cada configuración paramétrica. Esto permitiria realizar un *Test de Friedman* y con su análisis ad hoc, obtener observaciones de mayor o igual calidad.\n",
    "- Probar los modelos y cada una de sus configuraciones paramétricas frente a otros conjuntos distintos a *Iris* y *Covertype*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
