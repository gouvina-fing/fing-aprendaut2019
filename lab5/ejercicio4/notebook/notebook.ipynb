{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega 5.1 - Clasificador (Regresión Logística)\n",
    "\n",
    "### Grupo 07:\n",
    "     - Renzo Gambone C.I. 5.155.486-4\n",
    "     - Germán Ouviña C.I. 4.823.566-1\n",
    "     - Leandro Rodríguez C.I 4.691.736-4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción\n",
    "***\n",
    "### 1.1. Objetivo\n",
    "***\n",
    "El objetivo de esta tarea fue implementar clasificadores basados en **regresión logística**, aplicando **PCA** en el corpus para ciertos escenarios. Una vez generados distintos clasificadores en base a varios parámetros, se evaluó la performance de los mismos utilizando distintos tipos de métricas y se compararon dichas evaluaciones con el fin de determinar cual modelo se ajustó mejor a cada escenario.\n",
    "\n",
    "En términos formales, los parámetros del problema se reducen a lo siguiente:\n",
    "- **Tarea *T*:** Clasificar ejemplos de un conjunto restringido a cierto formato dado.\n",
    "- **Experiencia *E*:** Conjunto de datos del formato apropiado con ejemplos previamente clasificados.\n",
    "- **Performance *P*:** Múltiples tipos de medidas (las cuales se profundizan en la sección 2.4).\n",
    "\n",
    "### 1.2. Entrega\n",
    "***\n",
    "La entrega de esta tarea consta de dos grandes componentes:\n",
    "- **Informe** en formato de Jupyter Notebook (este informe).\n",
    "- **Programa** que permite entrenar clasificadores, evaluar su desempeño, etc.\n",
    "\n",
    "El objetivo del informe es centralizar la información relativa a las pautas de la letra, situando el enfoque en la construcción de los distintos modelos, así como en los datos obtenidos mediante las pruebas realizadas con varias configuraciones paramétricas. Se adjuntan algunos scripts para ayudar a la lectura o probar en tiempo real ciertas funcionalidades.\n",
    "\n",
    "Por otra parte, el programa ofrece una interfaz en consola que permite entrenar y evaluar clasificadores acorde a múltiples configuraciones paramétricas. A su vez, permite comparar distintos clasificadores automaticamente. Si bien todas estas herramientas fueron pensadas para uso del grupo, en el archivo *README.md* se adjunta una sencilla guía de como utilizarlas.\n",
    "\n",
    "### 1.3. Estructura\n",
    "***\n",
    "En las siguientes secciones se especifica el diseño del modelo, justificando la toma de decisiones a la hora de establecer los parámetros y detallando que bibliotecas fueron utilizadas, junto a las métricas utilizadas en la evaluación. Luego, se detalla la metodología de experimentación y con la misma los resultados obtenidos para cada modelo y cada conjunto de datos, habiendo entrenado con distintas configuraciones paramétricas. Finalmente se agregan conclusiones respecto a los resultados obtenidos.\n",
    "\n",
    "Como detalle importante, dado que la tarea se construyó de cierta forma y la consigna cuenta con pautas específicas, a continuación se especifíca en que sección se trata cada punto:\n",
    "\n",
    "La sección 2 (**Diseño**) A.\n",
    "\n",
    "La sección 3 (**Experimentación**) A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Diseño\n",
    "***\n",
    "En esta sección se detallan las características del modelo implementado, profundizando sobre las estrategias y algoritmos empleados en la configuración paramétrica. También se tratan otros puntos como el procesamiento previo al entrenamiento y la evaluación posterior al mismo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Modelo\n",
    "***\n",
    "Para este escenario el modelo propuesto es el de **regresión logística**, un modelo de clasificación que adapta la idea de la **regresión lineal**, es decir, aproximar en base a los ejemplos del corpus una función con codomino continuo, y transformar el resultado continuo en uno discreto, utilizando una **función de probabilidad** y asignando a dicha probabilidad una clase en concreto.\n",
    "\n",
    "Se definen más formalmente las siguientes nociones:\n",
    "* $D =$ Conjunto de entrenamiento\n",
    "* $C_D =$ Conjunto de posibles clasificaciones para $d \\in D$\n",
    "* $RL_D =$ Clasificador de regresión logística generado en base a $D$\n",
    "* Se representa una clasificación de un ejemplo $d \\in D$ realizada por el clasificador $RL_D$ como $RL_D(d) = c : c \\in C_D$\n",
    "\n",
    "### 2.2. Preprocesamiento\n",
    "***\n",
    "Con el objetivo de cumplir parte de las pautas de la consigna, se realizaron ciertos cambios en el conjunto de datos a utilizar. A continuación, se listan los cambios realizados agrupandolos en base a motivación y área cambiada en el conjunto original.\n",
    "\n",
    "#### 2.2.1. Extracción de candidatos y partidos\n",
    "***\n",
    "Luego de levantar los datos, se filtran los candidatos que tengan menos de mil votantes. Esto da como resultado que los partidos que permanezcan van a ser solo los de aquellos candidatos que tienen más de mil votos cada uno. A modo de ejemplo, en el caso del partido colorado y el partido nacional, tenían candidatos con menos de mil votantes y con más de mil votantes. En este caso se dejan sólo los candidatos que tenían más de mil votantes.\n",
    "\n",
    "Para implementar la extracción se usaron funcionalidades de la librería pandas.\n",
    "\n",
    "#### 2.2.2. Separación de conjuntos de entrenamiento y evaluación\n",
    "***\n",
    "A\n",
    "\n",
    "#### 2.2.3. Reducción de dimensionalidad\n",
    "***\n",
    "En modo experimental, se puede realizar una reducción de dimensiones utilizando PCA. Se puede comprobar si clasificando utilizando determinada cantidad de componentes principales luego de aplicar PCA, los resultados siguen similares descartando aquellas componentes de menor varianza.\n",
    "Para implementar la reducción de dimensionalidad utilizamos PCA de la librería sci-kit learn.\n",
    "\n",
    "### 2.3. Algoritmo\n",
    "***\n",
    "En la siguiente sección se centralizan todas las especificaciones relativas a los algoritmos empleados, tanto para entrenar como para clasificar. Se detallan las bibliotecas utilizadas, así como la variación paramétrica y sus impactos.\n",
    "\n",
    "#### 2.3.1. Algoritmo de entrenamiento\n",
    "***\n",
    "\n",
    "El algoritmo de entrenamiento implementado para la **regresión logística** sigue las pautas del visto en el teórico. Dado que en esta ocasión no fue necesario desarrollarlo, solamente se mencionaran sin entrar en detalle aquellos aspectos teóricos o algorítmicos relativos al mismo.\n",
    "\n",
    "La biblioteca utilizada fue *scikit-learn*, tomando la implementación de la clase *LogisticRegression* del módulo *linear_model*. El método que ajusta el modelo al corpus en concreto es **_LogisticRegression.fit_**. La clase en cuestión permite realizar el entrenamiento en función de múltiples parámetros, dando a lugar a distintas configuraciones paramétricas. Dichos parámetros se detallarán en las siguientes secciones.\n",
    "\n",
    "Como breve repaso del funcionamiento del algoritmo, utilizando un método de aproximación en concreto, se realiza una suerte de interpolación utilizando los ejemplos del corpus y sus clasificaciones como guía, generando de esta forma una función que permite generar nuevas clasificaciones. El parámetro **_solver_** permite determinar que algoritmo de aproximación utilizar. Las opciones disponibles son las siguientes:\n",
    "- **Algoritmo de Newton** (_newton-cg_): Dicho algoritmo permite aproximar funciones utilizando además del gradiente, la **matriz hessiana**. Dado que debe computar la matriz, es computacionalmente costoso, pudiendo además quedar atascado en un **punto silla**, el cual es un tipo particular de **punto de inflexión** que no es extremo local pero tiene gradiente nulo. Dada la naturaleza del algoritmo, es particularmente bueno para aproximar a funciones cuadráticas.\n",
    "<br><br>\n",
    "- **Algoritmo de memoria limitada Broyden–Fletcher–Goldfarb–Shanno** (_lbfgs_): Perteneciente a la familia de algoritmos similares al **algoritmo de Newton**, **_LBFGS_** computa una aproximación de la **matriz hessiana** para aproximar la función objetivo, por lo que es computacionalmente menos costoso que el anteriormente mencionado, funcionando mejor con conjuntos de datos con pocos ejemplos. \n",
    "<br><br>\n",
    "- **Algoritmo Liblinear** (_liblinear_): El algoritmo utilizado por defecto, basado en la biblioteca homónima de _C++_. Se basa en la idea del **descenso por coordenadas**, por lo que puede quedar atascado en un **punto de inflexión** que no sea extremo local. Tiene buenos resultados en conjuntos de datos con pocos ejemplos.\n",
    "<br><br>\n",
    "- **Algoritmo de Promedio Estocástico de Gradiente** (_sag_): Este algoritmo pertenece a la familia de los que implementan **descenso por gradiente estocástico**, siendo particularmente bueno para conjuntos de datos grandes con muchos atributos. Esto está relacionado al hecho de que el costo es independiente los términos de la suma (atributos).\n",
    "<br><br>\n",
    "- **Algoritmo de Promedio Estocástico de Gradiente Avanzado** (_saga_): Esta inspirado en el algoritmo **_SAG_**, incorporando conceptos de otro método denominado **_SVRG_** (_Stochastic Variance Reduced Gradient_, Reducción de Varianza por Gradiente Estocástico). Esto permite implementar otro tipo de penalización durante el entrenamiento (en la sección 2.3.4. se expande este punto).\n",
    "\n",
    "#### 2.3.2. Algoritmo de clasificación\n",
    "***\n",
    "El algoritmo de clasificación implementado para la **regresión logística** sigue las pautas del visto en el teórico. Dado que en esta ocasión no fue necesario desarrollarlo, solamente se mencionaran sin entrar en detalle aquellos aspectos teóricos o algorítmicos relativos al mismo.\n",
    "\n",
    "La biblioteca utilizada fue *scikit-learn*, tomando la implementación de *LogisticRegression* del módulo *linear_model*. El método que ajusta el modelo al corpus en concreto es **_LogisticRegression.predict_**. La clase en cuestión permite realizar el entrenamiento en función de múltiples parámetros, pudiendo generar distintos clasificadores, lo cual afectaría el algoritmo de clasificación empleado.\n",
    "\n",
    "En el contexto de esta tarea se utilizó únicamente un modelo **_One-Versus-Rest_** (_ovr_), el cual coincide con el visto en el teórico. Como breve repaso del funcionamiento del algoritmo, por cada clase $c \\in C_D$ se genera una aproximación utilizando **regresión lineal**, separando los ejemplos entre aquellos con clasificación $c$ y aquellos con clasificación distinta a $c$. De esta forma, al clasificar un nuevo ejemplo, se obtiene la probabilidad de que dicho ejemplo pertenezca a cada clase $c \\in C_D$, devolviendose la clase correspondiente a la probabilidad mayor.\n",
    "\n",
    "#### 2.3.3. Parámetros - Normalización\n",
    "***\n",
    "Debido al método de entrenamiento, la diferencia entre los intervalos de cada atributo puede afectar negativamente a la aproximación de la función de clasificación. Es por esto que se introduce la posibilidad de **normalizar** dichos intervalos, con el objetivo de llevar todos los atributos a la misma escala.\n",
    "\n",
    "Dado que en este escenario los atributos del corpus (es decir, las respuestas a las preguntas) toman valores en el mismo intervalo $[1..5]$, no es necesario hacer una normalización de los datos de entrada.\n",
    "\n",
    "#### 2.3.4. Parámetros - Regularización y penalización\n",
    "***\n",
    "Debido al método de entrenamiento, es posible que el algoritmo **sobreajuste** la aproximación de la función de clasificación. Si ocurre un sobreajuste, se pierde la capacidad de generalización del algoritmo, pudiendo fallar notoriamente en clasificaciones de ejemplos no vistos. De esta forma, se agrega el concepto de **regularización**, siendo el proceso utilizado para evitar que la regresión se sobreajuste a los datos de entrenamiento.\n",
    "\n",
    "La técnica consiste en agregar un componente de penalización a la función de costo a minimizar.\n",
    "\n",
    "El parámetro **_penalty_** permite determinar que algoritmo de regularización utilizar, más concretamente, que norma de penalización implementar. Las opciones disponibles son las siguientes:\n",
    "- **L1 - Regularización Lasso**: A . La documentación de _scikit-learn_ establece que solo los modelos entrenados con **_solver_** = _liblinear_, _saga_ pueden utilizar esta estrategia de penalización.\n",
    "<br><br>\n",
    "- **L2 - Regularización Ridge**: A . Esta es la única estrategia de penalización que es admitida por cualquier **_solver_**.\n",
    "<br><br>\n",
    "- **L1/L2 - Regularización ElasticNet**: A. La documentación de _scikit-learn_ establece que solo los modelos entrenados con **_solver_** = _saga_ pueden utilizar esta estrategia de penalización, no obstante, al intentarlo se obtuvo un error, por lo que esta estrategia fue dejada de lado.\n",
    "\n",
    "\n",
    "((((PONER ALGUNA FORMULA?)))\n",
    "link referencia: http://enhancedatascience.com/2017/07/04/machine-learning-explained-regularization/\n",
    "\n",
    "Los solver newton-cg, sag y lbfgs solo soportan el penalizador 'l2'. El penalizador 'elasticnet' solo es soportado por el solver 'saga'. Si se selecciona 'None' no se aplica regularizacion. El solver liblinear no soporta la opcion 'None'.\n",
    "\n",
    "Luego de elegido el penalizador, se debe determinar un valor para el coeficiente de regularizacion. Si se toma un valor muy grande se produce un underfitting y si el valor es muy pequeno se va a sobreajustar sobre los ejemplos de entrenamiento. La libreria provee del parametro **C**. **C** es el inverso de la fuerza de regularizacion, por lo tanto debe ser un valor positivo distinto de 0. Por defecto el valor de **C** es 1.0.\n",
    "\n",
    "#### 2.3.5. Parámetros - Enfoque multiclase\n",
    "***\n",
    "La implementacion del algoritmo da la opcion a seleccion si realizamos una clasificacion multiclase o binaria. Para esto se provee del parametro **multi_class**. Los valores posibles son ovr, multinomial y auto. En nuestro caso utilizamos ovr que significa one versus rest. Este parametro crea internamente una regresion logistica binaria por cada clase y luego como se detallo anteriormente, se elige al de mayor valor.\n",
    "\n",
    "#### 2.3.6. Parámetros - Convergencia e iteraciones\n",
    "***\n",
    "Como se mencionó anteriormente, si no se llega a una convergencia, se debe detener el algoritmo en algún momento, ya sea utilizando una tolerancia (usada por defecto en 1e-04 por la implementación de la librería) o definiendo un máximo de iteraciones. En nuestro caso decidimos limitar la cantidad de iteraciones con el parámetro **max_iter**.\n",
    "\n",
    "\n",
    "### 2.4. Evaluación\n",
    "***\n",
    "En esta subsección se comentan métodos de evaluación utilizados y métricas consideradas.\n",
    "\n",
    "#### 2.4.1. Métodos\n",
    "***\n",
    "En este laboratorio se usaron dos métodos de evaluación. Primero el método de validación normal, partiendo el conjunto de datos en 2, donde por un lado nos queda un conjunto de datos para entrenar y por otro un subconjunto para testear el algoritmo. Se realiza una partición 80/20, entrenamiento y test, respectivamente.\n",
    "\n",
    "Para implementar la validación normal, sci-kit learn provee de una función para separar el conjunto de datos en entrenamiento y test. La función es train_test_split y se le pasan por parámetro el conjunto de entrenamiento a separar y opcionalmente algunos parámetros que si no son ingresados, se toma sus valores por defecto. Entre ellos tenemos **test_size** siendo un valor entre 0 y 1 el cual determina la proporción del conjunto de datos a usar como test. Otro parámetro es **train_size** que si no se lo ingresa, se define como **1 - test_size**. Por defecto **test_size** vale 0.25. Otro parámetro útil es **shuffle**, el cual antes de separar desordena el conjunto de datos aleatoriamente (por defecto es True).\n",
    "\n",
    "El otro método de evaluación es la validación cruzada. Se denomina como **validación cruzada** a la partición del conjunto $D$ en $k$ particiones $T_i$ y $E_i : i \\in [1..k]$,  utilizando una proporción de $\\frac{k-1}{k}$ y $\\frac{1}{k}$ ejemplos para $T_i$ y $E_i$ respectivamente.\n",
    "\n",
    "Esta estrategia es más robusta que la **validación normal** anteriormente mencionada, sin embargo tiene el problema de tener un mayor orden computacional, dado que tiene que correr $k$ entrenamientos en lugar de uno.\n",
    "\n",
    "En este caso, sci-kit learn provee de una función para implementar la validacion cruzada (**cross_validate**). A la función se le pasa el modelo (en nuestro caso la LogisticRegression), el conjunto de datos sin contener el valor objetivo (la clase de cada ejemplo de entrenamiento), la clasificación de cada ejemplo del conjunto de entrenamiento y se configura el parámetro **cv** para indicar el valor del **k** para realizar las particiones.\n",
    "\n",
    "En la experimentación se decidió probar con $k=5$ y #k=10#.\n",
    "\n",
    "#### 2.4.2. Métricas\n",
    "***\n",
    "Se utilizaron múltiples métricas para determinar la \"calidad\" o \"eficacia\" de los clasificadores entrenados. A continuación, una breve descripción de las mismas:\n",
    "\n",
    "##### 2.4.2.1 Accuracy\n",
    "***\n",
    "La **accuracy** o **exactitud** hace referencia a la cantidad de aciertos que el clasificador tuvo en relación al total de clasificaciones que realizó durante la evaluación. Para definir **accuracy**, se utilizan las siguientes nociones:\n",
    "- Sea $D$ el conjunto de datos, $C_D$ el conjunto de posibles clasificaciones en $D$ y $|C_D| = n$\n",
    "- Sea $t_i : i \\in [1..n]$ la cantidad de clasificaciones para la clase $i$ que fueron correctas\n",
    "- Sea $f_i : i \\in [1..n]$ la cantidad de clasificaciones para la clase $i$ que fueron incorrectas\n",
    "\n",
    "$$ accuracy = \\frac{\\sum_{i=1}^{n} t_i}{\\sum_{i=1}^{n} t_i + f_i}$$\n",
    "\n",
    "Se observa que **accuracy** no es una muy buena medida de performance, ya que depende mucho del conjunto de datos que se evalúe, pudiendo dar buenos resultados a un clasificador malo. Teniendo esto en cuenta, se utilizó esta métrica solo para tener una noción general del desempeño de un clasificador, dandole más peso a las métricas definidas a continuación.\n",
    "\n",
    "##### 2.4.2.2 Matriz de Confusión\n",
    "***\n",
    "La **matriz de confusión** es una matriz que permite almacenar todas las clasificaciones realizadas en una evaluación, basándose en cada resultado y su respectivo valor original. La estructura de la matriz es la siguiente:\n",
    "\n",
    "- Sea $D =$ Conjunto de datos\n",
    "- Sea $C_D =$ Conjunto de clasificaciones para $d \\in D$ \n",
    "- Sea $|C_D| = n$ cantidad de posibles clasificaciones en $C_D$\n",
    "- Sea $M$ la matriz de confusión para una evaluación definida como:\n",
    "\n",
    "$$M = \\begin{bmatrix}\n",
    "    x_{11} & x_{12} & \\dots  & x_{1n} \\\\\n",
    "    x_{21} & x_{22} & \\dots  & x_{2n} \\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    x_{n1} & x_{n2} & \\dots  & x_{nn}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "- Entonces $x_{ij} \\in M : i,j \\in [1..n]$ representa la cantidad de clasificaciones que originalmente eran **clase $i$** y que fueron clasificadas en la evaluación como **clase $j$**.\n",
    "\n",
    "De esta forma, en una matriz cuadrada de dimensión $n$, se pueden centralizar todas las clasificaciones realizadas y su relación con respecto a cada clase.\n",
    "\n",
    "En sí misma, la matriz de confusión no representa una métrica sino una herramienta para calcular otras métricas, las cuales serán detalladas a continuación. De todas formas, una mirada superficial a una matriz de confusión de tamaño razonable puede aportar información general sobre el desempeño del clasificador, (esto es detallado en la siguiente subsección).\n",
    "\n",
    "##### 2.4.2.3 Precision, Recall, F-measure\n",
    "***\n",
    "Usamos tres medidas que, si bien siguen una fórmula similar a la de **accuracy**, son mucho menos sensibles al ruido en el conjunto de datos $D$, ya que operan **por clase**. Antes de detallar cada una, se repasan ciertas nociones básicas utilizadas en la definición de cada métrica.\n",
    "\n",
    "Retomando el punto anterior, la matriz de confusión permite calcular para cada clase $c_i$, cuatro valores indispensables:\n",
    "- Los **verdaderos positivos** en la clase $c_i$ (denotados como $t_i$), son aquellos ejemplos que originalmente son clase $c_i$ y fueron clasificados correctamente en la evaluación como clase $c_i$. Para calcularlos utilizando la matriz de confusión, simplemente hay que tomar la celda $M(i,i)$ para la clase $c_i$.\n",
    "\n",
    "$$ t_i = M(i,i) $$\n",
    "\n",
    "- Los **falsos positivos** en la clase $c_i$ (denotados como $f_i$), son aquellos ejemplos que originalmente son clase $c_j : j \\neq i$ y fueron clasificados incorrectamente en la evaluación como clase $c_i$. Para calcularlos utilizando la matriz de confusión, simplemente hay que tomar la fila $M_{(i,)}$ para la clase $c_i$, y sumar todos sus valores (excepto la celda $M(i,i)$, que corresponde a los verdaderos positivos).\n",
    "\n",
    "$$ f_i = \\sum_{j=1, j \\neq i}^{n} M(i,j) $$\n",
    "\n",
    "- Los **verdaderos negativos** en la clase $c_i$ (denotados como $\\bar{t_i}$), son aquellos ejemplos que originalmente no son clase $c_i$ y fueron clasificados en la evaluación como clase $c_j : j \\neq i$. Cabe destacar que la clasificación como $c_j$ puede ser correcta o no, lo importante es que sea consistente en relación a $c_i$. Para calcularlos utilizando la matriz de confusión, simplemente hay que tomar la matriz adjunta a los verdaderos positivos de $c_i$ y sumar todas sus entradas. Dicha matriz se define como $M_{ii}$ y contiene todas las entradas de $M$ excepto la fila $i$ y la columna $i$.\n",
    "\n",
    "$$ \\bar{t_i} = \\sum_{j=1}^{n-1} \\sum_{k=1}^{n-1} M_{ii}(j,k) $$\n",
    "\n",
    "- Los **falsos negativos** en la clase $c_i$ (denotados como $\\bar{f_i}$), son aquellos ejemplos que originalmente son clase $c_i$ y fueron clasificados incorrectamente en la evaluación como clase $c_j : j \\neq i$. Para calcularlos utilizando la matriz de confusión, simplemente hay que tomar la columna $M_{(,i)}$ para la clase $c_i$, y sumar todos sus valores (excepto la celda $M(i,i)$, que corresponde a los verdaderos positivos).\n",
    "\n",
    "$$ \\bar{f_i} = \\sum_{j=1, j \\neq i}^{n} M(j,i) $$\n",
    "\n",
    "Teniendo en cuenta dichas definiciones, se pasa a definir las métricas utilizadas:\n",
    "- **Precision**\n",
    "> - La **precision** o precisión de una **clase $c_i$** hace referencia a la cantidad de clasificaciones correctas para dicha clase, en relación a la cantidad de clasificaciones totales (correctas e incorrectas) para dicha clase.\n",
    "> - La precision permite determinar \"que tan bien se clasifica una clase\". En otras palabras, que tan poco se equivoca el clasificador en marcar un ejemplo como cierta clase.\n",
    "> - Oscila entre 0 y 1, siendo mejor cuanto **mayor** es.\n",
    "> - Se calcula como:\n",
    "> $$ precision(c_i) = \\frac{t_i}{t_i + f_i}$$\n",
    "\n",
    "- **Recall**\n",
    "> - La **recall** o recuperación de una **clase $c_i$** hace referencia a la cantidad de clasificaciones correctas para dicha clase, en relación a la cantidad de clasificaciones originales para dicha clase.\n",
    "> - La recall permite determinar \"que tan bien se clasifican elementos de otras clases respecto a una clase\". En otras palabras, que tan poco se equivoca el clasificador en marcar un ejemplo de otras clases como cierta clase.\n",
    "> - Oscila entre 0 y 1, siendo mejor cuanto **mayor** es.\n",
    "> - Se calcula como:\n",
    "> $$ recall(c_i) = \\frac{t_i}{t_i + \\bar{f_i}}$$\n",
    "\n",
    "- **F-measure**\n",
    "> - La **F-measure** o medida-F de una **clase $c_i$** es una medida que relaciona **precision** y **recall**, oficiando de alguna forma como un representante de cierta clase.\n",
    "> - La F-measure permite determinar \"que tan bien se clasifica una clase y que tan poco se falla a la vez\". En otras palabras, es una relación proporcional entre la precision y la recall y por tanto es una buena métrica para determinar el desempeño del clasificador respecto a una clase.\n",
    "> - Oscila entre 0 y 1, siendo mejor cuanto **mayor** es.\n",
    "> - Se calcula como:\n",
    "> $$ Fmeasure(c_i) = \\frac{2 precision(c_i) recall(c_i)}{precision(c_i) + recall(c_i)}$$\n",
    "\n",
    "Si bien estas medidas ofrecen información más enriquecedora en comparación a las anteriormente mencionadas, cuentan con el \"defecto\" de aplicar por clase y no dar una medida general del clasificador. Para conjuntos $D$ con pocas clasificaciones en $C_D$ esto no es un gran problema, pero complica la comparación al aumentar la cantidad de clases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experimentación\n",
    "***\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Metodología\n",
    "***\n",
    "A\n",
    "\n",
    "1. **Evaluación del corpus:** A.\n",
    "<br><br>\n",
    "2. **Configuraciones paramétricas:** A.\n",
    "<br><br>\n",
    "3. **Elección y comparación de representantes:** A.\n",
    "<br><br>\n",
    "4. **Comparación de clasificadores según partido:** A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Evaluación del corpus\n",
    "***\n",
    "Aquí se va a monitorear cómo afecta al corpus el preprocesamiento realizado. Vamos a mostrar cómo de distribuyen los votos de cada candidato/partido separando entre aquellos con más de mil votantes y con menos de mil votantes. Y también vamos a monitorear el explained variance ratio luego de reducir dimensiones con PCA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Script que grafica métricas del corpus\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import operator\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "#from utils.const import *\n",
    "from model.model import Model\n",
    "import processing.reader as reader\n",
    "import evaluation.evaluator as evaluator\n",
    "import plotting.corpusPlotting as corpusPlotting\n",
    "import plotting.pcaPlotting as pcaPlotting\n",
    "import plotting.evalPlotting as evalPlotting\n",
    "import utils.gui as gui\n",
    "from utils.const import DATA_ENCUESTAS, DATA_CANDIDATOS, MenuOps, PlotOps\n",
    "%matplotlib inline \n",
    "\n",
    "# Leer dataset de respuestas a encuesta separando entre candidatos con más y menos de 1000 votos\n",
    "dataset = reader.readDataset('../' + DATA_ENCUESTAS, options={'from_notebook': True})\n",
    "datasetC = reader.readDatasetC('../' + DATA_ENCUESTAS, options={'from_notebook': True})\n",
    "\n",
    "candidatesJSON = reader.readCandidates(options = {'from_notebook': True})\n",
    "partiesJSON = reader.readParties(options = {'from_notebook': True})\n",
    "\n",
    "# Graficar distribución de votantes según candidato y partido\n",
    "corpusPlotting.plotCorpus(dataset, datasetC, candidatesJSON, partiesJSON)\n",
    "\n",
    "# Graficar ratio de varianza para cada dimensión\n",
    "pcaPlotting.plotPCA(dataset)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Se grafica el explained variance ratio para ver mejor k de PCA\n",
    "# Se grafica la distribución de candidatos y partidos con más de 1000 votos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se ve en la gráfica de ratio de varianza contra número de componentes, luego de cierto número de componentes (5 por ejemplo), el porcentaje de varianza aumenta de manera uniforme. En el laboratorio anterior ya habíamos notado este comportamiento utilizando una implementación propia de PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Configuración paramétrica\n",
    "***\n",
    "A\n",
    "\n",
    "#### 3.3.1. Evaluaciones\n",
    "***\n",
    "En resumen, para nuestra implementación de regresión logística usando la librería sci-kit learn vamos a variar los siguientes parámetros del modelo:\n",
    "\n",
    "- **solver**: Los valores a variar son newton-cg, lbfgs,liblinear, sag y saga.\n",
    "- **penalty**: Los valores a variar son l2, l1 y None. \n",
    "- **max_iter**: Este valor por defecto probamos con 1000 iteraciones.\n",
    "- **C**: Este valor es el inverso del regularization strength. Como se mencionó debe ser un valor positivo mayor que cero.\n",
    "\n",
    "Para el parámetro **multi_class** se fija el valor 'ovr' (one-versus-rest) dado que buscamos una clasificación multiclase compuesta por varios clasificadores binarios donde cada uno clasifica su clase y luego se decide según el que devuelva un valor máximo entre ellos.\n",
    "\n",
    "#### 3.3.2. Resultados\n",
    "***\n",
    "A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script que dada una configuración paramétrica, la entrena y evalúa\n",
    "# Evaluación muestra accuracy, metricas, matriz de confusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Elección y comparación de representantes\n",
    "***\n",
    "A\n",
    "\n",
    "#### 3.4.1. Análisis cuantitativo\n",
    "***\n",
    "A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script que evalúa con cross validation cada configuración paramétrica y las devuelve ordenadas por accuracy\n",
    "# Devuelve los 4 mejores que son: Candidatos sin PCA, Partidos sin PCA, Candidatos con PCA y Partidos con PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2. Análisis cualitativo\n",
    "***\n",
    "A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script que grafica métricas de los módulos elegidos con el anterior script\n",
    "# Se grafica en barras las metricas, en mapa de calor las matrices de confusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.3. Representantes elegidos\n",
    "***\n",
    "A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Comparación de clasificadores según partido\n",
    "***\n",
    "A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script que evalúa con cross validation a los representantes de candidatos y sustituye sus candidatos por partidos,\n",
    "# comparando rendimiento con representantes de partidos\n",
    "# Tambien grafica métricas en barras, mapa de calor de matrices de confusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusiones\n",
    "***\n",
    "\n",
    "#### 4.1. Respecto a los Datos\n",
    "***\n",
    "- A\n",
    "\n",
    "#### 4.2. Respecto a los Parámetros\n",
    "***\n",
    "- A\n",
    "\n",
    "#### 4.3. Respecto a los Resultados\n",
    "***\n",
    "- A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Referencias\n",
    "***\n",
    "[1] **Documentación oficial de Scikit-Learn** - https://scikit-learn.org/stable/documentation.html\n",
    "\n",
    "[2] **Minimizing Finite Sums with the Stochastic Average Gradient** - https://hal.inria.fr/hal-00860051/document\n",
    "\n",
    "[3] **SAGA: A Fast Incremental Gradient Method With Support for Non-Strongly Convex Composite Objectives** - https://arxiv.org/pdf/1407.0202.pdf\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
